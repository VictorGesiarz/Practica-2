{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import random\n",
    "\n",
    "from  extract_book_features import extract_book_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = pd.read_csv('../clean_data/books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th>Freebase ID</th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication Year</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Rating Count</th>\n",
       "      <th>Average Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7956168</td>\n",
       "      <td>/m/026lcx6</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Kitchen God's Wife opens with the narrati...</td>\n",
       "      <td>116.0</td>\n",
       "      <td>8.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1703697</td>\n",
       "      <td>/m/05pr53</td>\n",
       "      <td>The Testament</td>\n",
       "      <td>John Grisham</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>['Thriller', 'Fiction', 'Suspense']</td>\n",
       "      <td>Troy Phelan, an eccentric elderly billionaire...</td>\n",
       "      <td>261.0</td>\n",
       "      <td>7.544643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999996</td>\n",
       "      <td>/m/03y389</td>\n",
       "      <td>Airframe</td>\n",
       "      <td>Michael Crichton</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>['Science Fiction', 'Novel']</td>\n",
       "      <td>The novel opens aboard Hong Kong-based Transp...</td>\n",
       "      <td>129.0</td>\n",
       "      <td>7.719298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1298672</td>\n",
       "      <td>/m/04qyx7</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>Michael Crichton</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>['Science Fiction', 'Fiction', 'Suspense']</td>\n",
       "      <td>In the middle of the New Mexico desert, a vac...</td>\n",
       "      <td>263.0</td>\n",
       "      <td>8.052083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73408</td>\n",
       "      <td>/m/0jqbz</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>['Fiction']</td>\n",
       "      <td>The book opens with the Finch family's ancest...</td>\n",
       "      <td>267.0</td>\n",
       "      <td>9.043165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>4760716</td>\n",
       "      <td>/m/0clxxp</td>\n",
       "      <td>The Game-Players of Titan</td>\n",
       "      <td>Philip K. Dick</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>['Science Fiction', 'Speculative fiction', 'Fa...</td>\n",
       "      <td>Pete Garden, the protagonist, is one of sever...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>480566</td>\n",
       "      <td>/m/02fmjq</td>\n",
       "      <td>Galactic Pot-Healer</td>\n",
       "      <td>Philip K. Dick</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>['Science Fiction', 'Speculative fiction', 'Fi...</td>\n",
       "      <td>The novel takes place in a dismal future Amer...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>2497286</td>\n",
       "      <td>/m/07h_l2</td>\n",
       "      <td>Solar Lottery</td>\n",
       "      <td>Philip K. Dick</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>['Science Fiction', 'Speculative fiction', 'Fi...</td>\n",
       "      <td>Solar Lottery takes place in a world dominate...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>23616820</td>\n",
       "      <td>/m/06zktr5</td>\n",
       "      <td>Le Sang noir</td>\n",
       "      <td>Louis Guilloux</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One day in 1917 an aging philosophy tutor, ni...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736</th>\n",
       "      <td>23328624</td>\n",
       "      <td>/m/09k7b62</td>\n",
       "      <td>Wild Geese</td>\n",
       "      <td>Martha Ostenso</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>['Historical novel']</td>\n",
       "      <td>Lind Archer, a teacher from the city, has com...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4737 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Wikipedia ID Freebase ID                 Book Title            Author   \n",
       "0          7956168  /m/026lcx6     The Kitchen God's Wife           Amy Tan  \\\n",
       "1          1703697   /m/05pr53              The Testament      John Grisham   \n",
       "2           999996   /m/03y389                   Airframe  Michael Crichton   \n",
       "3          1298672   /m/04qyx7                   Timeline  Michael Crichton   \n",
       "4            73408    /m/0jqbz      To Kill a Mockingbird        Harper Lee   \n",
       "...            ...         ...                        ...               ...   \n",
       "4732       4760716   /m/0clxxp  The Game-Players of Titan    Philip K. Dick   \n",
       "4733        480566   /m/02fmjq        Galactic Pot-Healer    Philip K. Dick   \n",
       "4734       2497286   /m/07h_l2              Solar Lottery    Philip K. Dick   \n",
       "4735      23616820  /m/06zktr5               Le Sang noir    Louis Guilloux   \n",
       "4736      23328624  /m/09k7b62                 Wild Geese    Martha Ostenso   \n",
       "\n",
       "      Publication Year                                             Genres   \n",
       "0               1991.0                                                NaN  \\\n",
       "1               1999.0                ['Thriller', 'Fiction', 'Suspense']   \n",
       "2               1996.0                       ['Science Fiction', 'Novel']   \n",
       "3               1999.0         ['Science Fiction', 'Fiction', 'Suspense']   \n",
       "4               1960.0                                        ['Fiction']   \n",
       "...                ...                                                ...   \n",
       "4732            1963.0  ['Science Fiction', 'Speculative fiction', 'Fa...   \n",
       "4733            1969.0  ['Science Fiction', 'Speculative fiction', 'Fi...   \n",
       "4734            1955.0  ['Science Fiction', 'Speculative fiction', 'Fi...   \n",
       "4735            1935.0                                                NaN   \n",
       "4736            1925.0                               ['Historical novel']   \n",
       "\n",
       "                                                Summary  Rating Count   \n",
       "0      The Kitchen God's Wife opens with the narrati...         116.0  \\\n",
       "1      Troy Phelan, an eccentric elderly billionaire...         261.0   \n",
       "2      The novel opens aboard Hong Kong-based Transp...         129.0   \n",
       "3      In the middle of the New Mexico desert, a vac...         263.0   \n",
       "4      The book opens with the Finch family's ancest...         267.0   \n",
       "...                                                 ...           ...   \n",
       "4732   Pete Garden, the protagonist, is one of sever...           1.0   \n",
       "4733   The novel takes place in a dismal future Amer...           1.0   \n",
       "4734   Solar Lottery takes place in a world dominate...           1.0   \n",
       "4735   One day in 1917 an aging philosophy tutor, ni...           1.0   \n",
       "4736   Lind Archer, a teacher from the city, has com...           1.0   \n",
       "\n",
       "      Average Rating  \n",
       "0           8.280000  \n",
       "1           7.544643  \n",
       "2           7.719298  \n",
       "3           8.052083  \n",
       "4           9.043165  \n",
       "...              ...  \n",
       "4732        7.000000  \n",
       "4733        8.000000  \n",
       "4734        7.000000  \n",
       "4735             NaN  \n",
       "4736        7.000000  \n",
       "\n",
       "[4737 rows x 9 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "Found 252 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 368 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "65\n",
      "Found 387 pages, best-seller: Yes, film: Yes, saga: Jack Ryan, followed by: nan, preceded by: Patriot Games\n",
      "66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 318 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 336 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "68\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4321 pages, best-seller: No, film: Yes, saga: Mitch McDeereseries, followed by: nan, preceded by: The Exchange\n",
      "70\n",
      "Found 229240 pages, best-seller: No, film: Yes, saga: The Hitchhiker's Guide to the Galaxy, followed by: So Long, and Thanks for All the Fish, preceded by: And Another Thing...\n",
      "71\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: Pilote de guerre(1942), preceded by: Lettre à un otage [fr] (1944)\n",
      "72\n",
      "Found 144 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "73\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Adventures of Huckleberry Finn\n",
      "74\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "75\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "76\n",
      "Found 546528 pages, best-seller: No, film: Yes, saga: No, followed by: Good Bones, preceded by: Alias Grace\n",
      "77\n",
      "Found 29416 pages, best-seller: No, film: No, saga: No, followed by: Castle Roogna, preceded by: Ogre, Ogre\n",
      "78\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "Found 537668 pages, best-seller: No, film: Yes, saga: No, followed by: A Son of the Circus, preceded by: The Fourth Hand\n",
      "81\n",
      "Found 496 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "82\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Year of the Flood\n",
      "83\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 207 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 169 pages, best-seller: No, film: No, saga: The Giver Quartet, followed by: Gathering Blue, preceded by: Son\n",
      "86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 447 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: Doctor Sleep\n",
      "87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 pages, best-seller: No, film: No, saga: No, followed by: Tell Me Your Dreams, preceded by: Are You Afraid Of The Dark?\n",
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 251 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "89\n",
      "Found 232 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Pigs in Heaven\n",
      "90\n",
      "Found 428 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "91\n",
      "Found 592 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "92\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "93\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "94\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 338 pages, best-seller: No, film: Yes, saga: No, followed by: None, Back Roads was Tawni's first published novel., preceded by: Coal Run (June 2004), Sister Mine (March 2007)\n",
      "96\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "97\n",
      "Found 321 pages, best-seller: No, film: No, saga: No, followed by: Shadow Image, preceded by: nan\n",
      "98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 496 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 412 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "100\n",
      "Found 400 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "101\n",
      "Found 1951447402 pages, best-seller: No, film: Yes, saga: The Chronicles of Narnia, followed by: The Lion, the Witch and the Wardrobe, preceded by: The Voyage of the Dawn Treader\n",
      "102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "104\n",
      "Found 139 pages, best-seller: No, film: Yes, saga: The Mouse and the Motorcycle, followed by: Runaway Ralph, preceded by: nan\n",
      "105\n",
      "Found 320 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "106\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "108\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "109\n",
      "Found 371 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "110\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "111\n",
      "Found 546 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "112\n",
      "Found 370 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Gift of Asher Lev\n",
      "113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "114\n",
      "Found 371 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "115\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144 pages, best-seller: No, film: Yes, saga: Matt Helm, followed by: The Shadowers, preceded by: The Devastators\n",
      "117\n",
      "Found 689489 pages, best-seller: Yes, film: Yes, saga: Robert Langdon#2, followed by: Angels & Demons, preceded by: The Lost Symbol\n",
      "118\n",
      "Found 390 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Tricky Business\n",
      "120\n",
      "Found 460 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "121\n",
      "Found 198 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "122\n",
      "Found 218 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "123\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "125\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "126\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 356 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Man and Wife\n",
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 432 pages, best-seller: No, film: No, saga: Women's Murder Club, followed by: 1st to Die, preceded by: 3rd Degree\n",
      "129\n",
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Room\n",
      "130\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "131\n",
      "Found 184 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "132\n",
      "Found 179 pages, best-seller: No, film: Yes, saga: Space Merchants, followed by: nan, preceded by: The Merchants' War\n",
      "133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "134\n",
      "Found 343 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "135\n",
      "Found 620 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "136\n",
      "Found 435 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "137\n",
      "Found 323 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "138\n",
      "Found 160 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 428 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "140\n",
      "Found 432 pages, best-seller: No, film: No, saga: No, followed by: The Mists of Avalon, preceded by: Lady of Avalon\n",
      "141\n",
      "Found 1028 pages, best-seller: Yes, film: No, saga: Jack Ryan, followed by: Rainbow Six, preceded by: Red Rabbit\n",
      "142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 672 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: Sycamore Row\n",
      "143\n",
      "Found 540 pages, best-seller: Yes, film: Yes, saga: Jack Ryan, followed by: The Hunt for Red October, preceded by: The Cardinal of the Kremlin\n",
      "144\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "145\n",
      "Found nan pages, best-seller: No, film: No, saga: The Cat Whoseries, followed by: The Cat Who Said Cheese, preceded by: The Cat Who Sang for the Birds\n",
      "146\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "147\n",
      "Found 400 pages, best-seller: No, film: No, saga: No, followed by: The Doomsday Conspiracy, preceded by: Nothing Lasts Forever\n",
      "148\n",
      "Found 357 pages, best-seller: No, film: No, saga: No, followed by: Invasion, preceded by: Vector\n",
      "149\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "150\n",
      "Found 269 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "151\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 434 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "153\n",
      "Found 382 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Darkness, followed by: nan, preceded by: Darkness Descending\n",
      "155\n",
      "Found 255 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "156\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "157\n",
      "Found 324 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "158\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "159\n",
      "Found 286 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "160\n",
      "Found 581 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "161\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "162\n",
      "Found 752 pages, best-seller: No, film: No, saga: Outlanderseries, followed by: Outlander, preceded by: Voyager\n",
      "163\n",
      "Found 480 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 227 pages, best-seller: No, film: Yes, saga: No, followed by: Billy Phelan's Greatest Game, preceded by: Quinn's Book\n",
      "165\n",
      "Found 464 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 464 pages, best-seller: No, film: Yes, saga: Alex Cross, followed by: Along Came a Spider, preceded by: Jack & Jill\n",
      "167\n",
      "Found 256224 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "168\n",
      "Found 586 pages, best-seller: Yes, film: Yes, saga: Dragonlance, followed by: nan, preceded by: nan\n",
      "169\n",
      "Found 278 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "170\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Daughter of Fortune, preceded by: nan\n",
      "171\n",
      "Found 465 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Anansi Boys\n",
      "172\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: The Space Odyssey series, followed by: 2010: Odyssey Two, preceded by: 3001: The Final Odyssey\n",
      "173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 348 pages, best-seller: No, film: Yes, saga: Hannibal Lecter, followed by: Hannibal Rising, preceded by: The Silence of the Lambs\n",
      "174\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "175\n",
      "Found 219 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "176\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "177\n",
      "Found 692 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "178\n",
      "Found 368 pages, best-seller: No, film: No, saga: Mary Russell, followed by: nan, preceded by: A Monstrous Regiment of Women\n",
      "179\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2261 pages, best-seller: No, film: No, saga: No, followed by: The Beet Queen, preceded by: The Bingo Palace\n",
      "181\n",
      "Found 448 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "182\n",
      "Found 387 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "183\n",
      "Found 278 pages, best-seller: Yes, film: No, saga: No, followed by: The Tears of the Singers, preceded by: Uhura's Song\n",
      "184\n",
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: Women, preceded by: Hollywood\n",
      "185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 pages, best-seller: No, film: No, saga: Felix and Zelda, followed by: nan, preceded by: Then (2009)\n",
      "Now (2010)\n",
      "After (2012)\n",
      "Soon (2015)\n",
      "Maybe (2017)\n",
      "Always (2021)\n",
      "186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 pages, best-seller: No, film: Yes, saga: No, followed by: Invisible Monsters, preceded by: Lullaby\n",
      "187\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "188\n",
      "Found 345 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "189\n",
      "Found 408208018 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "190\n",
      "Found 301 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "191\n",
      "Found 1791 pages, best-seller: No, film: Yes, saga: Wayside School, followed by: Sideways Stories From Wayside School(1978), preceded by: Wayside School Gets A Little Stranger (1995)\n",
      "192\n",
      "Found 340 pages, best-seller: No, film: No, saga: Dragonriders of Pern, followed by: The Chronicles of Pern: First Fall, preceded by: Dragonseye or Red Star Rising\n",
      "193\n",
      "Found 431 pages, best-seller: No, film: No, saga: Dragonriders of Pern, followed by: Nerilka's Story, preceded by: Renegades of Pern\n",
      "194\n",
      "Found 30718 pages, best-seller: No, film: No, saga: Xanthseries, followed by: Centaur Aisle, preceded by: Night Mare\n",
      "195\n",
      "Found 843 pages, best-seller: Yes, film: Yes, saga: Lonesome Dove series, followed by: nan, preceded by: Streets of Laredo\n",
      "196\n",
      "Found 560 pages, best-seller: No, film: Yes, saga: No, followed by: The Hotel New Hampshire, preceded by: A Prayer for Owen Meany\n",
      "197\n",
      "Found 513 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "198\n",
      "Found 448 pages, best-seller: No, film: No, saga: Darwin series, followed by: nan, preceded by: Darwin's Children\n",
      "199\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "200\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 720 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "203\n",
      "Found 546 pages, best-seller: No, film: Yes, saga: No, followed by: Shame, preceded by: Haroun and the Sea of Stories\n",
      "204\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Wormwood\n",
      "205\n",
      "Found 617 pages, best-seller: Yes, film: Yes, saga: No, followed by: The Cider House Rules, preceded by: A Son of the Circus\n",
      "206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Maura IslesJane Rizzoli, followed by: The Apprentice, preceded by: Body Double\n",
      "208\n",
      "Found 391 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Leaving Cold Sassy\n",
      "209\n",
      "Found 400 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "210\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "211\n",
      "Found 226 pages, best-seller: No, film: Yes, saga: No, followed by: None, preceded by: English: NP (novel)\n",
      "212\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "213\n",
      "Found 418 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "214\n",
      "Found 365 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 197 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "216\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "217\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "218\n",
      "Found 399 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 480 pages, best-seller: No, film: Yes, saga: No, followed by: The Rooster Bar, preceded by: nan\n",
      "220\n",
      "Found 250 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "221\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "222\n",
      "Found 191 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Lady Slings the Booze\n",
      "223\n",
      "Found 500 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Lost Painting: The Quest for a Caravaggio Masterpiece\n",
      "224\n",
      "Found 447 pages, best-seller: No, film: No, saga: Jack Reacher, followed by: Past Tense, preceded by: The Sentinel\n",
      "225\n",
      "Found 7531 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1036 pages, best-seller: No, film: Yes, saga: No, followed by: Mansfield Park, preceded by: Northanger Abbey\n",
      "227\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "228\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Pride and Prejudice\n",
      "229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "230\n",
      "Found 277 pages, best-seller: No, film: Yes, saga: Philip Marlowe, followed by: nan, preceded by: Farewell, My Lovely\n",
      "231\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "232\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "233\n",
      "Found 565 pages, best-seller: No, film: No, saga: Aloysius Pendergast, followed by: Reliquary, preceded by: Still Life with Crows\n",
      "234\n",
      "Found 660 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "236\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Princess Diaries, Volume II: Princess in the Spotlight\n",
      "237\n",
      "Found 232 pages, best-seller: No, film: No, saga: Joe Leaphorn/Jim CheeNavajo Tribal PoliceSeries, followed by: Hunting Badger(1999), preceded by: The Sinister Pig (2003)\n",
      "238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 399 pages, best-seller: No, film: Yes, saga: No, followed by: Birdsong, preceded by: nan\n",
      "239\n",
      "Found 4131 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: Tales from Watership Down\n",
      "240\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: Slaughterhouse-Five, preceded by: Slapstick\n",
      "241\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "242\n",
      "Found 182 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "243\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Indian in the Cupboard, followed by: nan, preceded by: The Return of the Indian\n",
      "244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Lake House\n",
      "245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 482 pages, best-seller: No, film: No, saga: Hyperion Cantos, followed by: nan, preceded by: The Fall of Hyperion\n",
      "246\n",
      "Found 489448 pages, best-seller: No, film: No, saga: Prequel to TheOriginal Shannara Trilogy, followed by: The Measure of the Magic, preceded by: The Sword of Shannara\n",
      "247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "248\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 408 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Children of God\n",
      "250\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "251\n",
      "Found 166 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Twisting the Rope\n",
      "252\n",
      "Found 185 pages, best-seller: No, film: No, saga: The Cat Whoseries, followed by: The Cat Who Saw Red, preceded by: The Cat Who Played Post Office\n",
      "253\n",
      "Found 415 pages, best-seller: No, film: No, saga: Kay Scarpetta, followed by: Point of Origin, preceded by: The Last Precinct\n",
      "254\n",
      "Found 224 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Luka and the Fire of Life\n",
      "255\n",
      "Found 385 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "256\n",
      "Found 760 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "257\n",
      "Found 2242 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "258\n",
      "Found 534 pages, best-seller: No, film: No, saga: Dirk PittNovels, followed by: Flood Tide, preceded by: Valhalla Rising\n",
      "259\n",
      "Found 496 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Angel of Darkness\n",
      "260\n",
      "Found 704 pages, best-seller: No, film: No, saga: No, followed by: none, preceded by: none\n",
      "261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 pages, best-seller: Yes, film: No, saga: Warriors, followed by: nan, preceded by: Fire and Ice\n",
      "262\n",
      "Found 1000 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "263\n",
      "Found 185 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "264\n",
      "Found 464 pages, best-seller: No, film: No, saga: No, followed by: Wildlife, preceded by: Women with Men: Three Stories\n",
      "265\n",
      "Found 340 pages, best-seller: No, film: No, saga: Kay Scarpetta, followed by: From Potter's Field, preceded by: Unnatural Exposure\n",
      "266\n",
      "Found 546543 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 pages, best-seller: No, film: Yes, saga: Kay Scarpetta, followed by: Unnatural Exposure, preceded by: Black Notice\n",
      "268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "271\n",
      "Found 1601954 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "272\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: Chronicles of the Avatar, followed by: nan, preceded by: The Shadow of Kyoshi\n",
      "273\n",
      "Found 284 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: As I Walked Out One Midsummer Morning\n",
      "274\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3611 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 302 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "278\n",
      "Found 434 pages, best-seller: No, film: No, saga: Dragonriders of Pern, followed by: The Masterharper of Pern, preceded by: A Gift of Dragons\n",
      "279\n",
      "Found 240 pages, best-seller: No, film: No, saga: Dragonriders of PernHarper Hall Trilogy, followed by: The White Dragon, preceded by: Moreta: Dragonlady of Pern\n",
      "280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 393 pages, best-seller: No, film: Yes, saga: No, followed by: Jurassic Park, preceded by: nan\n",
      "281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "282\n",
      "Found 202 pages, best-seller: No, film: No, saga: Dragonriders of PernHarper Hall Trilogy, followed by: Dragonquest, preceded by: Dragonsinger\n",
      "283\n",
      "Found 692 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 505 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "285\n",
      "Found 677 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 485512 pages, best-seller: Yes, film: Yes, saga: The Mortal Instruments, followed by: nan, preceded by: City of Ashes\n",
      "287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 353 pages, best-seller: No, film: Yes, saga: No, followed by: Stormy Weather, preceded by: Sick Puppy\n",
      "288\n",
      "Found 311 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Testaments\n",
      "289\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "291\n",
      "Found nan pages, best-seller: No, film: No, saga: The Bagthorpe Saga, followed by: Ordinary Jack, preceded by: Bagthorpes Unlimited\n",
      "292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 242 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "293\n",
      "Found 2562007 pages, best-seller: No, film: No, saga: The Cat Whoseries, followed by: nan, preceded by: The Cat Who Ate Danish Modern\n",
      "294\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: The Clocks, preceded by: Star Over Bethlehem and other stories\n",
      "295\n",
      "Found 528 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "296\n",
      "Found 352 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: Voyages Extraordinaires#4Baltimore Gun Club#1, followed by: Journey to the Center of the Earth, preceded by: nan\n",
      "298\n",
      "Found 343 pages, best-seller: No, film: No, saga: Time Quintet,Polly O'Keefe, followed by: Many Waters, preceded by: nan\n",
      "299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1780 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 415 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "301\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "302\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "303\n",
      "Found 918 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 237 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "305\n",
      "Found 275367 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 548 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 368 pages, best-seller: No, film: No, saga: Oathswornseries, followed by: The Wolf Sea(2008), preceded by: The Prow Beast (2010)\n",
      "308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3751 pages, best-seller: No, film: Yes, saga: The Maze Runnerseries, followed by: The Fever Code(in narrative order), preceded by: The Scorch Trials[2]\n",
      "309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 208 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "310\n",
      "Found 379480 pages, best-seller: Yes, film: Yes, saga: Ender's Game series, followed by: nan, preceded by: Shadow of the Hegemon\n",
      "311\n",
      "Found 876 pages, best-seller: Yes, film: No, saga: Avalon, followed by: nan, preceded by: The Forest House\n",
      "312\n",
      "Found 177 pages, best-seller: No, film: Yes, saga: Mountain, followed by: nan, preceded by: On the Far Side of the Mountain, Frightful's Mountain\n",
      "313\n",
      "Found 395 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "314\n",
      "Found 423 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "315\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 422 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "317\n",
      "Found 350 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: The Terminal Man\n",
      "318\n",
      "Found 305 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "319\n",
      "Found 227 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Blue Sword\n",
      "320\n",
      "Found 367 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 338 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "324\n",
      "Found 303 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "325\n",
      "Found 274 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "326\n",
      "Found 362 pages, best-seller: No, film: Yes, saga: Tom Sawyer, followed by: The Adventures of Tom Sawyer, preceded by: Tom Sawyer Abroad\n",
      "327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "328\n",
      "Found 10371024 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: ScarlettRhett Butler's People\n",
      "329\n",
      "Found 355 pages, best-seller: No, film: Yes, saga: George SmileyThe Quest for Karla, followed by: nan, preceded by: The Honourable Schoolboy\n",
      "330\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "331\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 467 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "333\n",
      "Found 274 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "334\n",
      "Found 352 pages, best-seller: No, film: Yes, saga: No, followed by: Lucky You, preceded by: Basket Case\n",
      "335\n",
      "Found 480 pages, best-seller: No, film: No, saga: Aloysius Pendergast, followed by: Relic, preceded by: The Cabinet of Curiosities\n",
      "336\n",
      "Found 502 pages, best-seller: No, film: Yes, saga: No, followed by: Timeline, preceded by: State of Fear\n",
      "337\n",
      "Found 448 pages, best-seller: No, film: Yes, saga: Moonlight Bay Trilogy, followed by: nan, preceded by: Seize the Night\n",
      "338\n",
      "Found 288 pages, best-seller: No, film: No, saga: Alphabet Mysteries, followed by: \"I\" Is for Innocent, preceded by: \"K\" Is for Killer\n",
      "339\n",
      "Found 407 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "340\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "341\n",
      "Found 277 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "342\n",
      "Found 387 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "343\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Brida, preceded by: By the River Piedra I Sat Down and Wept\n",
      "344\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: Who Wants a Cheap Rhinoceros?\n",
      "345\n",
      "Found 371342 pages, best-seller: No, film: Yes, saga: The Vampire Chronicles, followed by: nan, preceded by: The Vampire Lestat\n",
      "346\n",
      "Found 311 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "347\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "348\n",
      "Found 426 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "349\n",
      "Found 376 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "350\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: The Hound of Death, preceded by: Unfinished Portrait\n",
      "351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: Third Girl, preceded by: By the Pricking of My Thumbs\n",
      "352\n",
      "Found 2721 pages, best-seller: No, film: Yes, saga: No, followed by: Murder Is Easy, preceded by: Sad Cypress\n",
      "353\n",
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: Steppenwolf, preceded by: Journey to the East\n",
      "354\n",
      "Found 192 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "355\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Cranford, preceded by: Wives and Daughters\n",
      "357\n",
      "Found 397 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Thunderbird (2015)\n",
      "358\n",
      "Found 181 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "359\n",
      "Found 210 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "360\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Discworld11th novel – 2nd Death story, followed by: Moving Pictures, preceded by: Witches Abroad\n",
      "361\n",
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "362\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "363\n",
      "Found 84 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "364\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Extraordinary Voyages#3, followed by: The Adventures of Captain Hatteras, preceded by: From the Earth to the Moon\n",
      "365\n",
      "Found 216199 pages, best-seller: Yes, film: Yes, saga: Star Wars, followed by: From the Adventures of Luke Skywalker(1976), preceded by: Star Wars Episode V: The Empire Strikes Back (1980)\n",
      "366\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "368\n",
      "Found 353 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "369\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "370\n",
      "Found 309 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "371\n",
      "Found 348 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "372\n",
      "Found 1024 pages, best-seller: No, film: Yes, saga: No, followed by: Surrender None, preceded by: Liar's Oath\n",
      "373\n",
      "Found 383429 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "374\n",
      "Found 486 pages, best-seller: No, film: No, saga: No, followed by: Walking to Mercury, preceded by: City of Refuge\n",
      "375\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Midnight Robber\n",
      "377\n",
      "Found 392 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "378\n",
      "Found 312 pages, best-seller: No, film: No, saga: Tillerman Cycle, followed by: nan, preceded by: Dicey's Song\n",
      "379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "380\n",
      "Found 307 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "381\n",
      "Found 342 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "382\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: Song of Solomon, preceded by: Beloved\n",
      "383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 310 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "384\n",
      "Found 257 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "385\n",
      "Found 420 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "386\n",
      "Found 320 pages, best-seller: No, film: No, saga: Kay Scarpetta, followed by: Cruel and Unusual, preceded by: From Potter's Field\n",
      "387\n",
      "Found 479 pages, best-seller: No, film: No, saga: Buffy the Vampire Slayer, followed by: Apocalypse Memories, preceded by: Spark and Burn\n",
      "388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 496 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 343 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "391\n",
      "Found 487 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 415 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "393\n",
      "Found 418 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 740 pages, best-seller: Yes, film: Yes, saga: John Clark, followed by: Executive Orders, preceded by: The Bear and the Dragon\n",
      "395\n",
      "Found 432544 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Path of the Assassin\n",
      "396\n",
      "Found 400 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "397\n",
      "Found 376 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "398\n",
      "Found 384 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "399\n",
      "Found 544 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "400\n",
      "Found 99045815322 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "402\n",
      "Found 1168 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "403\n",
      "Found 901 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "404\n",
      "Found 158 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "405\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "406\n",
      "Found 296 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "407\n",
      "Found 160 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "408\n",
      "Found 182 pages, best-seller: No, film: Yes, saga: Inspector Wexford#1, followed by: nan, preceded by: A New Lease of Death\n",
      "409\n",
      "Found 403 pages, best-seller: No, film: No, saga: No, followed by: None, preceded by: Transfer of Power\n",
      "410\n",
      "Found 168 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "411\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: Dune, followed by: Dune, preceded by: Children of Dune\n",
      "412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 496 pages, best-seller: No, film: No, saga: Lockwood & Co., followed by: The Screaming Staircase, preceded by: The Hollow Boy\n",
      "413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 177140 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "414\n",
      "Found 159 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "415\n",
      "Found 156 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "416\n",
      "Found 367 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "417\n",
      "Found 365 pages, best-seller: No, film: Yes, saga: No, followed by: Setting Free the Bears, preceded by: The 158-Pound Marriage\n",
      "418\n",
      "Found 247 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 pages, best-seller: No, film: No, saga: Spenser, followed by: Hugger Mugger, preceded by: Widow's Walk\n",
      "420\n",
      "Found 351 pages, best-seller: No, film: Yes, saga: Pastwatch series, followed by: nan, preceded by: Pastwatch: The Flood\n",
      "421\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "422\n",
      "Found 307 pages, best-seller: No, film: No, saga: No, followed by: Blackberry Wine, preceded by: nan\n",
      "423\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "424\n",
      "Found 3501 pages, best-seller: No, film: No, saga: Lord Peter Wimsey, followed by: Murder Must Advertise, preceded by: Gaudy Night\n",
      "425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "426\n",
      "Found 414 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "427\n",
      "Found 639 pages, best-seller: Yes, film: Yes, saga: John Clark, followed by: The Sum of All Fears, preceded by: Debt of Honor\n",
      "428\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Shirley\n",
      "429\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "430\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "431\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "432\n",
      "Found 409 pages, best-seller: No, film: Yes, saga: Anno Draculaseries, followed by: nan, preceded by: The Bloody Red Baron\n",
      "433\n",
      "Found 160 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "434\n",
      "Found 310 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: The Lord of the Rings\n",
      "435\n",
      "Found 120 pages, best-seller: No, film: Yes, saga: Fudge series, followed by: nan, preceded by: Otherwise Known as Sheila the Great\n",
      "436\n",
      "Found 247 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Shadow in Hawthorn Bay\n",
      "437\n",
      "Found 304 pages, best-seller: No, film: Yes, saga: No, followed by: Mother Night, preceded by: God Bless You, Mr. Rosewater\n",
      "438\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "439\n",
      "Found 479 pages, best-seller: No, film: No, saga: No, followed by: The Sicilian, preceded by: The Last Don\n",
      "440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 465 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "441\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "442\n",
      "Found 565 pages, best-seller: Yes, film: No, saga: Cemetery of Forgotten Books, followed by: nan, preceded by: The Angel's Game\n",
      "443\n",
      "Found 176 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 pages, best-seller: No, film: No, saga: No, followed by: The Bluest Eye, preceded by: Song of Solomon\n",
      "445\n",
      "Found 365 pages, best-seller: No, film: No, saga: Parableduology, followed by: Parable of the Sower, preceded by: nan\n",
      "446\n",
      "Found 371 pages, best-seller: No, film: No, saga: No, followed by: Life After God, preceded by: Polaroids from the Dead\n",
      "447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11381 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "449\n",
      "Found 201 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "450\n",
      "Found 184 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "452\n",
      "Found 704 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Falls the Shadow\n",
      "453\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "454\n",
      "Found 6581 pages, best-seller: No, film: Yes, saga: TwilightSaga, followed by: Breaking Dawn, preceded by: nan\n",
      "455\n",
      "Found 346 pages, best-seller: No, film: Yes, saga: No, followed by: By the Rivers of Babylon, preceded by: Cathedral (DeMille)Orbit (Block)\n",
      "456\n",
      "Found 367 pages, best-seller: No, film: No, saga: Kay Scarpetta, followed by: Cause of Death, preceded by: Point of Origin\n",
      "457\n",
      "Found 218 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "458\n",
      "Found 496 pages, best-seller: No, film: No, saga: The Matarese Dynasty, followed by: The Matarese Circle, preceded by: nan\n",
      "459\n",
      "Found 352338 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Bull from the Sea\n",
      "460\n",
      "Found 701 pages, best-seller: No, film: No, saga: Kushiel's Legacy, followed by: nan, preceded by: Kushiel's Chosen\n",
      "461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "462\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "464\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 448432 pages, best-seller: No, film: Yes, saga: No, followed by: One L, preceded by: The Burden of Proof\n",
      "466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Jack McEvoy #1, followed by: nan, preceded by: nan\n",
      "467\n",
      "Found 357 pages, best-seller: No, film: No, saga: Amelia Peabody seriesmysteries, followed by: Crocodile on the Sandbank, preceded by: The Mummy Case\n",
      "468\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 278 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "470\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Sherlock Holmes, followed by: The Memoirs of Sherlock Holmes, preceded by: The Return of Sherlock Holmes\n",
      "471\n",
      "Found 2401 pages, best-seller: No, film: No, saga: Chrestomanci, followed by: Witch Week, preceded by: Mixed Magics\n",
      "472\n",
      "Found 37523 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "473\n",
      "Found 214 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 308 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "475\n",
      "Found 400 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "476\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 625 pages, best-seller: No, film: Yes, saga: Jack Sawyer Trilogy, followed by: The Talisman, preceded by: TBA\n",
      "478\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "479\n",
      "Found 223 pages, best-seller: No, film: No, saga: Empireseries, followed by: The Currents of Space, preceded by: \"Blind Alley\"\n",
      "480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 293 pages, best-seller: No, film: Yes, saga: No, followed by: Dandelion Wine, preceded by: The Halloween Tree\n",
      "482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 148 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1241993 pages, best-seller: No, film: No, saga: Waverley Novels;Tales of My Landlord[1st series], followed by: The Antiquary, preceded by: The Tale of Old Mortality\n",
      "484\n",
      "Found 502 pages, best-seller: No, film: No, saga: Earth's Children, followed by: The Clan of the Cave Bear, preceded by: The Mammoth Hunters\n",
      "485\n",
      "Found 3451 pages, best-seller: No, film: No, saga: Ireta[1], followed by: The Death of Sleep, preceded by: nan\n",
      "486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6901 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "487\n",
      "Found 284298 pages, best-seller: No, film: No, saga: The Borrowers, followed by: The Borrowers Aloft, preceded by: nan\n",
      "488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 461 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2741 pages, best-seller: No, film: No, saga: Annals of the Western Shore, followed by: nan, preceded by: Voices\n",
      "490\n",
      "Found 341 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "491\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: The Beautiful and Damned(1922), preceded by: Tender Is the Night (1934)\n",
      "492\n",
      "Found 56 pages, best-seller: No, film: Yes, saga: Harry Potter, followed by: nan, preceded by: nan\n",
      "493\n",
      "Found 128 pages, best-seller: No, film: Yes, saga: Harry Potter, followed by: nan, preceded by: nan\n",
      "494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "495\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Sketch Book, followed by: nan, preceded by: nan\n",
      "496\n",
      "Found 252 pages, best-seller: No, film: No, saga: The Dark Is Rising, followed by: nan, preceded by: The Dark Is Rising\n",
      "497\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "498\n",
      "Found 245 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "499\n",
      "Found 759 pages, best-seller: No, film: Yes, saga: Little Women, followed by: nan, preceded by: Little Men\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 523 pages, best-seller: No, film: Yes, saga: Bourne Trilogy, followed by: nan, preceded by: The Bourne Supremacy\n",
      "503\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Paradise Regained\n",
      "504\n",
      "Found 640 pages, best-seller: No, film: No, saga: Jack Ryan, followed by: The Bear and the Dragon, preceded by: The Teeth of the Tiger\n",
      "505\n",
      "Found 529 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "506\n",
      "Found 512624 pages, best-seller: No, film: No, saga: No, followed by: Rebecca, preceded by: nan\n",
      "507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 368 pages, best-seller: No, film: No, saga: Tim Rackley Novels, followed by: The Kill Clause, preceded by: Troubleshooter\n",
      "508\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Heidi Grows Up\n",
      "509\n",
      "Found 3111932637661 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "510\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "511\n",
      "Found 329 pages, best-seller: No, film: No, saga: Arkady Renko# 4, followed by: Red Square, preceded by: Wolves Eat Dogs\n",
      "512\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "513\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Giver Quartet, followed by: nan, preceded by: Gathering Blue\n",
      "514\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "515\n",
      "Found 606 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "516\n",
      "Found 178 pages, best-seller: No, film: Yes, saga: Fudge series, followed by: Otherwise Known as Sheila the Great, preceded by: Fudge-A-Mania\n",
      "517\n",
      "Found 368465 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "518\n",
      "Found 328 pages, best-seller: Yes, film: Yes, saga: No, followed by: Animal Farm, preceded by: nan\n",
      "519\n",
      "Found 168 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "520\n",
      "Found 1771 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Zia\n",
      "521\n",
      "Found 192 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "522\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Five Children[1](a.k.a.Psammead) series[2], followed by: nan, preceded by: The Phoenix and the Carpet\n",
      "523\n",
      "Found 325 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "524\n",
      "Found 365 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 253 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: About a Boy\n",
      "526\n",
      "Found 400 pages, best-seller: No, film: No, saga: Nightrunner, followed by: Shadows Return, preceded by: Casket of Souls\n",
      "527\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "528\n",
      "Found 247 pages, best-seller: No, film: Yes, saga: Inspector Pitt Mysteries, followed by: nan, preceded by: Callander Square\n",
      "529\n",
      "Found 4831 pages, best-seller: No, film: No, saga: Lord Peter Wimsey, followed by: The Nine Tailors, preceded by: Busman's Honeymoon\n",
      "530\n",
      "Found 368 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "531\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "532\n",
      "Found 416410 pages, best-seller: No, film: Yes, saga: The Godfather, followed by: The Godfather, preceded by: The Godfather Returns\n",
      "533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "534\n",
      "Found 278 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Kindness of Women\n",
      "535\n",
      "Found 709 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: The Whalestoe Letters\n",
      "536\n",
      "Found 867 pages, best-seller: No, film: Yes, saga: Bas-Lagnovels, followed by: nan, preceded by: The Scar\n",
      "537\n",
      "Found 677 pages, best-seller: No, film: Yes, saga: No, followed by: Plum Island, preceded by: Night Fall\n",
      "538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 265 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Riding the Rap\n",
      "539\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: The Chronicles of Prydain, followed by: Taran Wanderer, preceded by: nan\n",
      "540\n",
      "Found 355 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "542\n",
      "Found 401 pages, best-seller: No, film: Yes, saga: No, followed by: Jack Maggs, preceded by: My Life as a Fake\n",
      "543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "544\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "545\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "546\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "547\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "548\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "549\n",
      "Found 393 pages, best-seller: No, film: No, saga: Harry Bosch, #6, followed by: Trunk Music, preceded by: A Darkness More Than Night\n",
      "550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 319 pages, best-seller: No, film: Yes, saga: No, followed by: Double Whammy, preceded by: Native Tongue\n",
      "551\n",
      "Found 263 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "552\n",
      "Found 480 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 365 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "554\n",
      "Found 272 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "555\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "556\n",
      "Found 2371 pages, best-seller: No, film: No, saga: Elvis Cole series, followed by: nan, preceded by: Stalking the Angel\n",
      "557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 131 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Oliver's Story (novel)\n",
      "558\n",
      "Found 31 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 576 pages, best-seller: No, film: Yes, saga: No, followed by: End of Watch, preceded by: If It Bleeds (novella)\n",
      "560\n",
      "Found 368 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "561\n",
      "Found 512 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 512 pages, best-seller: Yes, film: No, saga: No, followed by: When Christ and His Saints Slept, preceded by: Devil's Brood\n",
      "563\n",
      "Found 247 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "564\n",
      "Found 480 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "565\n",
      "Found 1601954 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "566\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "567\n",
      "Found 250 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "568\n",
      "Found 192 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: Shampoo Planet\n",
      "569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 439 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Up_in_the_Air_(novel) (2001)\n",
      "571\n",
      "Found 326 pages, best-seller: No, film: No, saga: Mary Russell, followed by: The Beekeeper's Apprentice, preceded by: A Letter of Mary\n",
      "572\n",
      "Found 210 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 211 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 597 pages, best-seller: No, film: Yes, saga: No, followed by: Rising Sun, preceded by: The Lost World\n",
      "575\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Firefox Down\n",
      "576\n",
      "Found 568 pages, best-seller: No, film: Yes, saga: No, followed by: Strong Motion, preceded by: Freedom\n",
      "577\n",
      "Found 348 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "578\n",
      "Found 224 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Divine Secrets of the Ya-Ya Sisterhood\n",
      "579\n",
      "Found 1225 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Decembrists (Abandoned and Unfinished)\n",
      "580\n",
      "Found 512 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "581\n",
      "Found 403 pages, best-seller: No, film: No, saga: Gabriel Allonseries, followed by: The Confessor, preceded by: Prince of Fire\n",
      "582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 386400 pages, best-seller: No, film: No, saga: Gabriel Allon series, followed by: The Kill Artist, preceded by: The Confessor\n",
      "583\n",
      "Found 273 pages, best-seller: No, film: No, saga: Amelia Peabody seriesmysteries, followed by: nan, preceded by: The Curse of the Pharaohs\n",
      "584\n",
      "Found 484 pages, best-seller: No, film: No, saga: Great War, followed by: The Great War: American Front, preceded by: The Great War: Breakthroughs\n",
      "585\n",
      "Found nan pages, best-seller: No, film: No, saga: Southern Victory, followed by: nan, preceded by: The Great War: American Front (Great War)\n",
      "586\n",
      "Found 372 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "587\n",
      "Found 359 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "588\n",
      "Found 319 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "589\n",
      "Found 325 pages, best-seller: No, film: No, saga: Incarnations of Immortality, followed by: nan, preceded by: Bearing an Hourglass\n",
      "590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 426 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "591\n",
      "Found 32922 pages, best-seller: No, film: No, saga: No, followed by: The Source of Magic, preceded by: Centaur Aisle\n",
      "592\n",
      "Found 32627 pages, best-seller: No, film: No, saga: No, followed by: A Spell for Chameleon, preceded by: Castle Roogna\n",
      "593\n",
      "Found 301 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "594\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "595\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 278 pages, best-seller: No, film: Yes, saga: No, followed by: High Fidelity, preceded by: How to Be Good\n",
      "597\n",
      "Found 287 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 850 pages, best-seller: No, film: No, saga: Outlanderseries, followed by: nan, preceded by: Dragonfly in Amber\n",
      "599\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "600\n",
      "Found 190 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "601\n",
      "Found 184 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "602\n",
      "Found 576 pages, best-seller: No, film: Yes, saga: Original Shannara Trilogy, followed by: The Sword of Shannara, preceded by: The Wishsong of Shannara\n",
      "603\n",
      "Found 184 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "604\n",
      "Found 243 pages, best-seller: No, film: Yes, saga: No, followed by: Easy Go, preceded by: Zero Cool\n",
      "605\n",
      "Found 2881 pages, best-seller: No, film: No, saga: Lord Peter Wimsey, followed by: The Unpleasantness at the Bellona Club, preceded by: The Five Red Herrings\n",
      "606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 154 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "607\n",
      "Found 436 pages, best-seller: No, film: No, saga: Temperance Brennan, followed by: Déjà Dead, preceded by: Deadly Decisions\n",
      "608\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "609\n",
      "Found 32 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Science Verse\n",
      "610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5121 pages, best-seller: No, film: No, saga: Jack Reacher, followed by: Tripwire, preceded by: Echo Burning\n",
      "611\n",
      "Found 200 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: The Road Back\n",
      "612\n",
      "Found 386 pages, best-seller: No, film: No, saga: No, followed by: Chocolat, preceded by: Five quarters of the orange\n",
      "613\n",
      "Found 444 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 420 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1601954 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "618\n",
      "Found 234 pages, best-seller: No, film: No, saga: Doctor Whobook:Past Doctor Adventures, followed by: Heart of TARDIS, preceded by: Imperial Moon\n",
      "619\n",
      "Found 454 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "620\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5121 pages, best-seller: No, film: No, saga: Jack Reacher, followed by: Tripwire, preceded by: Echo Burning\n",
      "622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 392 pages, best-seller: No, film: No, saga: Tunnels, followed by: Spiral, preceded by: nan\n",
      "623\n",
      "Found 192 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "624\n",
      "Found 319 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "625\n",
      "Found 224 pages, best-seller: No, film: Yes, saga: Robotseries, followed by: \"Mother Earth\", preceded by: The Naked Sun\n",
      "626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 393 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Crime\n",
      "627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 323 pages, best-seller: No, film: Yes, saga: No, followed by: Crystal(1987), preceded by: Scorpions (1990)\n",
      "628\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "630\n",
      "Found 3121 pages, best-seller: No, film: Yes, saga: No, followed by: The Secret of Chimneys, preceded by: The Big Four\n",
      "631\n",
      "Found 400 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "632\n",
      "Found 107 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "634\n",
      "Found 195 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "635\n",
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "636\n",
      "Found 195 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: A Child's History of England, preceded by: Little Dorrit\n",
      "639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 346 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Harlan's Race (1994)\n",
      "640\n",
      "Found 242 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "641\n",
      "Found 608 pages, best-seller: No, film: Yes, saga: No, followed by: Evening Class, preceded by: Scarlet Feather\n",
      "642\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Mixture As Before, preceded by: The Hour Before Dawn\n",
      "643\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Mrs Dalloway, preceded by: Orlando: A Biography\n",
      "644\n",
      "Found 252 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "645\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "646\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Coyote Blue\n",
      "647\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "648\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "649\n",
      "Found 309 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 394 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Lollipop Shoes\n",
      "651\n",
      "Found 928 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "652\n",
      "Found 401 pages, best-seller: No, film: Yes, saga: No, followed by: The World According to Garp, preceded by: The Cider House Rules\n",
      "653\n",
      "Found 304 pages, best-seller: No, film: Yes, saga: Bridge trilogy, followed by: Virtual Light, preceded by: All Tomorrow's Parties\n",
      "654\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "655\n",
      "Found 487 pages, best-seller: No, film: No, saga: Churchill, followed by: nan, preceded by: Never Surrender[4]\n",
      "656\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 384 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "658\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "659\n",
      "Found 558 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "660\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "661\n",
      "Found nan pages, best-seller: No, film: No, saga: James Bond, followed by: nan, preceded by: nan\n",
      "662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 679 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "664\n",
      "Found 416 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "665\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "666\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "667\n",
      "Found 208 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 373 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "669\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "670\n",
      "Found 504 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "671\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Sketches by Boz, preceded by: Oliver Twist\n",
      "672\n",
      "Found 384 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "673\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 283 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Promise\n",
      "675\n",
      "Found 249 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 169 pages, best-seller: Yes, film: Yes, saga: Stargirl, followed by: nan, preceded by: Love, Stargirl\n",
      "677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "678\n",
      "Found 416 pages, best-seller: No, film: No, saga: Kay Scarpetta, followed by: The Body Farm, preceded by: Cause of Death\n",
      "679\n",
      "Found 384 pages, best-seller: No, film: No, saga: George Smiley/The Quest for Karla, followed by: The Honourable Schoolboy, preceded by: The Little Drummer Girl\n",
      "680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 356 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "681\n",
      "Found 3361 pages, best-seller: Yes, film: No, saga: No, followed by: Singin' and Swingin' and Gettin' Merry Like Christmas, preceded by: All God's Children Need Traveling Shoes\n",
      "682\n",
      "Found 560 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "683\n",
      "Found 536 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 pages, best-seller: No, film: Yes, saga: No, followed by: Diary, preceded by: Rant\n",
      "685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "688\n",
      "Found 3011 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "689\n",
      "Found 245 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 184 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "691\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "692\n",
      "Found 262 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Heart of Aztlan\n",
      "693\n",
      "Found 472 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "695\n",
      "Found 369 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "696\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Mortal Fear, preceded by: Harmful Intent\n",
      "697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256192 pages, best-seller: No, film: No, saga: Aurelio Zenseries, #8, followed by: Blood Rain, preceded by: Medusa\n",
      "698\n",
      "Found nan pages, best-seller: No, film: No, saga: Century Trilogy, followed by: Fall of Giants,Winter of the World, preceded by: nan\n",
      "699\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "700\n",
      "Found 282 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 446 pages, best-seller: Yes, film: Yes, saga: Odd Thomas, followed by: In Odd We Trust, preceded by: Forever Odd\n",
      "703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 368 pages, best-seller: Yes, film: Yes, saga: No, followed by: Survive the Night, preceded by: nan\n",
      "704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 766879 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Twelve\n",
      "705\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "706\n",
      "Found 689 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "708\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "709\n",
      "Found 431 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "710\n",
      "Found 275 pages, best-seller: No, film: Yes, saga: Caddie Woodlawn, followed by: nan, preceded by: Magical Melons\n",
      "711\n",
      "Found 533 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "712\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "713\n",
      "Found 294 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Blow Your House Down\n",
      "715\n",
      "Found 788 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: Lady of the Light\n",
      "716\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 159 pages, best-seller: Yes, film: Yes, saga: Collection Blanche, followed by: nan, preceded by: nan\n",
      "718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 309 pages, best-seller: No, film: No, saga: Dragonriders of Pern, followed by: nan, preceded by: Dragonquest\n",
      "719\n",
      "Found 192 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "720\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: To Love and Be Wise (1950), preceded by: The Singing Sands (1952)\n",
      "721\n",
      "Found 185 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "722\n",
      "Found 403 pages, best-seller: No, film: No, saga: No, followed by: The Laws of Our Fathers, preceded by: Reversible Errors\n",
      "723\n",
      "Found 2231 pages, best-seller: No, film: Yes, saga: Earthsea, followed by: The Tombs of Atuan, preceded by: Tehanu\n",
      "724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 480 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "725\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 464 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Burndive\n",
      "727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 534 pages, best-seller: No, film: No, saga: Fault Lines series, followed by: Last Call, preceded by: Earthquake Weather\n",
      "728\n",
      "Found 236 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "729\n",
      "Found 1591802 pages, best-seller: No, film: Yes, saga: The Borrowers, followed by: nan, preceded by: The Borrowers Afield\n",
      "730\n",
      "Found 192 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "731\n",
      "Found 161 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "732\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: Song of the Trees, preceded by: Let the Circle Be Unbroken\n",
      "733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: The Fire (novel)\n",
      "734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 324 pages, best-seller: No, film: Yes, saga: No, followed by: Tar Baby, preceded by: Jazz\n",
      "735\n",
      "Found 326 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 pages, best-seller: No, film: No, saga: Lincoln Rhyme series, followed by: The Coffin Dancer, preceded by: The Stone Monkey\n",
      "737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 322 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "738\n",
      "Found 415 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "739\n",
      "Found 246 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "740\n",
      "Found 245 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "741\n",
      "Found 292 pages, best-seller: No, film: No, saga: Marcus Didius Falco, followed by: Two for the Lions, preceded by: Ode to a Banker\n",
      "742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "743\n",
      "Found 434 pages, best-seller: No, film: No, saga: Oxford Time Travel, #2, followed by: Doomsday Book, preceded by: Blackout/All Clear\n",
      "744\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "745\n",
      "Found 607 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "746\n",
      "Found 416 pages, best-seller: No, film: Yes, saga: The Lord of the Rings, followed by: The Two Towers, preceded by: nan\n",
      "747\n",
      "Found 352 pages, best-seller: No, film: Yes, saga: The Lord of the Rings, followed by: The Fellowship of the Ring, preceded by: The Return of the King\n",
      "748\n",
      "Found 423 pages, best-seller: No, film: Yes, saga: The Lord of the Rings, followed by: nan, preceded by: The Two Towers\n",
      "749\n",
      "Found 290 pages, best-seller: Yes, film: No, saga: Alphabet Mysteries, followed by: \"K\" Is for Killer, preceded by: \"M\" Is for Malice\n",
      "750\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "751\n",
      "Found 333400 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "752\n",
      "Found 256690483 pages, best-seller: No, film: Yes, saga: Rama series, followed by: nan, preceded by: Rama II\n",
      "753\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "754\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "755\n",
      "Found 352 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 158 pages, best-seller: No, film: No, saga: No, followed by: The Lynchers, preceded by: Sent for You Yesterday\n",
      "757\n",
      "Found 440 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "758\n",
      "Found 598 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Memories of Midnight\n",
      "759\n",
      "Found 170 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3201 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 317 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "762\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: Death in the Clouds, preceded by: Murder in Mesopotamia\n",
      "763\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "764\n",
      "Found 629 pages, best-seller: No, film: No, saga: No, followed by: The Alienist(1994), preceded by: Surrender, New York\n",
      "765\n",
      "Found 376 pages, best-seller: No, film: Yes, saga: No, followed by: Surfacing, preceded by: Life Before Man\n",
      "766\n",
      "Found 281 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Surfacing\n",
      "767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "768\n",
      "Found 291 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "769\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "770\n",
      "Found 176 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "771\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "772\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "773\n",
      "Found 278 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "774\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "775\n",
      "Found 286 pages, best-seller: Yes, film: No, saga: Alphabet Mysteries, followed by: \"H\" Is for Homicide, preceded by: \"J\" Is for Judgment\n",
      "776\n",
      "Found 544 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "778\n",
      "Found 228 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "779\n",
      "Found 127 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Green Witch\n",
      "780\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 pages, best-seller: Yes, film: No, saga: Native Tongue, followed by: nan, preceded by: The Judas Rose\n",
      "782\n",
      "Found 134 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 344 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: PornoMarabou Stork Nightmares\n",
      "784\n",
      "Found 380 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "785\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: A Wind in the Door\n",
      "786\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: John Thomas and Lady Jane(1927), preceded by: nan\n",
      "787\n",
      "Found 201 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "788\n",
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: In the Skin of a Lion, preceded by: nan\n",
      "789\n",
      "Found 336 pages, best-seller: No, film: Yes, saga: No, followed by: A Widow for One Year, preceded by: Until I Find You\n",
      "790\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "791\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "792\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "793\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Vampire Chronicles, preceded by: nan\n",
      "794\n",
      "Found 377 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 214119 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "796\n",
      "Found 343 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 562 pages, best-seller: No, film: No, saga: Blue Rose Trilogy, followed by: None, preceded by: Mystery\n",
      "798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 518 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "799\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 656 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "803\n",
      "Found nan pages, best-seller: No, film: No, saga: Inspector Alan Banks, #10, followed by: Dead Right, preceded by: Cold Is the Grave\n",
      "804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "805\n",
      "Found 533 pages, best-seller: No, film: No, saga: George Smiley/The Quest for Karla, followed by: Tinker Tailor Soldier Spy, preceded by: Smiley's People\n",
      "806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 pages, best-seller: Yes, film: Yes, saga: No, followed by: Into the Wild, preceded by: Under the Banner of Heaven\n",
      "807\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: Gather Together in My Name\n",
      "808\n",
      "Found 247 pages, best-seller: Yes, film: Yes, saga: No, followed by: The Andromeda Strain, preceded by: The Great Train Robbery\n",
      "809\n",
      "Found 280 pages, best-seller: No, film: Yes, saga: No, followed by: History of a Six Weeks' Tour, preceded by: Valperga (roman)\n",
      "810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Heinlein juveniles, followed by: Starman Jones, preceded by: Tunnel in the Sky\n",
      "811\n",
      "Found 368 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "812\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "813\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 365 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "815\n",
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: Generation X: Tales for an Accelerated Culture, preceded by: Life After God\n",
      "816\n",
      "Found 387 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "817\n",
      "Found 412 pages, best-seller: No, film: No, saga: No, followed by: Memories of Midnight, preceded by: The Stars Shine Down\n",
      "818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 302 pages, best-seller: No, film: No, saga: The State, followed by: The Integral Trees, preceded by: \"The Kiteman\"\n",
      "820\n",
      "Found 289 pages, best-seller: No, film: No, saga: No, followed by: Evil Under the Sun, preceded by: The Body in the Library\n",
      "821\n",
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Widows of Eastwick\n",
      "822\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "823\n",
      "Found 432 pages, best-seller: No, film: Yes, saga: Left Behind Series, followed by: The Remnant, preceded by: Glorious Appearing\n",
      "824\n",
      "Found 448 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 480 pages, best-seller: No, film: Yes, saga: Moonlight Bay Trilogy, followed by: Fear Nothing, preceded by: Ride the Storm\n",
      "826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "827\n",
      "Found 283288 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Heinlein juveniles, followed by: Starman Jones, preceded by: Tunnel in the Sky\n",
      "829\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 278352 pages, best-seller: No, film: No, saga: No, followed by: 2nd Chance, preceded by: 4th of July\n",
      "831\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Island of the Sequined Love Nun, preceded by: Lamb\n",
      "832\n",
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "833\n",
      "Found 480 pages, best-seller: Yes, film: No, saga: The Campus, followed by: The Bear and the Dragon, preceded by: Dead or Alive\n",
      "834\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "835\n",
      "Found 21812482288 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: \"Two Hearts\"\n",
      "836\n",
      "Found 662 pages, best-seller: No, film: No, saga: The 'Egyptian' novels, followed by: nan, preceded by: The Seventh Scroll\n",
      "837\n",
      "Found 241 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "838\n",
      "Found 262 pages, best-seller: No, film: No, saga: Tales of the City, followed by: Significant Others, preceded by: Michael Tolliver Lives\n",
      "839\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "840\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "842\n",
      "Found 5762001 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "843\n",
      "Found 608 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "844\n",
      "Found 678 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 368 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "846\n",
      "Found 296 pages, best-seller: No, film: No, saga: Nero Wolfe, followed by: Too Many Cooks, preceded by: Over My Dead Body\n",
      "847\n",
      "Found 251 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: The Wilds1998 in literature, preceded by: Come Out Tonight 1999 in literature\n",
      "849\n",
      "Found 2982001 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "850\n",
      "Found 465 pages, best-seller: No, film: No, saga: Krondor's Sons, followed by: Prince of the Blood, preceded by: nan\n",
      "851\n",
      "Found 608 pages, best-seller: No, film: Yes, saga: Earl Swagger, followed by: Hot Springs, preceded by: Havana\n",
      "852\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 335 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "855\n",
      "Found 424 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "856\n",
      "Found 400 pages, best-seller: No, film: Yes, saga: A Myron Bolitar Novel, followed by: Promise Me, preceded by: Live Wire\n",
      "857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "858\n",
      "Found 2161 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: The Book of Dust, followed by: nan, preceded by: nan\n",
      "860\n",
      "Found 336 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 pages, best-seller: No, film: No, saga: Kay Scarpetta, followed by: Postmortem, preceded by: All That Remains\n",
      "862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 190 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10371024 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: ScarlettRhett Butler's People\n",
      "864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 303 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "865\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "866\n",
      "Found 464 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "867\n",
      "Found 358432 pages, best-seller: No, film: No, saga: No, followed by: Transfer of Power, preceded by: Separation of Power\n",
      "868\n",
      "Found 673 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "869\n",
      "Found 510 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "870\n",
      "Found 176 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "871\n",
      "Found 320 pages, best-seller: No, film: No, saga: Acorna Universe[1], followed by: Acorna's Quest, preceded by: Acorna's World\n",
      "872\n",
      "Found 496 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "873\n",
      "Found 445 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "874\n",
      "Found 434528 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "875\n",
      "Found 322 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "876\n",
      "Found 332 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 420 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "878\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: The Great Train Robbery, preceded by: Congo\n",
      "879\n",
      "Found 981 pages, best-seller: No, film: Yes, saga: Bunnicula, followed by: nan, preceded by: nan\n",
      "880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "881\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Bird Girl and the Man Who Followed the Sun (1996)\n",
      "882\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "883\n",
      "Found 257 pages, best-seller: Yes, film: Yes, saga: No, followed by: The Tao of Pooh, preceded by: nan\n",
      "884\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "885\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "886\n",
      "Found 336 pages, best-seller: Yes, film: Yes, saga: No, followed by: The Sealed Letter, preceded by: nan\n",
      "887\n",
      "Found 434 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 369 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "889\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 370 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "891\n",
      "Found 343 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "892\n",
      "Found 222101941 pages, best-seller: No, film: No, saga: Gideon Fell, followed by: The Arabian Nights Murder(1936), preceded by: The Crooked Hinge (1938)\n",
      "893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 241272 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 211 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "896\n",
      "Found 259 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "897\n",
      "Found 296 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Secret Adversary\n",
      "898\n",
      "Found 363 pages, best-seller: No, film: No, saga: No, followed by: The Best Laid Plans, preceded by: The Sky Is Falling\n",
      "899\n",
      "Found 180 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Pinky Pye\n",
      "900\n",
      "Found 293 pages, best-seller: No, film: Yes, saga: No, followed by: Sea Glass, preceded by: nan\n",
      "901\n",
      "Found 279 pages, best-seller: No, film: No, saga: No, followed by: Jericho Road, preceded by: Woman in the Woods\n",
      "902\n",
      "Found 864 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "903\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "904\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "905\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "906\n",
      "Found 301 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Mexico Set\n",
      "907\n",
      "Found 468 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 116 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Sour Land\n",
      "910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 475 pages, best-seller: No, film: Yes, saga: Inspector Rebus, followed by: Set in Darkness, preceded by: Resurrection Men\n",
      "911\n",
      "Found 608 pages, best-seller: Yes, film: Yes, saga: The Second L.A. Quartet, followed by: Perfidia, preceded by: nan\n",
      "912\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "914\n",
      "Found 690 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: A Man in Full\n",
      "915\n",
      "Found 291 pages, best-seller: No, film: No, saga: Amelia Peabody seriesmysteries, followed by: The Mummy Case, preceded by: Deeds of the Disturber\n",
      "916\n",
      "Found 544 pages, best-seller: Yes, film: Yes, saga: Millennium, followed by: The Girl Who Kicked the Hornets' Nest, preceded by: The Girl Who Takes an Eye for an Eye\n",
      "917\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "918\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "919\n",
      "Found 352352 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "920\n",
      "Found 304 pages, best-seller: No, film: No, saga: Time Quintet, followed by: A Wind in the Door, preceded by: Many Waters\n",
      "921\n",
      "Found 523 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 260 pages, best-seller: No, film: Yes, saga: James Bond, followed by: On Her Majesty's Secret Service, preceded by: The Man with the Golden Gun\n",
      "923\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "924\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: The Reef, preceded by: nan\n",
      "925\n",
      "Found 400 pages, best-seller: No, film: No, saga: No, followed by: The War of Don Emmanuel's Nether Parts&Señor Vivo and the Coca Lord, preceded by: nan\n",
      "926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: Roderick Alleyn, followed by: Hand in Glove, preceded by: Death at the Dolphin\n",
      "927\n",
      "Found 400 pages, best-seller: No, film: No, saga: Stone Barrington, followed by: nan, preceded by: Dirt (novel)\n",
      "928\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: Polaroids from the Dead, preceded by: Miss Wyoming\n",
      "930\n",
      "Found 465 pages, best-seller: No, film: No, saga: No, followed by: The Unlikely Spy, preceded by: The Marching Season\n",
      "931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "932\n",
      "Found 342 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "933\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 266 pages, best-seller: No, film: No, saga: Anita Blake: Vampire Hunter, followed by: nan, preceded by: The Laughing Corpse\n",
      "935\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Watermelon, preceded by: Rachel's Holiday\n",
      "936\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 242 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "938\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "939\n",
      "Found 265 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Rabbit Redux\n",
      "940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "941\n",
      "Found 208 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "942\n",
      "Found 566 pages, best-seller: No, film: Yes, saga: Eight Worlds, followed by: nan, preceded by: The Golden Globe\n",
      "943\n",
      "Found 690 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "947\n",
      "Found 315 pages, best-seller: No, film: Yes, saga: No, followed by: Seawitch, preceded by: Athabasca\n",
      "948\n",
      "Found 1042 pages, best-seller: No, film: No, saga: War and Remembrance, followed by: nan, preceded by: nan\n",
      "949\n",
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "950\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: 'Raising Demons\n",
      "951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "952\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 248 pages, best-seller: No, film: Yes, saga: No, followed by: N/A. First work by the author., preceded by: In a Glass House\n",
      "954\n",
      "Found 448 pages, best-seller: No, film: No, saga: Darwin series, followed by: nan, preceded by: Darwin's Children\n",
      "955\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 262 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "957\n",
      "Found 357 pages, best-seller: No, film: No, saga: The Culture, followed by: Inversions, preceded by: Matter\n",
      "958\n",
      "Found 656 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "959\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Hammerheads\n",
      "960\n",
      "Found 480 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "961\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "962\n",
      "Found 340368 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "963\n",
      "Found 208224 pages, best-seller: No, film: No, saga: The Shakespeare Stealer trilogy, followed by: nan, preceded by: Shakespeare's Scribe\n",
      "964\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "965\n",
      "Found 176 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "966\n",
      "Found 528 pages, best-seller: No, film: Yes, saga: No, followed by: Illywhacker, preceded by: The Tax Inspector\n",
      "967\n",
      "Found 370 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 413 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "969\n",
      "Found 384 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "970\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 266 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "972\n",
      "Found 222 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 145 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 199 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "976\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "977\n",
      "Found 324 pages, best-seller: Yes, film: Yes, saga: Ender's Game series, followed by: nan, preceded by: Speaker for the Dead\n",
      "978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 311 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "979\n",
      "Found 220 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "980\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "981\n",
      "Found 352 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "982\n",
      "Found 597 pages, best-seller: Yes, film: Yes, saga: Bourne Trilogy, followed by: The Bourne Identity, preceded by: The Bourne Ultimatum\n",
      "983\n",
      "Found 194 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "984\n",
      "Found nan pages, best-seller: No, film: No, saga: Mike Hammer, followed by: Vengeance Is Mine, preceded by: The Big Kill\n",
      "985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 395 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "986\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "987\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Northanger Abbey, preceded by: nan\n",
      "988\n",
      "Found 365 pages, best-seller: No, film: No, saga: Parableduology, followed by: Parable of the Sower, preceded by: nan\n",
      "989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 309 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 185 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Psycho II\n",
      "992\n",
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Saint Leibowitz and the Wild Horse Woman\n",
      "993\n",
      "Found 325 pages, best-seller: No, film: No, saga: No, followed by: Ishmael, preceded by: My Ishmael\n",
      "994\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Beautiful and Damned (1922)\n",
      "995\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "996\n",
      "Found 352 pages, best-seller: No, film: No, saga: League of Peoples/Festina Ramos, followed by: nan, preceded by: Commitment Hour\n",
      "997\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "998\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "999\n",
      "Found 358 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1000\n",
      "Found 160111571 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: \"Screwtape Proposes a Toast\"\n",
      "1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 464 pages, best-seller: No, film: Yes, saga: Jason Bourne, followed by: The Bourne Ultimatum, preceded by: The Bourne Betrayal\n",
      "1002\n",
      "Found 344 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1003\n",
      "Found 305 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: Rage of Angels, preceded by: If Tomorrow Comes\n",
      "1005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 pages, best-seller: No, film: Yes, saga: No, followed by: Master of the Game, preceded by: Windmills of the Gods\n",
      "1006\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1007\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Farther Adventures of Robinson Crusoe\n",
      "1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 156 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1009\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1010\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1011\n",
      "Found 183 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 211 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1013\n",
      "Found 400 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1014\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1015\n",
      "Found 139 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1016\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1018\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Anne of Windy Poplars, preceded by: Anne of Ingleside\n",
      "1019\n",
      "Found 195186 pages, best-seller: No, film: Yes, saga: Brian's Saga, followed by: nan, preceded by: The River\n",
      "1020\n",
      "Found 271 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1021\n",
      "Found 224 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1022\n",
      "Found 467 pages, best-seller: No, film: No, saga: TheOriginalShannaraTrilogy, followed by: The Elfstones of Shannara, preceded by: The Scions of Shannara\n",
      "1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: All My Puny Sorrows, preceded by: Fight Night\n",
      "1024\n",
      "Found 270 pages, best-seller: No, film: No, saga: Spenser, followed by: Paper Doll, preceded by: Thin Air\n",
      "1025\n",
      "Found 223 pages, best-seller: No, film: No, saga: Spenser, followed by: Stardust, preceded by: Double Deuce\n",
      "1026\n",
      "Found 311384 pages, best-seller: No, film: No, saga: Spenser, followed by: Valediction, preceded by: Taming a Sea Horse\n",
      "1027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 336 pages, best-seller: No, film: No, saga: The Interdependency series, followed by: nan, preceded by: The Consuming Fire\n",
      "1028\n",
      "Found 262 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Storyteller (1981)\n",
      "1029\n",
      "Found 219 pages, best-seller: No, film: No, saga: Spenser, followed by: The Judas Goat, preceded by: Early Autumn\n",
      "1030\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Peasants\n",
      "1031\n",
      "Found 186 pages, best-seller: No, film: No, saga: Spenser, followed by: nan, preceded by: God Save the Child\n",
      "1032\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1034\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1035\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1036\n",
      "Found 371 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: \"The Only Meaning of the Oil-Wet Water\"\n",
      "1037\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1038\n",
      "Found 503 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1039\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1040\n",
      "Found 275 pages, best-seller: No, film: No, saga: Star Trek: The Next Generation#5, followed by: Survivors, preceded by: Power Hungry\n",
      "1041\n",
      "Found 372 pages, best-seller: No, film: No, saga: No, followed by: Orange Crush, preceded by: The Stingray Shuffle\n",
      "1042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1043\n",
      "Found 261 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1044\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Anne of Green Gables, followed by: nan, preceded by: Anne of Avonlea\n",
      "1045\n",
      "Found nan pages, best-seller: No, film: No, saga: Discworld15th novel – 2nd City Watch novel (3rd story), followed by: Lords and Ladies, preceded by: Soul Music\n",
      "1046\n",
      "Found 442502 pages, best-seller: No, film: No, saga: World of the Five Gods, followed by: nan, preceded by: Paladin of Souls\n",
      "1047\n",
      "Found 363 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 335 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1050\n",
      "Found 8601 pages, best-seller: No, film: No, saga: Inheritance Cycle, followed by: Brisingr, preceded by: nan\n",
      "1051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1052\n",
      "Found 256320 pages, best-seller: No, film: No, saga: Dirk Gently, followed by: Dirk Gently's Holistic Detective Agency, preceded by: The Salmon of Doubt\n",
      "1053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 309 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1054\n",
      "Found 366 pages, best-seller: No, film: Yes, saga: No, followed by: Mindbend, preceded by: Mortal Fear\n",
      "1055\n",
      "Found 288 pages, best-seller: No, film: No, saga: The Cat Whoseries, followed by: The Cat Who Sniffed Glue, preceded by: The Cat Who Talked to Ghosts\n",
      "1056\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1057\n",
      "Found 373 pages, best-seller: No, film: No, saga: The Talent Universe, followed by: Pegasus in Flight, preceded by: nan\n",
      "1058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 382 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: Golden Son\n",
      "1059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 342 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1060\n",
      "Found 276 pages, best-seller: No, film: Yes, saga: Aubrey–Maturin series, followed by: The Mauritius Command, preceded by: The Fortune of War\n",
      "1061\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: 2061: Odyssey Three, preceded by: nan\n",
      "1062\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1063\n",
      "Found 358 pages, best-seller: No, film: Yes, saga: Anno Draculaseries, followed by: Anno Dracula, preceded by: Dracula Cha Cha Cha\n",
      "1064\n",
      "Found 108 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1065\n",
      "Found 3091 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1066\n",
      "Found 239 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1067\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 646 pages, best-seller: Yes, film: Yes, saga: Jack Sawyer Trilogy, followed by: nan, preceded by: Black House\n",
      "1069\n",
      "Found 128 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1070\n",
      "Found 144 pages, best-seller: No, film: Yes, saga: Captain Underpantsseries, followed by: Captain Underpants and the Attack of the Talking Toilets, preceded by: Captain Underpants and the Perilous Plot of Professor Poopypants\n",
      "1071\n",
      "Found 447 pages, best-seller: No, film: No, saga: No, followed by: The Legacy of Heorot, preceded by: Destiny's Road\n",
      "1072\n",
      "Found 352 pages, best-seller: No, film: No, saga: Winterlands, followed by: nan, preceded by: Dragonshadow\n",
      "1073\n",
      "Found 211 pages, best-seller: No, film: No, saga: Time Quintet, followed by: A Wrinkle in Time, preceded by: A Swiftly Tilting Planet\n",
      "1074\n",
      "Found 134 pages, best-seller: No, film: Yes, saga: Brian's Saga, followed by: The River, preceded by: Brian's Return\n",
      "1075\n",
      "Found 406 pages, best-seller: No, film: Yes, saga: 2002, followed by: nan, preceded by: Kingdom of the Golden Dragon\n",
      "1076\n",
      "Found 345 pages, best-seller: No, film: No, saga: Vorkosigan Saga, followed by: Barrayar, preceded by: Brothers in Arms\n",
      "1077\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 264 pages, best-seller: No, film: No, saga: James Bond, followed by: nan, preceded by: nan\n",
      "1079\n",
      "Found 373 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1080\n",
      "Found nan pages, best-seller: No, film: No, saga: The Strands Series, followed by: Spires of Spirit, preceded by: Maze of Moonlight\n",
      "1081\n",
      "Found 345 pages, best-seller: No, film: No, saga: Cheela, followed by: nan, preceded by: Starquake\n",
      "1082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: The Oz books, followed by: nan, preceded by: The Marvelous Land of Oz\n",
      "1083\n",
      "Found 264 pages, best-seller: No, film: No, saga: Dragonriders of PernHarper Hall Trilogy, followed by: Dragonsong, preceded by: The White Dragon\n",
      "Dragondrums\n",
      "1084\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1085\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1086\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1087\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1088\n",
      "Found 447 pages, best-seller: No, film: No, saga: No, followed by: Blindsight, preceded by: Acceptable Risk\n",
      "1089\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1090\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Water-Method Man\n",
      "1091\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 286 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1093\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: \"Birth of a Salesman\" (short),Full Moon(novel), preceded by: Service With a Smile\n",
      "1094\n",
      "Found 542 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: The Wilt Alternative\n",
      "1096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 388 pages, best-seller: No, film: No, saga: Harry Bosch#18, followed by: The Burning Room, preceded by: The Wrong Side of Goodbye\n",
      "1097\n",
      "Found 432 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: That Was Then, This Is Now\n",
      "1099\n",
      "Found 896 pages, best-seller: No, film: Yes, saga: Duneseries, followed by: nan, preceded by: Dune Messiah\n",
      "1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1101\n",
      "Found 232 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 448 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 440 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1104\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Dead Famous (2001), preceded by: Past Mortem (2004)\n",
      "1106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1107\n",
      "Found nan pages, best-seller: Yes, film: No, saga: Anne of Green Gables, followed by: Anne of Avonlea, preceded by: Anne of Windy Poplars\n",
      "1108\n",
      "Found 576 pages, best-seller: No, film: Yes, saga: Underworld USA Trilogy, followed by: nan, preceded by: The Cold Six Thousand\n",
      "1109\n",
      "Found 450 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1110\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 283 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Promise\n",
      "1112\n",
      "Found 160 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: There's a Bat in Bunk Five\n",
      "1113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 321 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1114\n",
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1115\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1116\n",
      "Found 201 pages, best-seller: Yes, film: Yes, saga: No, followed by: Nine Stories, preceded by: Raise High the Roof Beam, Carpenters and Seymour: An Introduction\n",
      "1117\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1118\n",
      "Found 228 pages, best-seller: No, film: Yes, saga: Rune Trilogy, followed by: None, preceded by: Death of a Blue Movie Star\n",
      "1119\n",
      "Found 160 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1120\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1121\n",
      "Found 351 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280240 pages, best-seller: Yes, film: Yes, saga: No, followed by: The Eagle Has Landed, preceded by: The Valhalla Exchange\n",
      "1123\n",
      "Found 400 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1124\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 448 pages, best-seller: Yes, film: No, saga: Will Trent, followed by: Fractured, preceded by: Broken\n",
      "1126\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 318 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1130\n",
      "Found 213 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1131\n",
      "Found 487 pages, best-seller: No, film: No, saga: No, followed by: The Road to Gandolfo, preceded by: nan\n",
      "1132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1133\n",
      "Found 330 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1134\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Pollyanna Grows Up\n",
      "1135\n",
      "Found 228 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1136\n",
      "Found 1702 pages, best-seller: No, film: Yes, saga: Julie of the Wolves, followed by: nan, preceded by: Julie\n",
      "1137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1138\n",
      "Found 313 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 224 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1140\n",
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: Red Dwarf: Infinity Welcomes Careful Drivers, preceded by: Last Human\n",
      "1141\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1142\n",
      "Found 174144 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1143\n",
      "Found 188 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1144\n",
      "Found 616 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1145\n",
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1146\n",
      "Found 224 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Sula\n",
      "1147\n",
      "Found 453 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: Sea Glass\n",
      "1148\n",
      "Found 17612372 pages, best-seller: No, film: Yes, saga: Little House, followed by: nan, preceded by: Little House on the Prairie\n",
      "1149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Final Flight\n",
      "1150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1152\n",
      "Found 139 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1153\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1154\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1155\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1156\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1157\n",
      "Found 470 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 282 pages, best-seller: No, film: Yes, saga: No, followed by: The Murder of Roger Ackroyd, preceded by: The Mystery of the Blue Train\n",
      "1159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 291 pages, best-seller: No, film: Yes, saga: No, followed by: Interpreter of Maladies, preceded by: Unaccustomed Earth\n",
      "1160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 pages, best-seller: Yes, film: No, saga: The It Girl, followed by: Reckless, preceded by: Lucky\n",
      "1161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 402 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Magician King\n",
      "1162\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8601 pages, best-seller: No, film: No, saga: Inheritance Cycle, followed by: Brisingr, preceded by: nan\n",
      "1165\n",
      "Found 368 pages, best-seller: Yes, film: Yes, saga: No, followed by: Little Altars Everywhere(prequel), preceded by: Ya-Yas in Bloom, The Crowning Glory of Calla Lily Ponder\n",
      "1166\n",
      "Found 344 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1167\n",
      "Found 352 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5111 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1170\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1171\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: Celestine series, followed by: nan, preceded by: The Tenth Insight: Holding the VisionThe Secret of Shambhala: In Search of the Eleventh InsightThe Twelfth Insight: The Hour of Decision\n",
      "1172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1173\n",
      "Found 288 pages, best-seller: No, film: No, saga: Regeneration Trilogy, followed by: The Eye in the Door, preceded by: Another World\n",
      "1174\n",
      "Found 534 pages, best-seller: No, film: Yes, saga: Inkheartseries, followed by: nan, preceded by: Inkspell\n",
      "1175\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1176\n",
      "Found 240 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 246 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1178\n",
      "Found 396 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1179\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1180\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1181\n",
      "Found 480 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1182\n",
      "Found 160 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1183\n",
      "Found 224 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1184\n",
      "Found 499 pages, best-seller: No, film: Yes, saga: No, followed by: The Great Santini, preceded by: The Prince of Tides\n",
      "1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 pages, best-seller: Yes, film: No, saga: No, followed by: I'll Be Seeing You, preceded by: The Lottery Winner\n",
      "1186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1187\n",
      "Found 336 pages, best-seller: No, film: Yes, saga: No, followed by: Syrup, preceded by: Company\n",
      "1188\n",
      "Found 383 pages, best-seller: Yes, film: No, saga: No, followed by: The Road, preceded by: Stella Maris\n",
      "1189\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1191\n",
      "Found 2521 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1192\n",
      "Found 272 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1193\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1194\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1195\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1196\n",
      "Found 449 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1197\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1198\n",
      "Found 896 pages, best-seller: No, film: No, saga: Masters of Rome, followed by: nan, preceded by: The Grass Crown\n",
      "1199\n",
      "Found 5661 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 305 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1201\n",
      "Found 336 pages, best-seller: No, film: Yes, saga: Castaways, followed by: nan, preceded by: The Angel's Command\n",
      "1202\n",
      "Found 315 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 305 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1204\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1205\n",
      "Found 160 pages, best-seller: No, film: No, saga: Shadow Children, followed by: nan, preceded by: Among the Impostors\n",
      "1206\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Discworld, followed by: The Last Hero, preceded by: Night Watch\n",
      "1207\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1209\n",
      "Found 252 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1210\n",
      "Found 213 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1212\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1213\n",
      "Found 376 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1214\n",
      "Found nan pages, best-seller: No, film: No, saga: Harry Bosch, followed by: nan, preceded by: The Black Ice\n",
      "1215\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1216\n",
      "Found 400 pages, best-seller: No, film: Yes, saga: Folktales, followed by: Rose Daughter, preceded by: nan\n",
      "1217\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Kiss (short story)\n",
      "1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: Bride Quartet, followed by: Vision in White, preceded by: Savor the Moment\n",
      "1219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1220\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1221\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1222\n",
      "Found 384 pages, best-seller: No, film: Yes, saga: No, followed by: If Tomorrow Comes, preceded by: The Sands of Time\n",
      "1223\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1224\n",
      "Found 180 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1225\n",
      "Found 204 pages, best-seller: No, film: Yes, saga: The Chronicles of Prydain, followed by: The Black Cauldron, preceded by: Taran Wanderer\n",
      "1226\n",
      "Found 224 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Moon of Gomrath\n",
      "1227\n",
      "Found 182 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Tiger Rising\n",
      "1228\n",
      "Found 275 pages, best-seller: No, film: No, saga: The Cat Whoseries, followed by: The Cat Who Lived High, preceded by: The Cat Who Moved a Mountain\n",
      "1229\n",
      "Found 295 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1230\n",
      "Found 160 pages, best-seller: No, film: Yes, saga: The Hitchhiker's Guide to the Galaxy, followed by: The Restaurant at the End of the Universe, preceded by: So Long, and Thanks for All the Fish\n",
      "1231\n",
      "Found 464 pages, best-seller: Yes, film: No, saga: Arthurian Saga, followed by: nan, preceded by: The Hollow Hills\n",
      "1232\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 224 pages, best-seller: No, film: Yes, saga: The Chronicles of Prydain, followed by: The Book of Three, preceded by: The Castle of Llyr\n",
      "1234\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: To Sail Beyond the Sunset\n",
      "1235\n",
      "Found 3291 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1236\n",
      "Found 184 pages, best-seller: Yes, film: No, saga: Animorphs#1, followed by: nan, preceded by: The Visitor\n",
      "1237\n",
      "Found 240 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Fruit of the Lemon, preceded by: The Long Song\n",
      "1239\n",
      "Found 1841428542 pages, best-seller: No, film: Yes, saga: The Chronicles of Narnia, followed by: The Magician's Nephew, preceded by: nan\n",
      "1240\n",
      "Found 353 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Fraternity of the Stone\n",
      "1241\n",
      "Found 159 pages, best-seller: No, film: Yes, saga: No, followed by: The Outsiders, preceded by: Rumble Fish\n",
      "1242\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 544 pages, best-seller: No, film: Yes, saga: No, followed by: America, America, preceded by: The Assassins\n",
      "1245\n",
      "Found 159 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1246\n",
      "Found 536 pages, best-seller: No, film: Yes, saga: No, followed by: The Rainbow, preceded by: The Lost Girl\n",
      "1247\n",
      "Found 3111 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1248\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1250\n",
      "Found 315 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1251\n",
      "Found 195 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1253\n",
      "Found 122 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1254\n",
      "Found 410419 pages, best-seller: Yes, film: No, saga: Alexander the Great, followed by: Fire from Heaven, preceded by: Funeral Games\n",
      "1255\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1256\n",
      "Found 218 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1257\n",
      "Found 356 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1258\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1259\n",
      "Found 208181 pages, best-seller: No, film: Yes, saga: No, followed by: The Moon Is Down, preceded by: The Pearl\n",
      "1260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 414 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 494 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1262\n",
      "Found 2981 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: The Long Secret\n",
      "1263\n",
      "Found 432 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1264\n",
      "Found 304 pages, best-seller: Yes, film: No, saga: Warriors: The New Prophecy, followed by: Midnight, preceded by: Dawn\n",
      "1265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 221224 pages, best-seller: No, film: Yes, saga: Space Odyssey, followed by: nan, preceded by: 2010: Odyssey Two\n",
      "1266\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1267\n",
      "Found 160 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1268\n",
      "Found 504 pages, best-seller: No, film: No, saga: Green Rider (series), followed by: nan, preceded by: First Rider's Call\n",
      "1269\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1270\n",
      "Found 210 pages, best-seller: No, film: No, saga: FoundationSeries, followed by: Foundation and Empire, preceded by: Foundation's Edge\n",
      "1271\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: Death on the Nile, preceded by: Hercule Poirot's Christmas\n",
      "1272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 284 pages, best-seller: No, film: No, saga: No, followed by: Goodbye California, preceded by: River of Death\n",
      "1273\n",
      "Found 688 pages, best-seller: Yes, film: Yes, saga: Jack Ryan, followed by: The Cardinal of the Kremlin, preceded by: The Sum of All Fears\n",
      "1274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 336 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 316 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1276\n",
      "Found 208 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1277\n",
      "Found 288 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 336 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Illywhacker\n",
      "1279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1280\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The End of the Affair(1951), preceded by: Loser Takes All (1955)\n",
      "1281\n",
      "Found 223 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1282\n",
      "Found 184 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1283\n",
      "Found 416 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 522 pages, best-seller: No, film: No, saga: Jack Reacher, followed by: nan, preceded by: Die Trying\n",
      "1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 208 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1287\n",
      "Found 306 pages, best-seller: No, film: No, saga: Dirk Gently, followed by: nan, preceded by: The Long Dark Tea-Time of the Soul\n",
      "1288\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Death of a She Devil\n",
      "1289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1290\n",
      "Found 192224 pages, best-seller: No, film: Yes, saga: The Hitchhiker's Guide to the Galaxy, followed by: Life, the Universe and Everything, preceded by: Mostly Harmless\n",
      "1291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 448 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1292\n",
      "Found nan pages, best-seller: No, film: No, saga: Discworld7th novel – 1st individual story, followed by: Wyrd Sisters, preceded by: Guards! Guards!\n",
      "1293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1294\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1295\n",
      "Found 216 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1296\n",
      "Found 241 pages, best-seller: No, film: Yes, saga: The Tales of Alvin Maker, followed by: nan, preceded by: Red Prophet\n",
      "1297\n",
      "Found 321 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1298\n",
      "Found 874 pages, best-seller: Yes, film: No, saga: Jack Ryan, followed by: Debt of Honor, preceded by: Rainbow Six\n",
      "1299\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1300\n",
      "Found 537 pages, best-seller: No, film: No, saga: CoDominium, followed by: nan, preceded by: The Gripping Hand\n",
      "1301\n",
      "Found 252 pages, best-seller: No, film: Yes, saga: Ripliad, followed by: nan, preceded by: Ripley Under Ground\n",
      "1302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 360 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1303\n",
      "Found 149 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 845 pages, best-seller: No, film: Yes, saga: The Dark Tower, followed by: Song of Susannah, preceded by: nan\n",
      "1305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 455 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1306\n",
      "Found 342 pages, best-seller: No, film: Yes, saga: Ringworldstoryline fromKnown Space, followed by: nan, preceded by: The Ringworld Engineers, 1979\n",
      "1307\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1308\n",
      "Found 243 pages, best-seller: No, film: Yes, saga: The State, followed by: nan, preceded by: The Integral Trees\n",
      "1309\n",
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Tar-Aiym Krang\n",
      "1310\n",
      "Found 418 pages, best-seller: No, film: No, saga: No, followed by: The Mark of the Assassin, preceded by: The Kill Artist\n",
      "1311\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Discworld20th novel – 4th Death story, followed by: Feet of Clay, preceded by: Jingo\n",
      "1312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 165 pages, best-seller: No, film: Yes, saga: No, followed by: London Fields (novel), preceded by: The Information (novel)\n",
      "1313\n",
      "Found 592 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1314\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1315\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8651001 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 263 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 335 pages, best-seller: No, film: Yes, saga: No, followed by: Strip Tease, preceded by: Lucky You\n",
      "1319\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: All My Puny Sorrows, preceded by: Fight Night\n",
      "1320\n",
      "Found 5572 pages, best-seller: No, film: No, saga: The Sword of Truth, followed by: Faith of the Fallen, preceded by: Naked Empire\n",
      "1321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6731 pages, best-seller: No, film: No, saga: The Sword of Truth, followed by: Phantom, preceded by: The Omen Machine\n",
      "1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1024 pages, best-seller: No, film: No, saga: No, followed by: The Pillars of the Earth, preceded by: A Column of Fire[1]\n",
      "1323\n",
      "Found 344427 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 868 pages, best-seller: Yes, film: Yes, saga: Jack RyanThe Campus, followed by: Locked On, preceded by: Command Authority\n",
      "1325\n",
      "Found 348 pages, best-seller: No, film: Yes, saga: Hannibal Lecter, followed by: Hannibal Rising, preceded by: The Silence of the Lambs\n",
      "1326\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1327\n",
      "Found 243 pages, best-seller: No, film: No, saga: The Vlad Taltos novels, followed by: Phoenix, preceded by: Orca\n",
      "1328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 242 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1329\n",
      "Found 214 pages, best-seller: No, film: No, saga: The Vlad Taltos novels, followed by: Yendi, preceded by: Taltos\n",
      "1330\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1331\n",
      "Found 239 pages, best-seller: No, film: No, saga: The Vlad Taltos novels, followed by: nan, preceded by: Yendi\n",
      "1332\n",
      "Found 192 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1333\n",
      "Found 630 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 368 pages, best-seller: No, film: Yes, saga: Jumper, followed by: Reflex, preceded by: Exo\n",
      "1335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 544 pages, best-seller: No, film: Yes, saga: The Witcher, followed by: The Tower of Swallows, preceded by: Season of Storms\n",
      "1336\n",
      "Found 386 pages, best-seller: No, film: No, saga: Will Lee Novels, followed by: The Run, preceded by: Mounting Fears\n",
      "1337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 864 pages, best-seller: No, film: No, saga: Honor Harringtonseries, followed by: War of Honor, preceded by: Mission of Honor\n",
      "1338\n",
      "Found 188 pages, best-seller: No, film: Yes, saga: No, followed by: The New York Trilogy, preceded by: Moon Palace\n",
      "1339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1340\n",
      "Found 356 pages, best-seller: No, film: No, saga: Foundationseries, followed by: Foundation's Edge, preceded by: nan\n",
      "1341\n",
      "Found 31412942 pages, best-seller: No, film: Yes, saga: in Deathseries, followed by: nan, preceded by: Glory in Death\n",
      "1342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Jack Reacher, followed by: Blue Moon, preceded by: Better off Dead\n",
      "1343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1344\n",
      "Found 228 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1345\n",
      "Found 768 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304432 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1347\n",
      "Found 5031 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: Original Sins\n",
      "1348\n",
      "Found 526 pages, best-seller: No, film: No, saga: Beklan Empire, followed by: nan, preceded by: Maia\n",
      "1349\n",
      "Found 346 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1350\n",
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: Why Didn't They Ask Evans?, preceded by: Three Act Tragedy\n",
      "1351\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Voyages Extraordinaires#4Baltimore Gun Club#1, followed by: Journey to the Center of the Earth, preceded by: nan\n",
      "1352\n",
      "Found 376 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1353\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1354\n",
      "Found 464 pages, best-seller: No, film: Yes, saga: No, followed by: Thunderhead, preceded by: The Cabinet of Curiosities\n",
      "1355\n",
      "Found 480 pages, best-seller: Yes, film: Yes, saga: Aloysius Pendergast, followed by: nan, preceded by: Reliquary\n",
      "1356\n",
      "Found 278 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 404 pages, best-seller: No, film: Yes, saga: No, followed by: Fatal Cure, preceded by: Contagion\n",
      "1359\n",
      "Found 179 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1360\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1362\n",
      "Found 528 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1363\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The River Why, preceded by: nan\n",
      "1364\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 432 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1368\n",
      "Found 242 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1369\n",
      "Found 491 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1370\n",
      "Found 288288 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 397 pages, best-seller: No, film: Yes, saga: Jack Caffery #2, followed by: Birdman, preceded by: Tokyo\n",
      "1372\n",
      "Found 297 pages, best-seller: No, film: Yes, saga: No, followed by: Survivor, preceded by: Choke\n",
      "1373\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1374\n",
      "Found 544 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1375\n",
      "Found 443 pages, best-seller: No, film: No, saga: No, followed by: The Secret Pilgrim, preceded by: Our Game\n",
      "1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Flyaway\n",
      "1377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400384 pages, best-seller: No, film: Yes, saga: Women of the Otherworld, followed by: nan, preceded by: Stolen\n",
      "1378\n",
      "Found 338 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1379\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 181 pages, best-seller: No, film: No, saga: The Vlad Taltos novels, followed by: Teckla, preceded by: Phoenix\n",
      "1381\n",
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: The Town and the City(1950), preceded by: The Subterraneans  (1958)\n",
      "1382\n",
      "Found 464 pages, best-seller: No, film: No, saga: Avalon Series, followed by: The Forest House, preceded by: Priestess of Avalon\n",
      "1383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 pages, best-seller: Yes, film: Yes, saga: Fallen, followed by: Fallen, preceded by: Passion\n",
      "1384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1602 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1385\n",
      "Found 224 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1386\n",
      "Found 137 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Battle for the Castle\n",
      "1387\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1388\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1390\n",
      "Found 320 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: These Old Shades\n",
      "1391\n",
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1392\n",
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: The Other Side of Midnight, preceded by: nan\n",
      "1393\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Richard Hannay, followed by: The Thirty-Nine Steps, preceded by: Mr Standfast\n",
      "1394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1395\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 412 pages, best-seller: No, film: No, saga: No, followed by: Windmills of the Gods, preceded by: Memories of Midnight\n",
      "1397\n",
      "Found 96 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1398\n",
      "Found nan pages, best-seller: No, film: No, saga: Heinlein juveniles, followed by: Time for the Stars, preceded by: Have Space Suit—Will Travel\n",
      "1399\n",
      "Found 255 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1400\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1401\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 214 pages, best-seller: No, film: No, saga: No, followed by: The Bachelor of Arts, preceded by: Malgudi Days\n",
      "1403\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Tale of Samuel Whiskers or The Roly-Poly Pudding, preceded by: The Tale of Ginger and Pickles\n",
      "1404\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1405\n",
      "Found 629 pages, best-seller: Yes, film: Yes, saga: Twilightseries, followed by: New Moon, preceded by: Breaking Dawn\n",
      "1406\n",
      "Found 448 pages, best-seller: No, film: No, saga: No, followed by: King Solomon's Carpet, preceded by: No Night Is Too Long\n",
      "1407\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1408\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 278 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Kindness of Women\n",
      "1410\n",
      "Found 218 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 405 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1412\n",
      "Found 183 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1413\n",
      "Found 468 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Hope, preceded by: nan\n",
      "1415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 248 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1416\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1418\n",
      "Found 330 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1419\n",
      "Found 509 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 432 pages, best-seller: No, film: Yes, saga: No, followed by: Main Street, preceded by: Arrowsmith\n",
      "1421\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1422\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Alchemist (1988)\n",
      "1423\n",
      "Found 571 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 263 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1425\n",
      "Found 272 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1426\n",
      "Found 304 pages, best-seller: No, film: Yes, saga: Homecoming Saga, followed by: The Memory of Earth, preceded by: The Ships of Earth\n",
      "1427\n",
      "Found nan pages, best-seller: No, film: Yes, saga: None, followed by: nan, preceded by: Charlie and the Great Glass Elevator\n",
      "1428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 517 pages, best-seller: No, film: No, saga: Hyperion Cantos, followed by: Hyperion, preceded by: Endymion\n",
      "1429\n",
      "Found 157 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1430\n",
      "Found 289 pages, best-seller: No, film: No, saga: No, followed by: Under a War-Torn Sky, preceded by: nan\n",
      "1431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 254 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1433\n",
      "Found 611 pages, best-seller: No, film: Yes, saga: Bourne Trilogy, followed by: The Bourne Supremacy, preceded by: The Bourne Legacy\n",
      "1434\n",
      "Found 191 pages, best-seller: No, film: No, saga: Darkover, followed by: The Forbidden Tower, preceded by: nan\n",
      "1435\n",
      "Found nan pages, best-seller: No, film: No, saga: The Strands Series, followed by: Shroud of ShadowandSpires of Spirit, preceded by: nan\n",
      "1436\n",
      "Found 291 pages, best-seller: No, film: Yes, saga: Space Odyssey, followed by: 2001: A Space Odyssey, preceded by: 2061: Odyssey Three\n",
      "1437\n",
      "Found 414 pages, best-seller: No, film: No, saga: Darkover, followed by: The Shattered Chain, preceded by: City of Sorcery\n",
      "1438\n",
      "Found 272 pages, best-seller: No, film: Yes, saga: The Worthing series, followed by: nan, preceded by: nan\n",
      "1439\n",
      "Found nan pages, best-seller: No, film: No, saga: The Strands Series, followed by: Maze of Moonlight, preceded by: Strands of Sunlight\n",
      "1440\n",
      "Found nan pages, best-seller: No, film: No, saga: The Strands Series, followed by: Strands of Starlight, preceded by: Shroud of Shadow\n",
      "1441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 220 pages, best-seller: No, film: No, saga: Star Trek: The Original Series, followed by: Star Trek II: The Wrath of Khan, preceded by: Triangle\n",
      "1442\n",
      "Found 275 pages, best-seller: No, film: No, saga: Kate Martinelli series, followed by: To Play the Fool, preceded by: Night Work\n",
      "1443\n",
      "Found 320 pages, best-seller: No, film: No, saga: Heralds of Valdemar, followed by: Arrow's Flight, preceded by: nan\n",
      "1444\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: The Tiger's Child (1995)\n",
      "1445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 596 pages, best-seller: No, film: No, saga: Shane Schofield, followed by: Ice Station, preceded by: Scarecrow\n",
      "1446\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1447\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 203 pages, best-seller: No, film: No, saga: Amos Walker#2, followed by: Motor City Blue, preceded by: The Midnight Man\n",
      "1449\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1450\n",
      "Found nan pages, best-seller: No, film: No, saga: Ireta[2], followed by: Dinosaur Planet, preceded by: Sassinak\n",
      "1451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 189 pages, best-seller: No, film: No, saga: Ireta[2], followed by: nan, preceded by: Dinosaur Planet Survivors\n",
      "1452\n",
      "Found 373 pages, best-seller: No, film: No, saga: No, followed by: The Vulcan Academy Murders, preceded by: Shadow Lord\n",
      "1453\n",
      "Found nan pages, best-seller: No, film: No, saga: Heinlein juveniles, followed by: Rocket Ship Galileo, preceded by: Red Planet\n",
      "1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 384 pages, best-seller: No, film: Yes, saga: No, followed by: The Appeal, preceded by: Ford County\n",
      "1455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 pages, best-seller: No, film: Yes, saga: Asian Saga, followed by: Gai-Jin(in chronology of Asian Saga), preceded by: Noble House\n",
      "1457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 199 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1458\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: The Two Faces of Tomorrow, preceded by: Giants' Star\n",
      "1459\n",
      "Found 279 pages, best-seller: No, film: No, saga: The Steerswoman, followed by: nan, preceded by: The Outskirter’s Secret\n",
      "1460\n",
      "Found 573850 pages, best-seller: No, film: No, saga: The Red Wheel, followed by: nan, preceded by: November 1916\n",
      "1461\n",
      "Found nan pages, best-seller: No, film: No, saga: Silver Wolf (series), followed by: nan, preceded by: Night of the Wolf (novel) then by The Wolf King\n",
      "1462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4061 pages, best-seller: No, film: Yes, saga: The Kane Chronicles(bk 3), followed by: The Throne of Fire, preceded by: nan\n",
      "1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 391 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1464\n",
      "Found 384 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1465\n",
      "Found 384 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Echopraxia\n",
      "1466\n",
      "Found 285 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1467\n",
      "Found 196 pages, best-seller: No, film: No, saga: The Tillerman Series, followed by: Homecoming, preceded by: A Solitary Blue\n",
      "1468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 291 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1469\n",
      "Found 243 pages, best-seller: No, film: No, saga: The Space Trilogy, followed by: Out of the Silent Planet, preceded by: That Hideous Strength\n",
      "1470\n",
      "Found 313 pages, best-seller: No, film: Yes, saga: No, followed by: The Unconsoled, preceded by: Never Let Me Go\n",
      "1471\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1472\n",
      "Found 350 pages, best-seller: No, film: No, saga: Arthurian Saga, followed by: The Last Enchantment, preceded by: The Prince and the Pilgrim\n",
      "1473\n",
      "Found 2171510222 pages, best-seller: No, film: Yes, saga: The Chronicles of Narnia, followed by: The Voyage of the Dawn Treader, preceded by: The Horse and His Boy\n",
      "1474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1475\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: Star Over Bethlehem and other stories, preceded by: Third Girl\n",
      "1476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 248 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1477\n",
      "Found 573850 pages, best-seller: No, film: No, saga: The Red Wheel, followed by: nan, preceded by: November 1916\n",
      "1478\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1479\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Life Before Man, preceded by: The Handmaid's Tale\n",
      "1481\n",
      "Found 272 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Double Whammy\n",
      "1482\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Destination: Void, preceded by: The Lazarus Effect\n",
      "1483\n",
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1484\n",
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 262 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Solstice Wood\n",
      "1486\n",
      "Found 304 pages, best-seller: No, film: Yes, saga: No, followed by: Planet Plane, preceded by: The Kraken Wakes\n",
      "1487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 243 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1489\n",
      "Found 894 pages, best-seller: No, film: No, saga: No, followed by: The First Man in Rome, preceded by: Fortune's Favourites\n",
      "1490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 432 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1491\n",
      "Found 310 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1492\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1493\n",
      "Found nan pages, best-seller: No, film: No, saga: Emily series, followed by: Emily Climbs, preceded by: nan\n",
      "1494\n",
      "Found nan pages, best-seller: No, film: No, saga: Emily series, followed by: Emily of New Moon, preceded by: Emily's Quest\n",
      "1495\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Emily series, followed by: nan, preceded by: Emily Climbs\n",
      "1496\n",
      "Found 3891 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1497\n",
      "Found 461 pages, best-seller: No, film: No, saga: Bob Lee Swaggerseries, followed by: Point of Impact, preceded by: Time to Hunt\n",
      "1498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Jinx's Magic\n",
      "1499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 227 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1500\n",
      "Found 352 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 446 pages, best-seller: No, film: No, saga: Harry Bosch, #12, followed by: The Lincoln Lawyer, preceded by: The Overlook\n",
      "1502\n",
      "Found 384 pages, best-seller: No, film: No, saga: Great Episodes, followed by: Hang a Thousand Trees with Ribbons, preceded by: Cast Two Shadows\n",
      "1503\n",
      "Found 339 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1504\n",
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: The Lost Kingdom of Bamarre, preceded by: nan\n",
      "1505\n",
      "Found 284 pages, best-seller: No, film: No, saga: Richard Sharpe, followed by: Sharpe's Assassin, preceded by: nan\n",
      "1506\n",
      "Found 324 pages, best-seller: No, film: No, saga: Arthur trilogy, followed by: nan, preceded by: At the Crossing-Places\n",
      "1507\n",
      "Found 368 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1508\n",
      "Found 432 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1509\n",
      "Found 32 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1510\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1511\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1512\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1513\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: As I Lay Dying, preceded by: Light in August\n",
      "1514\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Captain Underpantsseries, followed by: Captain Underpants and the Perilous Plot of Professor Poopypants, preceded by: Captain Underpants and the Big, Bad Battle of the Bionic Booger Boy Part 1: The Night of the Nasty Nostril Nuggets\n",
      "1515\n",
      "Found 455512 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1516\n",
      "Found 277 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1517\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1518\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1519\n",
      "Found 560 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1520\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1521\n",
      "Found 450 pages, best-seller: Yes, film: No, saga: The Death Gate Cycle, followed by: Fire Sea, preceded by: The Hand of Chaos\n",
      "1522\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 pages, best-seller: Yes, film: Yes, saga: Fallen, followed by: nan, preceded by: Torment\n",
      "1524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: The Atrocity Exhibition, preceded by: Concrete Island\n",
      "1525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 544 pages, best-seller: No, film: Yes, saga: The Kent Family Chronicles, followed by: nan, preceded by: The Rebels\n",
      "1526\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1527\n",
      "Found 72 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1528\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1529\n",
      "Found 347 pages, best-seller: No, film: Yes, saga: in Death, followed by: Purity in Death, preceded by: Imitation in Death\n",
      "1530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Phthor\n",
      "1531\n",
      "Found 187 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 266 pages, best-seller: Yes, film: Yes, saga: No, followed by: The Terminal Man, preceded by: Eaters of the Dead\n",
      "1533\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1534\n",
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1535\n",
      "Found 352 pages, best-seller: No, film: No, saga: No, followed by: Northern Lights(1973), preceded by: The Nuclear Age (1985)\n",
      "1536\n",
      "Found 238 pages, best-seller: No, film: No, saga: No, followed by: In the Lake of the Woods(1994), preceded by: July, July (2002)\n",
      "1537\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1538\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1539\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1540\n",
      "Found 237 pages, best-seller: No, film: Yes, saga: No, followed by: The Third Man(1949), preceded by: The Quiet American (1955)\n",
      "1541\n",
      "Found 798 pages, best-seller: Yes, film: Yes, saga: Jack Ryan, followed by: Patriot Games, preceded by: Clear and Present Danger\n",
      "1542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 336 pages, best-seller: No, film: No, saga: Sean Dillon, followed by: The Killing Ground, preceded by: nan\n",
      "1543\n",
      "Found 1721 pages, best-seller: No, film: Yes, saga: The Chronicles of Narnia, followed by: nan, preceded by: Prince Caspian\n",
      "1544\n",
      "Found 160 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 512 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Killer Angels\n",
      "1546\n",
      "Found 2691 pages, best-seller: No, film: No, saga: No, followed by: Gather Together in My Name, preceded by: The Heart of a Woman\n",
      "1547\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1548\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 246 pages, best-seller: No, film: No, saga: Tales of the City, followed by: Tales of the City, preceded by: Further Tales of the City\n",
      "1550\n",
      "Found 150 pages, best-seller: No, film: No, saga: Moomins, followed by: Comet in Moominland, preceded by: The Exploits of Moominpappa\n",
      "1551\n",
      "Found 192276 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1552\n",
      "Found 262 pages, best-seller: No, film: No, saga: No, followed by: Wild Meat and the Bully Burgers,Saturday Night at the Pahala Theater, preceded by: Heads By Harry\n",
      "1553\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 250 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1556\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1557\n",
      "Found 222208 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1558\n",
      "Found 496 pages, best-seller: No, film: Yes, saga: L.A. Quartet, followed by: The Big Nowhere(1988), preceded by: White Jazz (1992)\n",
      "1559\n",
      "Found 336 pages, best-seller: No, film: No, saga: Strange and Quinn, followed by: nan, preceded by: Hell to Pay\n",
      "1560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 pages, best-seller: No, film: No, saga: Strange and Quinn, followed by: Right as Rain, preceded by: Soul Circus\n",
      "1561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 230 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1562\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Invisible Cities, preceded by: Mr. Palomar\n",
      "1564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 pages, best-seller: No, film: No, saga: No, followed by: Knots and Crosses, preceded by: Tooth and Nail\n",
      "1565\n",
      "Found 156 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1566\n",
      "Found 418 pages, best-seller: No, film: Yes, saga: Harry Bosch, #7, followed by: Angels Flight&Blood Work, preceded by: City of Bones\n",
      "1567\n",
      "Found 287 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1568\n",
      "Found 486 pages, best-seller: No, film: No, saga: The Magic Goes Away, followed by: nan, preceded by: Burning Tower\n",
      "1569\n",
      "Found 306 pages, best-seller: No, film: No, saga: James Asher Chronicles, followed by: nan, preceded by: Traveling with the Dead\n",
      "1570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 pages, best-seller: No, film: Yes, saga: Jack Ryan, followed by: nan, preceded by: Unknown Man No. 89\n",
      "1571\n",
      "Found 476 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Roderick Alleyn, followed by: Died in the Wool, preceded by: Swing Brother Swing\n",
      "1573\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Art Trilogy, followed by: nan, preceded by: Everville\n",
      "1574\n",
      "Found 354 pages, best-seller: No, film: Yes, saga: Serge A. Storms, followed by: Florida Roadkill, preceded by: Orange Crush\n",
      "1575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 405 pages, best-seller: No, film: No, saga: Corona, followed by: nan, preceded by: nan\n",
      "1576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1577\n",
      "Found 325 pages, best-seller: No, film: No, saga: No, followed by: Bloodsucking Fiends, preceded by: The Lust Lizard of Melancholy Cove\n",
      "1578\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1579\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 345 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1581\n",
      "Found 464 pages, best-seller: No, film: Yes, saga: No, followed by: The Lust Lizard of Melancholy Cove, preceded by: Fluke, or, I Know Why the Winged Whale Sings\n",
      "1582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1583\n",
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1584\n",
      "Found 383 pages, best-seller: No, film: No, saga: Robotseries, followed by: The Robots of Dawn, preceded by: The Stars, Like Dust\n",
      "1585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1586\n",
      "Found 293 pages, best-seller: No, film: No, saga: Krondor's Sons, followed by: nan, preceded by: The King's Buccaneer\n",
      "1587\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 228 pages, best-seller: No, film: No, saga: No, followed by: Midnight, preceded by: The Diamond Girls\n",
      "1589\n",
      "Found 353 pages, best-seller: Yes, film: Yes, saga: No, followed by: Native Tongue, preceded by: Stormy Weather\n",
      "1590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Chinaman: The Legend of Pradeep Mathew, preceded by: nan\n",
      "1592\n",
      "Found 348 pages, best-seller: No, film: Yes, saga: Inspector Wexford# 17, followed by: Kissing the Gunner's Daughter, preceded by: Road Rage\n",
      "1593\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1594\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 208 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Imperial Bedrooms\n",
      "1596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1597\n",
      "Found 240 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1598\n",
      "Found 304432 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1599\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1600\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1602\n",
      "Found 288 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: The Girl from the Golden Horn\n",
      "1603\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1604\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1605\n",
      "Found 609 pages, best-seller: Yes, film: Yes, saga: No, followed by: The 158-Pound Marriage, preceded by: The Hotel New Hampshire\n",
      "1606\n",
      "Found 351 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1607\n",
      "Found 289 pages, best-seller: No, film: No, saga: No, followed by: Parnassus on Wheels(1917), preceded by: nan\n",
      "1608\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1609\n",
      "Found 297 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1610\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1611\n",
      "Found 304 pages, best-seller: No, film: Yes, saga: Bridge trilogy, followed by: \"Skinner's Room\" (short story), preceded by: Idoru\n",
      "1612\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: In the Night Room\n",
      "1613\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1614\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1615\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Son of Rosemary\n",
      "1617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Darkness, Tell Us, preceded by: Alarums\n",
      "1618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 370 pages, best-seller: No, film: Yes, saga: No, followed by: She Wakes1989 in literature, preceded by: Offspring 1991 in literature\n",
      "1619\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1622\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1623\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1625\n",
      "Found 640 pages, best-seller: No, film: No, saga: Diogenes Trilogy,Aloysius Pendergast, followed by: Dance of Death, preceded by: The Wheel of Darkness\n",
      "1626\n",
      "Found 352 pages, best-seller: No, film: No, saga: Kenzie-Gennaro, followed by: Gone, Baby, Gone, preceded by: Moonlight Mile\n",
      "1627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1628\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1629\n",
      "Found 317 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1630\n",
      "Found 357 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1631\n",
      "Found 144 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Strider\n",
      "1632\n",
      "Found 437 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1634\n",
      "Found 2871 pages, best-seller: No, film: No, saga: Lord Peter Wimsey, followed by: nan, preceded by: Clouds of Witness\n",
      "1635\n",
      "Found 344 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1636\n",
      "Found 286 pages, best-seller: No, film: No, saga: Dragonriders of Pern, followed by: Dragondrums, preceded by: Nerilka's Story\n",
      "1637\n",
      "Found nan pages, best-seller: No, film: Yes, saga: First Quarto, followed by: nan, preceded by: nan\n",
      "1638\n",
      "Found 368448 pages, best-seller: No, film: No, saga: No, followed by: The Third Option, preceded by: Executive Power\n",
      "1639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: Fletch, followed by: nan, preceded by: Confess, Fletch\n",
      "1640\n",
      "Found 310 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1641\n",
      "Found 176 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 368 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1643\n",
      "Found 302 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1644\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1645\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Oz books, followed by: The Marvelous Land of Oz, preceded by: Dorothy and the Wizard in Oz\n",
      "1646\n",
      "Found 308 pages, best-seller: No, film: No, saga: No, followed by: The Murder at the Vicarage, preceded by: Peril at End House\n",
      "1647\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 498 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1649\n",
      "Found 186 pages, best-seller: No, film: Yes, saga: The Mouse and the Motorcycle, followed by: nan, preceded by: Runaway Ralph\n",
      "1650\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1651\n",
      "Found 1452 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: A Billion for Boris\n",
      "1652\n",
      "Found 333 pages, best-seller: No, film: No, saga: Dragonriders of Pern, followed by: Dragonflight, preceded by: Dragonsong\n",
      "1653\n",
      "Found 160 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1654\n",
      "Found 183 pages, best-seller: No, film: Yes, saga: Ramona, followed by: nan, preceded by: Ramona the Pest (1968)\n",
      "1655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Pamela in her Exalted Condition\n",
      "1656\n",
      "Found 3049 pages, best-seller: No, film: No, saga: No, followed by: Night Mare, preceded by: Crewel Lye: A Caustic Yarn\n",
      "1657\n",
      "Found 182 pages, best-seller: No, film: No, saga: Nero Wolfe, followed by: Too Many Clients, preceded by: Homicide Trinity\n",
      "1658\n",
      "Found 242 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1659\n",
      "Found 304 pages, best-seller: No, film: No, saga: Nuala Anne McGrail series, followed by: Irish Love, preceded by: Irish Cream\n",
      "1660\n",
      "Found 343372 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 170 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1662\n",
      "Found 496 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1663\n",
      "Found 480 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1664\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Kiss an Angel, preceded by: Dream a Little Dream\n",
      "1665\n",
      "Found 413 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1666\n",
      "Found 636 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1667\n",
      "Found 155 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1668\n",
      "Found 255 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5121 pages, best-seller: No, film: No, saga: Jack Reacher, followed by: Tripwire, preceded by: Echo Burning\n",
      "1670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 231 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 146 pages, best-seller: No, film: No, saga: No, followed by: Moving the Mountain, preceded by: With Her in Ourland\n",
      "1672\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Little Dorrit, preceded by: Great Expectations\n",
      "1673\n",
      "Found 292 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1674\n",
      "Found 202 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 370 pages, best-seller: No, film: Yes, saga: A Myron Bolitar Novel, followed by: Darkest Fear, preceded by: Long Lost\n",
      "1676\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 206 pages, best-seller: No, film: No, saga: The 39 Clues, followed by: The Black Circle, preceded by: The Viper's Nest\n",
      "1678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1679\n",
      "Found 208 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1680\n",
      "Found 290 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1681\n",
      "Found 766 pages, best-seller: Yes, film: No, saga: Jack Ryan, followed by: Without Remorse, preceded by: Executive Orders\n",
      "1682\n",
      "Found 260 pages, best-seller: No, film: No, saga: Kate Martinelli series, followed by: A Grave Talent, preceded by: With Child\n",
      "1683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1684\n",
      "Found 310 pages, best-seller: No, film: Yes, saga: No, followed by: The Day of the Jackal, preceded by: The Dogs of War\n",
      "1685\n",
      "Found 358380 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1686\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1688\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: The Hobbit, preceded by: The Adventures of Tom Bombadil\n",
      "1689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1690\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1691\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1692\n",
      "Found 352336 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1693\n",
      "Found 905 pages, best-seller: No, film: Yes, saga: No, followed by: The Last Call, preceded by: The Procedure\n",
      "1694\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1695\n",
      "Found 220 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1696\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1697\n",
      "Found 384 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Señor Vivo and the Coca Lord & The Troublesome Offspring of Cardinal Guzman\n",
      "1698\n",
      "Found 176 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1699\n",
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 420 pages, best-seller: No, film: Yes, saga: No, followed by: The Handmaid's Tale, preceded by: Wilderness Tips\n",
      "1701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 216 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1702\n",
      "Found 337 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Casanova (1998)\n",
      "1703\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1704\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1705\n",
      "Found 197 pages, best-seller: No, film: No, saga: No, followed by: Smile, preceded by: Guts\n",
      "1706\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1707\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Winnie-the-Pooh, preceded by: nan\n",
      "1708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 374 pages, best-seller: No, film: Yes, saga: The Hunger Gamestrilogy, followed by: The Ballad of Songbirds and Snakes, preceded by: Catching Fire\n",
      "1709\n",
      "Found 384 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1710\n",
      "Found 1832 pages, best-seller: No, film: No, saga: The Cat Who..., followed by: The Cat Who Turned On and Off, preceded by: The Cat Who Played Brahms\n",
      "1711\n",
      "Found 236 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Forever Free\n",
      "1712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192176 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1714\n",
      "Found 294 pages, best-seller: No, film: No, saga: Maisie Dobbs, followed by: nan, preceded by: Birds of a Feather\n",
      "1715\n",
      "Found 560 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1717\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 219 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1719\n",
      "Found 448 pages, best-seller: No, film: Yes, saga: Casteel series, followed by: Fallen Hearts, preceded by: Web of Dreams\n",
      "1720\n",
      "Found 145 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1721\n",
      "Found 272 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Beyond the Chocolate War\n",
      "1722\n",
      "Found 241 pages, best-seller: No, film: No, saga: The Giver Quartet, followed by: The Giver, preceded by: Messenger\n",
      "1723\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: A Key to Uncle Tom's Cabin\n",
      "1724\n",
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1725\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1726\n",
      "Found 1147 pages, best-seller: No, film: No, saga: Asian Saga, followed by: Noble House, preceded by: Escape\n",
      "1727\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 317 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1729\n",
      "Found 218 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1730\n",
      "Found 312 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1731\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1732\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1733\n",
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: Three Act Tragedy, preceded by: The A.B.C. Murders\n",
      "1734\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: The Mirror Crack'd from Side to Side, preceded by: A Caribbean Mystery\n",
      "1735\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1736\n",
      "Found 2452 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1737\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: The Thirteen Problems, preceded by: The Hound of Death\n",
      "1738\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Beebo Brinker Chronicles, followed by: Journey to a Woman, preceded by: nan\n",
      "1739\n",
      "Found nan pages, best-seller: No, film: No, saga: Jay Omega series, followed by: nan, preceded by: Zombies of the Gene Pool(1992)'\n",
      "1740\n",
      "Found 223 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Best Awful There Is\n",
      "1741\n",
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: At Bertram's Hotel, preceded by: Endless Night\n",
      "1742\n",
      "Found 264 pages, best-seller: No, film: No, saga: The Space Trilogy, followed by: None, preceded by: Perelandra\n",
      "1743\n",
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: Hallowe'en Party, preceded by: Nemesis\n",
      "1744\n",
      "Found 224 pages, best-seller: Yes, film: Yes, saga: No, followed by: Curtain, preceded by: An Autobiography\n",
      "1745\n",
      "Found 264 pages, best-seller: No, film: No, saga: No, followed by: Four Ways to Forgiveness, preceded by: nan\n",
      "1746\n",
      "Found 3151 pages, best-seller: No, film: No, saga: Lord Peter Wimsey, followed by: Whose Body?, preceded by: Unnatural Death\n",
      "1747\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: All God's Children Need Traveling Shoes, preceded by: Mom & Me & Mom\n",
      "1748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1750\n",
      "Found 255 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1751\n",
      "Found 144 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1752\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1753\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Middlemarch, preceded by: nan\n",
      "1754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1755\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1756\n",
      "Found 320 pages, best-seller: No, film: No, saga: Inspector Morseseries, #11, followed by: The Way Through the Woods, preceded by: Death Is Now My Neighbour\n",
      "1757\n",
      "Found 483 pages, best-seller: No, film: No, saga: Edentrilogy, followed by: nan, preceded by: Winter in Eden\n",
      "1758\n",
      "Found 497 pages, best-seller: No, film: No, saga: The Second Chronicles of Thomas Covenant, followed by: The Power that Preserves, preceded by: The One Tree\n",
      "1759\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1760\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1761\n",
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1762\n",
      "Found 368 pages, best-seller: No, film: No, saga: Genome, followed by: Dances on the Snow[2001], preceded by: Cripples [2004]\n",
      "1763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 879 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1764\n",
      "Found 643 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1766\n",
      "Found 281 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1767\n",
      "Found 328 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1768\n",
      "Found 832 pages, best-seller: No, film: No, saga: No, followed by: Pleading Guilty, preceded by: Personal Injuries\n",
      "1769\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Bonjour Tristesse, preceded by: Dans un mois, dans un an\n",
      "1770\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Things They Carried(1990), preceded by: Tomcat in Love (1998)\n",
      "1771\n",
      "Found 358 pages, best-seller: No, film: Yes, saga: in Death, followed by: Conspiracy in Death, preceded by: Witness in Death\n",
      "1772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1773\n",
      "Found 368 pages, best-seller: Yes, film: No, saga: Pendergast, followed by: Fever Dream, preceded by: Two Graves\n",
      "1774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1775\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 448432 pages, best-seller: No, film: Yes, saga: No, followed by: One L, preceded by: The Burden of Proof\n",
      "1777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 208 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1780\n",
      "Found 217 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1781\n",
      "Found 41 pages, best-seller: No, film: Yes, saga: No, followed by: McElligot's Pool, preceded by: Bartholomew and the Oobleck\n",
      "1782\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1783\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 131 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Oliver's Story (novel)\n",
      "1786\n",
      "Found 32 pages, best-seller: Yes, film: Yes, saga: No, followed by: The Runaway Bunny, preceded by: My World\n",
      "1787\n",
      "Found 1831410622 pages, best-seller: No, film: Yes, saga: The Chronicles of Narnia, followed by: The Horse and His Boy, preceded by: The Last Battle\n",
      "1788\n",
      "Found 1991480292 pages, best-seller: No, film: Yes, saga: The Chronicles of Narnia, followed by: The Silver Chair, preceded by: The Magician's Nephew\n",
      "1789\n",
      "Found 28812902 pages, best-seller: No, film: Yes, saga: Little House, followed by: The Long Winter, preceded by: These Happy Golden Years\n",
      "1790\n",
      "Found 23933381 pages, best-seller: No, film: Yes, saga: Little House, followed by: Little House on the Prairie, preceded by: By the Shores of Silver Lake\n",
      "1791\n",
      "Found 336 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1792\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1793\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1794\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1795\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1797\n",
      "Found 447 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1798\n",
      "Found 105 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Timothy of the Cay\n",
      "1799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Emergence trilogy, followed by: nan, preceded by: Tracking\n",
      "1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1801\n",
      "Found 308 pages, best-seller: No, film: No, saga: Nero Wolfe, followed by: The League of Frightened Men, preceded by: The Red Box\n",
      "1802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 629 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: Beggarman, Thief\n",
      "1803\n",
      "Found 403 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1804\n",
      "Found 352356 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1805\n",
      "Found 647 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1806\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1807\n",
      "Found 960 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Santangelonovels, followed by: nan, preceded by: Hollywood Wives\n",
      "1809\n",
      "Found 473 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Ark\n",
      "1810\n",
      "Found 310 pages, best-seller: No, film: No, saga: No, followed by: Partisans, preceded by: San Andreas\n",
      "1811\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1812\n",
      "Found 183 pages, best-seller: No, film: No, saga: Nero Wolfe, followed by: Champagne for One, preceded by: Three at Wolfe's Door\n",
      "1813\n",
      "Found 601 pages, best-seller: No, film: Yes, saga: The Matarese Dynasty, followed by: nan, preceded by: The Matarese Countdown\n",
      "1814\n",
      "Found 885 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: War and Remembrance\n",
      "1815\n",
      "Found 478 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1816\n",
      "Found 256 pages, best-seller: No, film: No, saga: James Bond, followed by: nan, preceded by: nan\n",
      "1817\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1050 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1819\n",
      "Found 187 pages, best-seller: No, film: No, saga: Robotseries, followed by: The Caves of Steel, preceded by: The Robots of Dawn, \"Mirror Image\"\n",
      "1820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1821\n",
      "Found 387 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1823\n",
      "Found nan pages, best-seller: No, film: No, saga: Discworld29th novel – 6th City Watch novel (7th story), followed by: The Amazing Maurice and His Educated Rodents, preceded by: The Wee Free Men\n",
      "1824\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Exiles at the Well of Souls\n",
      "1825\n",
      "Found 3121 pages, best-seller: No, film: No, saga: No, followed by: Geis of the Gargoyle, preceded by: Yon Ill Wind\n",
      "1826\n",
      "Found 182 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Pigman's Legacy (1980)The Pigman & Me (1990)\n",
      "1827\n",
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Mission to Moulokin\n",
      "1828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1829\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 312 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1831\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1832\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 368 pages, best-seller: No, film: No, saga: No, followed by: Fires of Winter, preceded by: Surrender My Love\n",
      "1834\n",
      "Found 246 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1835\n",
      "Found 215 pages, best-seller: No, film: Yes, saga: No, followed by: Athabasca, preceded by: Partisans\n",
      "1836\n",
      "Found 220 pages, best-seller: No, film: No, saga: James Bond, followed by: nan, preceded by: nan\n",
      "1837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 339 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1838\n",
      "Found nan pages, best-seller: No, film: No, saga: Greatwinter, followed by: Souls in the Great Machine, preceded by: Eyes of the Calculor\n",
      "1839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 248 pages, best-seller: No, film: No, saga: No, followed by: Riotous Assembly, preceded by: Porterhouse Blue\n",
      "1840\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 608 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1842\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: I Am Not Going to Get Up Today!, preceded by: Daisy-Head Mayzie\n",
      "1843\n",
      "Found 40 pages, best-seller: No, film: Yes, saga: Roald Dahl, followed by: Danny, the Champion of the World, preceded by: The Twits\n",
      "1844\n",
      "Found nan pages, best-seller: No, film: No, saga: Acorna Universe[1], followed by: Acorna's People, preceded by: Acorna's Search\n",
      "1845\n",
      "Found 249 pages, best-seller: No, film: No, saga: No, followed by: Calico Captive, preceded by: The Bronze Bow\n",
      "1846\n",
      "Found 303 pages, best-seller: No, film: No, saga: Fafhrd and the Gray Mouserseries, followed by: Swords and Ice Magic, preceded by: nan\n",
      "1847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Shiloh SeasonSaving ShilohA Shiloh Christmas\n",
      "1848\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Oz Books, followed by: Dorothy and the Wizard in Oz, preceded by: The Emerald City of Oz\n",
      "1849\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1850\n",
      "Found 250 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1851\n",
      "Found 160 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Max the Mighty\n",
      "1852\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1853\n",
      "Found 487 pages, best-seller: No, film: No, saga: No, followed by: The Crow Road, preceded by: Complicity\n",
      "1854\n",
      "Found 248 pages, best-seller: No, film: No, saga: Den of Shadows, followed by: Shattered Mirror(2001), preceded by: Hawksong(2003)\n",
      "1855\n",
      "Found 204 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1856\n",
      "Found 248 pages, best-seller: No, film: No, saga: Jeeves, followed by: Thank You, Jeeves, preceded by: The Code of the Woosters\n",
      "1857\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1859\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Through the Looking-Glass\n",
      "1860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 464 pages, best-seller: No, film: Yes, saga: Caster Chronicles, followed by: Beautiful Chaos, preceded by: nan\n",
      "1861\n",
      "Found 539 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1862\n",
      "Found 592 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 338 pages, best-seller: No, film: Yes, saga: Hannibal Lecter, followed by: Red Dragon, preceded by: Hannibal\n",
      "1864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1865\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: No, saga: MirrorWorld, followed by: nan, preceded by: Fearless\n",
      "1867\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 228 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1869\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1870\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Alexander's Bridge, preceded by: The Song of the Lark\n",
      "1871\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1874\n",
      "Found 196 pages, best-seller: No, film: No, saga: No, followed by: Just as Long as We're Together, preceded by: nan\n",
      "1875\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1877\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Strider\n",
      "1879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121 pages, best-seller: Yes, film: Yes, saga: Goosebumps, followed by: The Ghost Next Door, preceded by: Be Careful What You Wish For...\n",
      "1881\n",
      "Found 296 pages, best-seller: No, film: No, saga: Adam Dalgliesh#4, followed by: Unnatural Causes, preceded by: The Black Tower\n",
      "1882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4341512 pages, best-seller: No, film: No, saga: The Warlord Chronicles, followed by: nan, preceded by: Enemy of God\n",
      "1883\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1884\n",
      "Found 368 pages, best-seller: No, film: No, saga: Harry Bosch, #9, followed by: City of Bones, preceded by: The Narrows\n",
      "1885\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1886\n",
      "Found 328 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1887\n",
      "Found 481 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Mark of the Assassin\n",
      "1888\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1889\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: The Man from St. Petersburg(1982), preceded by: Lie Down with Lions (1986)\n",
      "1890\n",
      "Found 244 pages, best-seller: No, film: No, saga: The Snake Oil Series, followed by: A Truce With Time, preceded by: The Snake Oil Wars\n",
      "1891\n",
      "Found 351 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1892\n",
      "Found 319 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1893\n",
      "Found 499 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 175 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1895\n",
      "Found nan pages, best-seller: No, film: Yes, saga: together withPearl,CleannessandPatience, followed by: nan, preceded by: nan\n",
      "1896\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1898\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 251 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1901\n",
      "Found 148 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1902\n",
      "Found 374 pages, best-seller: No, film: Yes, saga: The Hunger Gamestrilogy, followed by: The Ballad of Songbirds and Snakes, preceded by: Catching Fire\n",
      "1903\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 439 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 305 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1906\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1907\n",
      "Found 488 pages, best-seller: No, film: No, saga: Lonesome Dove series, followed by: Streets of Laredo, preceded by: Comanche Moon\n",
      "1908\n",
      "Found 372 pages, best-seller: No, film: Yes, saga: in Death, followed by: Holiday in Death, preceded by: Loyalty in Death\n",
      "1909\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: Dune, followed by: Dune, preceded by: Children of Dune\n",
      "1910\n",
      "Found 444 pages, best-seller: No, film: No, saga: Duneseries, followed by: Dune Messiah, preceded by: God Emperor of Dune\n",
      "1911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 312 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 432 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Run Before the Wind\n",
      "1913\n",
      "Found 406 pages, best-seller: No, film: No, saga: No, followed by: Rabbit, Run, preceded by: Rabbit is Rich\n",
      "1914\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 226 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1916\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: Dumb Witness, preceded by: Appointment with Death\n",
      "1917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 312 pages, best-seller: No, film: Yes, saga: The Once and Future King, followed by: nan, preceded by: The Queen of Air and Darkness\n",
      "1918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 208 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1919\n",
      "Found 200 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: The Road Back\n",
      "1920\n",
      "Found 480 pages, best-seller: No, film: No, saga: No, followed by: Rabbit Redux, preceded by: Rabbit At Rest\n",
      "1921\n",
      "Found 3501958 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 281 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1923\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Discworld1st novel – 1st Rincewind story, followed by: nan, preceded by: The Light Fantastic\n",
      "1924\n",
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 pages, best-seller: No, film: Yes, saga: Regeneration Trilogy, followed by: The Man Who Wasn't There, preceded by: The Eye in the Door\n",
      "1927\n",
      "Found 600 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1928\n",
      "Found 704 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1929\n",
      "Found 292 pages, best-seller: No, film: No, saga: Arthurian Saga, followed by: The Wicked Day, preceded by: nan\n",
      "1930\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1931\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 187 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 368 pages, best-seller: No, film: Yes, saga: The Chemical Garden Trilogy, followed by: nan, preceded by: Fever\n",
      "1934\n",
      "Found 276 pages, best-seller: No, film: No, saga: Buffy the Vampire Slayer, followed by: The Lost Slayer, preceded by: These Our Actors\n",
      "1935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 510 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1937\n",
      "Found 483 pages, best-seller: No, film: No, saga: No, followed by: \"Shikari in Galveston\", preceded by: nan\n",
      "1938\n",
      "Found 256 pages, best-seller: No, film: No, saga: James Bond, followed by: nan, preceded by: nan\n",
      "1939\n",
      "Found 177 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1940\n",
      "Found 541 pages, best-seller: No, film: No, saga: Shane Schofield, followed by: nan, preceded by: Area 7\n",
      "1941\n",
      "Found 154 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1942\n",
      "Found 629 pages, best-seller: No, film: No, saga: Starfire series, followed by: Crusade, preceded by: The Shiva Option\n",
      "1943\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Berlin Game, preceded by: London Match\n",
      "1944\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 562 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1946\n",
      "Found 115 pages, best-seller: No, film: Yes, saga: Children's novel, followed by: nan, preceded by: How to Fight a Girl\n",
      "1947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 278 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1948\n",
      "Found 208 pages, best-seller: No, film: Yes, saga: Hitchhiker's Guide, followed by: The Hitchhiker's Guide to the Galaxy, preceded by: Life, the Universe and Everything\n",
      "1949\n",
      "Found 276 pages, best-seller: No, film: No, saga: Vandarei series, followed by: nan, preceded by: The Grey Mane of Morning\n",
      "1950\n",
      "Found 353 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1951\n",
      "Found 384 pages, best-seller: No, film: No, saga: Cordelia Gray#2, followed by: An Unsuitable Job for a Woman, preceded by: nan\n",
      "1952\n",
      "Found 471 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1953\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1954\n",
      "Found 374 pages, best-seller: No, film: Yes, saga: The Hunger Gamestrilogy, followed by: The Ballad of Songbirds and Snakes, preceded by: Catching Fire\n",
      "1955\n",
      "Found nan pages, best-seller: No, film: No, saga: Adam Dalgliesh#2, followed by: Cover Her Face, preceded by: Unnatural Causes\n",
      "1956\n",
      "Found 345 pages, best-seller: No, film: No, saga: Inspector Wexford# 15, followed by: The Veiled One, preceded by: Simisola\n",
      "1957\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1958\n",
      "Found 495 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 626 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1960\n",
      "1961\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1962\n",
      "Found 223 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1963\n",
      "Found 700 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Count of Moret, The Dove, Twenty Years After\n",
      "1964\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Oz books, followed by: nan, preceded by: The Marvelous Land of Oz\n",
      "1965\n",
      "Found nan pages, best-seller: No, film: No, saga: Mary Russell, followed by: The Moor, preceded by: Justice Hall\n",
      "1966\n",
      "Found 56 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Tale of Squirrel Nutkin\n",
      "1967\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1968\n",
      "Found 309 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1970\n",
      "Found 335 pages, best-seller: No, film: No, saga: Alexander the Great, followed by: The Persian Boy, preceded by: nan\n",
      "1971\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Extraordinary Voyages#11, followed by: The Fur Country, preceded by: The Mysterious Island\n",
      "1972\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 204 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1975\n",
      "Found 4641912 pages, best-seller: No, film: Yes, saga: No, followed by: A Pair of Blue Eyes, preceded by: The Hand of Ethelberta\n",
      "1976\n",
      "Found nan pages, best-seller: No, film: No, saga: Adam DalglieshNo. 1, followed by: nan, preceded by: A Mind to Murder\n",
      "1977\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: The Listerdale Mystery, preceded by: Parker Pyne Investigates\n",
      "1978\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1979\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1980\n",
      "Found 316 pages, best-seller: No, film: No, saga: No, followed by: Witch Hunt, preceded by: Blood Hunt\n",
      "1981\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1982\n",
      "Found 319 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1984\n",
      "Found 3361124731 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1985\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 483 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1987\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 185187 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "1989\n",
      "Found nan pages, best-seller: No, film: No, saga: Adrian Mole, followed by: Adrian Mole: The Wilderness Years, preceded by: The Lost Diaries of Adrian Mole, 1999–2001\n",
      "1990\n",
      "Found 441 pages, best-seller: No, film: No, saga: No, followed by: This Present Darkness, preceded by: nan\n",
      "1991\n",
      "Found 349 pages, best-seller: No, film: No, saga: Inspector Morse(#12), followed by: The Daughters of Cain, preceded by: The Remorseful Day\n",
      "1992\n",
      "Found 370 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: A Sterkarm Kiss\n",
      "1993\n",
      "Found 310 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "1994\n",
      "Found 255 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Silver Branch\n",
      "1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: The Castle Series, followed by: Howl's Moving Castle, preceded by: House of Many Ways\n",
      "1996\n",
      "Found 384 pages, best-seller: No, film: No, saga: League of Peoples, followed by: Hunted, preceded by: Trapped\n",
      "1997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 212 pages, best-seller: No, film: Yes, saga: Howl's Castle[1], followed by: nan, preceded by: Castle in the Air\n",
      "1998\n",
      "Found 328345 pages, best-seller: No, film: No, saga: Derkholm, followed by: nan, preceded by: Year of the Griffin\n",
      "1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 pages, best-seller: No, film: No, saga: No, followed by: Tangerine (novel), preceded by: nan\n",
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 432 pages, best-seller: No, film: Yes, saga: Meg, followed by: Meg: A Novel of Deep Terror, preceded by: Meg: Primal Waters\n",
      "2001\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: number9dream\n",
      "2002\n",
      "Found 338 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Disappearing Dwarf\n",
      "2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: No, saga: All-American Girl series, followed by: nan, preceded by: Ready or Not\n",
      "2004\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2005\n",
      "Found nan pages, best-seller: No, film: No, saga: Time Travelers Quartet, followed by: Out of Time, preceded by: For All Time\n",
      "2006\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2007\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Fortune's Favourites, preceded by: Caesar\n",
      "2008\n",
      "Found 77 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2009\n",
      "Found 256 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2010\n",
      "Found 263 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2012\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Dead Babies, preceded by: Other People\n",
      "2013\n",
      "Found 324 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2014\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Not the End of the World, preceded by: Boiling a Frog\n",
      "2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2016\n",
      "Found 368 pages, best-seller: No, film: No, saga: No, followed by: Gallowglass, preceded by: Asta's Book\n",
      "2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Doctor Whobook:Virgin New Adventures, followed by: The Left-Handed Hummingbird, preceded by: No Future\n",
      "2018\n",
      "Found 392 pages, best-seller: No, film: No, saga: No, followed by: The Unusual Life of Tristan Smith, preceded by: True History of the Kelly Gang\n",
      "2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 512 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 364 pages, best-seller: No, film: No, saga: Spin / Hypotheticals, followed by: nan, preceded by: Axis\n",
      "2021\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2022\n",
      "Found 294 pages, best-seller: No, film: No, saga: No, followed by: Don Rodriguez: Chronicles of Shadow Valley, preceded by: nan\n",
      "2023\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 584 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2025\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Rod Albright's Alien Adventures, followed by: nan, preceded by: I Left My Sneakers in Dimension X\n",
      "2026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 576 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2027\n",
      "Found 174 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2028\n",
      "Found 191 pages, best-seller: No, film: No, saga: The No. 1 Ladies' Detective Agencyseries, followed by: Morality for Beautiful Girls(2001), preceded by: The Full Cupboard of Life (2004)\n",
      "2029\n",
      "Found 156 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2030\n",
      "Found 181 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Ecotopia Emerging\n",
      "2031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2032\n",
      "Found 300 pages, best-seller: No, film: No, saga: Alphabet Mysteries, followed by: \"L\" Is for Lawless, preceded by: \"N\" Is for Noose\n",
      "2033\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2034\n",
      "Found 600 pages, best-seller: No, film: No, saga: No, followed by: Bliss, preceded by: Oscar and Lucinda\n",
      "2035\n",
      "Found 384 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2036\n",
      "Found 378 pages, best-seller: No, film: No, saga: No, followed by: The Time of the Transference, preceded by: Chorus Skating\n",
      "2037\n",
      "Found 192 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Canto for a Gypsy\n",
      "2038\n",
      "Found 335 pages, best-seller: No, film: No, saga: George Smiley, followed by: The Russia House, preceded by: The Night Manager\n",
      "2039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 480 pages, best-seller: No, film: Yes, saga: No, followed by: The Rooster Bar, preceded by: nan\n",
      "2040\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2041\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2042\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2043\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2044\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: 4.50 from Paddington, preceded by: Cat Among the Pigeons\n",
      "2045\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2046\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2047\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Shadows Of Steel, preceded by: The Tin Man\n",
      "2048\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2049\n",
      "Found 270 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2050\n",
      "Found 273 pages, best-seller: No, film: Yes, saga: No, followed by: Bones of the Moon, preceded by: A Child Across the Sky\n",
      "2051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2052\n",
      "Found 169 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2054\n",
      "Found 369 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 617 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: Series 4, followed by: nan, preceded by: nan\n",
      "2058\n",
      "Found 512 pages, best-seller: No, film: No, saga: American Empire, followed by: The Great War: Breakthroughs, preceded by: American Empire: The Center Cannot Hold\n",
      "2059\n",
      "Found 192 pages, best-seller: No, film: No, saga: The Cadfael Chronicles, followed by: Dead Man's Ransom, preceded by: An Excellent Mystery\n",
      "2060\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: Summer of Night, preceded by: nan\n",
      "2061\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2062\n",
      "Found 448 pages, best-seller: No, film: No, saga: Arthurian Saga, followed by: The Hollow Hills, preceded by: The Wicked Day\n",
      "2063\n",
      "Found 468 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2064\n",
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2065\n",
      "Found nan pages, best-seller: No, film: No, saga: Guinevere trilogy, followed by: nan, preceded by: Queen of the Summer Stars\n",
      "2066\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 441 pages, best-seller: No, film: No, saga: Hyperion Cantos, followed by: The Fall of Hyperion, preceded by: The Rise of Endymion\n",
      "2068\n",
      "Found 446 pages, best-seller: No, film: No, saga: Arthurian Saga, followed by: The Crystal Cave, preceded by: The Last Enchantment\n",
      "2069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 293 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2070\n",
      "Found 446 pages, best-seller: Yes, film: Yes, saga: Odd Thomas, followed by: In Odd We Trust, preceded by: Forever Odd\n",
      "2071\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 347 pages, best-seller: No, film: Yes, saga: The Adversary Cycle, followed by: nan, preceded by: The Tomb\n",
      "2074\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2075\n",
      "Found 554 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2076\n",
      "Found 350 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 372 pages, best-seller: No, film: Yes, saga: The Dresden Files, followed by: Death Masks, preceded by: Dead Beat\n",
      "2078\n",
      "Found 207 pages, best-seller: No, film: No, saga: Oxrun Station, followed by: The Grave, preceded by: The Dark Cry of the Moon\n",
      "2079\n",
      "Found 352 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2081\n",
      "Found 468 pages, best-seller: No, film: Yes, saga: Earth's Children, followed by: nan, preceded by: The Valley of Horses\n",
      "2082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Good King Harry, preceded by: The Unquiet Earth\n",
      "2084\n",
      "Found 557 pages, best-seller: No, film: Yes, saga: No, followed by: Single & Single, preceded by: Absolute Friends\n",
      "2085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 pages, best-seller: No, film: No, saga: Kay Scarpetta, followed by: Body of Evidence, preceded by: Cruel and Unusual\n",
      "2086\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2087\n",
      "Found 2311 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2088\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2089\n",
      "Found 384 pages, best-seller: No, film: Yes, saga: No, followed by: Jumper, preceded by: Impulse\n",
      "2090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 385 pages, best-seller: No, film: No, saga: Wess'Har Series, followed by: City of Pearl, preceded by: The World Before\n",
      "2095\n",
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449237 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2097\n",
      "Found 186 pages, best-seller: No, film: Yes, saga: Nero Wolfe, followed by: A Right to Die, preceded by: Death of a Doxy\n",
      "2098\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Moomins, followed by: Tales from Moominvalley, preceded by: Moominvalley in November\n",
      "2099\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2100\n",
      "Found 214 pages, best-seller: No, film: No, saga: Mushroom Planet[1], followed by: nan, preceded by: Stowaway to the Mushroom Planet\n",
      "2101\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 330 pages, best-seller: No, film: No, saga: No, followed by: The Siege, preceded by: nan\n",
      "2103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 630 pages, best-seller: No, film: No, saga: No, followed by: Goodbye, Columbus, preceded by: When She Was Good\n",
      "2104\n",
      "Found 272 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2105\n",
      "Found 471 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 546 pages, best-seller: Yes, film: Yes, saga: No, followed by: Clockers, preceded by: Samaritan\n",
      "2107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 560 pages, best-seller: No, film: No, saga: Revelation Space, followed by: nan, preceded by: Chasm City\n",
      "2108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 145 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2110\n",
      "Found 107 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2111\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 766879 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Twelve\n",
      "2113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 pages, best-seller: No, film: No, saga: Doctor Whobook:New Series Adventures, followed by: The Way Through the Woods, preceded by: Touched by an Angel\n",
      "2114\n",
      "Found 357 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2115\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2116\n",
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2117\n",
      "Found 194 pages, best-seller: No, film: No, saga: Regional Novels, followed by: Bayou Suzette, preceded by: Judy's Journey\n",
      "2118\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2119\n",
      "Found 368 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 274 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2122\n",
      "Found 374 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2123\n",
      "Found 172 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2124\n",
      "Found 32 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: When I'm Big: A Guess How Much I Love You Storybook\n",
      "2125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2126\n",
      "Found 493 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 337 pages, best-seller: No, film: Yes, saga: Meg, followed by: nan, preceded by: The Trench\n",
      "2128\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2129\n",
      "Found 344 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2130\n",
      "Found 244 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2131\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2132\n",
      "Found 252 pages, best-seller: No, film: No, saga: Blackford Oakes, followed by: Saving the Queen, preceded by: Who's on First\n",
      "2133\n",
      "Found 292 pages, best-seller: No, film: No, saga: Dragonriders of Pern, followed by: The Skies of Pern, preceded by: Dragonsblood\n",
      "2134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2135\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2136\n",
      "Found 416 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 262 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 496 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Gridlock (1991)\n",
      "2141\n",
      "Found 314 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2142\n",
      "Found 715 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2143\n",
      "Found 384 pages, best-seller: No, film: Yes, saga: No, followed by: A Perfect Spy, preceded by: The Secret Pilgrim\n",
      "2144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 212 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 344 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Reflex\n",
      "2146\n",
      "Found 247 pages, best-seller: No, film: No, saga: No, followed by: Gun, with Occasional Music, preceded by: The Wall of the Sky, the Wall of the Eye\n",
      "2147\n",
      "Found 432 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2148\n",
      "Found 528 pages, best-seller: No, film: No, saga: Eight Worlds, followed by: Steel Beach, preceded by: Irontown Blues\n",
      "2149\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 281 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 447 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2152\n",
      "Found 109 pages, best-seller: No, film: No, saga: Dangerous Angels, followed by: nan, preceded by: Witch Baby\n",
      "2153\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2154\n",
      "Found 237 pages, best-seller: No, film: No, saga: Vorkosigan Saga, followed by: The Warrior's Apprentice, preceded by: Falling Free\n",
      "2155\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: The Culture, followed by: Consider Phlebas, preceded by: Use of Weapons\n",
      "2156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 464 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2158\n",
      "Found nan pages, best-seller: No, film: No, saga: North American Confederacy, followed by: nan, preceded by: The Venus Belt (by publication), The Nagasaki Vector (by chronology)\n",
      "2159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 498 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Heaven\n",
      "2160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 631 pages, best-seller: No, film: No, saga: Empire of Man\\Roger MacClintock series, followed by: March Upcountry, preceded by: March to the Stars\n",
      "2161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2162\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2163\n",
      "Found 530 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2164\n",
      "Found 314 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2165\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2166\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Wreck of the Zephyr, preceded by: The Polar Express\n",
      "2167\n",
      "Found 641 pages, best-seller: No, film: Yes, saga: No, followed by: The Cat in the Hat(publication date)Horton Hears a Who!(in universe), preceded by: The Cat in the Hat Comes Back\n",
      "2168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 464 pages, best-seller: No, film: No, saga: The Enemy, followed by: The Fear, preceded by: The Fallen\n",
      "2169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2172\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2173\n",
      "Found 400 pages, best-seller: No, film: No, saga: Amelia Peabody seriesmysteries, followed by: The Golden One, preceded by: Guardian of the Horizon\n",
      "2174\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2175\n",
      "Found 392 pages, best-seller: No, film: No, saga: Vorkosigan Saga, followed by: Barrayar, preceded by: Cetaganda\n",
      "2176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2179\n",
      "Found 3821997 pages, best-seller: No, film: Yes, saga: No, followed by: The Rolling Stones(shared character), preceded by: nan\n",
      "2180\n",
      "Found 214 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2181\n",
      "Found 3351 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2182\n",
      "Found 22662579 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 308 pages, best-seller: No, film: Yes, saga: Alex Cross, followed by: London Bridges, preceded by: Cross\n",
      "2184\n",
      "Found 304 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2185\n",
      "Found 224 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2187\n",
      "Found 96 pages, best-seller: No, film: Yes, saga: Roald Dahl Collection, followed by: nan, preceded by: nan\n",
      "2188\n",
      "Found 24 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2189\n",
      "Found 62 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2190\n",
      "Found 251 pages, best-seller: Yes, film: Yes, saga: Harry Potter, followed by: Harry Potter and the Philosopher's Stone, preceded by: Harry Potter and the Prisoner of Azkaban\n",
      "2191\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2192\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Detective, preceded by: nan\n",
      "2194\n",
      "Found 87 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2195\n",
      "Found 2141 pages, best-seller: Yes, film: No, saga: No, followed by: I Know Why the Caged Bird Sings, preceded by: Singin' and Swingin' and Gettin' Merry like Christmas\n",
      "2196\n",
      "Found 23013712 pages, best-seller: No, film: Yes, saga: Little House, followed by: Little House in the Big Woods, preceded by: Little House on the Prairie\n",
      "2197\n",
      "Found 209 pages, best-seller: No, film: No, saga: No, followed by: Death Comes as the End, preceded by: The Hollow\n",
      "2198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 231 pages, best-seller: No, film: No, saga: Green Sky Trilogy, followed by: nan, preceded by: And All Between\n",
      "2199\n",
      "Found 423 pages, best-seller: No, film: No, saga: No, followed by: The Trespasser, preceded by: The Rainbow\n",
      "2200\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Anne of Green Gables, followed by: Anne of the Island, preceded by: Anne's House of Dreams\n",
      "2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 188 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2202\n",
      "Found 350 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2203\n",
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: Three Blind Mice and Other Stories, preceded by: The Under Dog and Other Stories\n",
      "2204\n",
      "Found 560 pages, best-seller: No, film: No, saga: Revelation Space, followed by: nan, preceded by: Chasm City\n",
      "2205\n",
      "Found 252 pages, best-seller: No, film: No, saga: Garrett P.I., followed by: Cold Copper Tears, preceded by: Dread Brass Shadows\n",
      "2206\n",
      "Found 347 pages, best-seller: No, film: No, saga: Garrett P.I., followed by: Red Iron Nights, preceded by: Petty Pewter Gods\n",
      "2207\n",
      "Found 216 pages, best-seller: Yes, film: Yes, saga: Jim Chee/Joe LeaphornNavajo Tribal Police Series, followed by: The Ghostway(1984), preceded by: A Thief of Time (1988)\n",
      "2208\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2209\n",
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2210\n",
      "Found 248 pages, best-seller: No, film: No, saga: Chronicles of Master Li and Number Ten Ox, followed by: nan, preceded by: The Story of the Stone\n",
      "2211\n",
      "Found 293 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2212\n",
      "Found 412 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 423 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2214\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Other People, preceded by: London Fields\n",
      "2215\n",
      "Found 356 pages, best-seller: No, film: Yes, saga: No, followed by: The Heritage of the West, preceded by: The Rainbow Trail\n",
      "2216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 451 pages, best-seller: No, film: Yes, saga: Bob Lee Swaggerseries, followed by: nan, preceded by: Black Light\n",
      "2217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 625 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2220\n",
      "Found 330 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2221\n",
      "Found 219 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2222\n",
      "Found 209 pages, best-seller: No, film: No, saga: Ballantine Adult Fantasy series, followed by: nan, preceded by: nan\n",
      "2223\n",
      "Found 371 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 384 pages, best-seller: No, film: Yes, saga: No, followed by: Inconceivable (1999), preceded by: High Society (2002)\n",
      "2225\n",
      "Found 368336 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2226\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 218 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2228\n",
      "Found 560 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2229\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2230\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2231\n",
      "Found 557 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Jennie Gerhardt\n",
      "2232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2233\n",
      "Found 484 pages, best-seller: No, film: No, saga: Erekosë, followed by: nan, preceded by: Phoenix in Obsidian\n",
      "2234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 531517 pages, best-seller: No, film: No, saga: Dirk PittNovels, followed by: Atlantis Found, preceded by: Trojan Odyssey\n",
      "2235\n",
      "Found 286 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 264 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2237\n",
      "Found 352 pages, best-seller: No, film: No, saga: No, followed by: Flinx in Flux, preceded by: Reunion\n",
      "2238\n",
      "Found nan pages, best-seller: No, film: No, saga: Humanx Commonwealth, followed by: nan, preceded by: nan\n",
      "2239\n",
      "Found 368 pages, best-seller: Yes, film: No, saga: Darkseries, followed by: Dark Magic, preceded by: Dark Fire\n",
      "2240\n",
      "Found 368 pages, best-seller: No, film: No, saga: Darkseries, followed by: Dark Gold, preceded by: Dark Challenge\n",
      "2241\n",
      "Found 784 pages, best-seller: No, film: No, saga: No, followed by: Iron Gold, preceded by: Light Bringer\n",
      "2242\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2243\n",
      "Found 373 pages, best-seller: No, film: No, saga: No, followed by: Beatniks(1997), preceded by: deadkidsongs (2001)\n",
      "2244\n",
      "Found 274 pages, best-seller: No, film: No, saga: No, followed by: Ishmael,The Story of B, preceded by: nan\n",
      "2245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2246\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: Pride and Prejudice, preceded by: Emma\n",
      "2247\n",
      "Found 292 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2248\n",
      "Found 249288 pages, best-seller: No, film: No, saga: The Brentford Trilogy, followed by: nan, preceded by: The Brentford Triangle\n",
      "2249\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2251\n",
      "Found 152 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2252\n",
      "Found 260 pages, best-seller: No, film: Yes, saga: Little House, followed by: On the Banks of Plum Creek, preceded by: The Long Winter\n",
      "2253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 424 pages, best-seller: No, film: Yes, saga: No, followed by: Tales from Firozsha Bag, preceded by: A Fine Balance\n",
      "2254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 pages, best-seller: No, film: No, saga: Inspector Morseseries, #2, followed by: Last Bus to Woodstock, preceded by: The Silent World of Nicholas Quinn\n",
      "2255\n",
      "Found 241 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2257\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2258\n",
      "Found 389 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Second Generation (1978)\n",
      "2259\n",
      "Found 178 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 384 pages, best-seller: No, film: No, saga: Matthew Shardlake Series, followed by: Dissolution, preceded by: Sovereign\n",
      "2262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 pages, best-seller: No, film: No, saga: Spenser, followed by: Back Story, preceded by: Cold Service\n",
      "2263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2264\n",
      "Found 233 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Star Trek:The Next Generation, followed by: nan, preceded by: nan\n",
      "2266\n",
      "Found 265 pages, best-seller: No, film: Yes, saga: Fletchseries, followed by: nan, preceded by: Fletch, Too\n",
      "2267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Lies of Silence(1990), preceded by: The Magician's Wife (1997)\n",
      "2268\n",
      "Found 335353 pages, best-seller: No, film: No, saga: Dragonriders of Pern, followed by: The Dolphins of Pern, preceded by: The Master Harper of Pern\n",
      "2269\n",
      "Found 496 pages, best-seller: No, film: No, saga: Great War, followed by: The Great War: Walk in Hell, preceded by: American Empire: Blood and Iron\n",
      "2270\n",
      "Found 160826 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2272\n",
      "Found 336 pages, best-seller: No, film: No, saga: No, followed by: Climbing Mount Improbable, preceded by: A Devil's Chaplain\n",
      "2273\n",
      "Found 327 pages, best-seller: No, film: No, saga: Vurt series, followed by: Vurt, preceded by: Automated Alice\n",
      "2274\n",
      "Found 573 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2275\n",
      "Found 230 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Burmese Days\n",
      "2276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: TrainspottingandGlue, preceded by: The Blade Artist and A Decent Ride\n",
      "2277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 510 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2280\n",
      "Found nan pages, best-seller: No, film: No, saga: ATrilogy of Desire, followed by: nan, preceded by: The Titan\n",
      "2281\n",
      "Found 416 pages, best-seller: Yes, film: No, saga: No, followed by: The Millionaire Next Door, preceded by: Millionaire Women Next Door\n",
      "2282\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2283\n",
      "Found 117 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2284\n",
      "Found 494 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2285\n",
      "Found 688 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2286\n",
      "Found 278 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2287\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2288\n",
      "Found 245 pages, best-seller: No, film: Yes, saga: No, followed by: The Water-Method Man, preceded by: The World According to Garp\n",
      "2289\n",
      "Found 399 pages, best-seller: No, film: Yes, saga: Dragonlance Chronicles, followed by: Dragons of Autumn Twilight, preceded by: Dragons of Spring Dawning\n",
      "2290\n",
      "Found 184 pages, best-seller: No, film: Yes, saga: Nero Wolfe, followed by: And Four to Go, preceded by: Plot It Yourself\n",
      "2291\n",
      "Found 3521 pages, best-seller: No, film: No, saga: Lord Peter Wimsey, followed by: Have His Carcase, preceded by: The Nine Tailors\n",
      "2292\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2293\n",
      "Found 134 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2294\n",
      "Found 251 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: Water Tales #1, followed by: nan, preceded by: nan\n",
      "2296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 151 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 368 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2298\n",
      "Found 305 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Search for the Dice Man\n",
      "2299\n",
      "Found 179 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2300\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Dear Enemy\n",
      "2302\n",
      "Found 112 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2303\n",
      "Found 448 pages, best-seller: No, film: No, saga: No, followed by: The Secret of Black Ship Island, preceded by: nan\n",
      "2304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 432 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2305\n",
      "Found 377 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2306\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The First Immortal\n",
      "2307\n",
      "Found 217 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 529 pages, best-seller: Yes, film: No, saga: Inspector Rebus, followed by: Black and Blue, preceded by: Dead Souls\n",
      "2309\n",
      "Found 339 pages, best-seller: No, film: No, saga: The Chronicles of the Deryni, followed by: Deryni Checkmate, preceded by: Camber of Culdi (next published), The Bishop's Heir (literary chronology)\n",
      "2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 369 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2312\n",
      "Found 768 pages, best-seller: No, film: No, saga: Earth's Children, followed by: The Valley of Horses, preceded by: The Plains of Passage\n",
      "2313\n",
      "Found 2762922004 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2314\n",
      "Found 1622 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2315\n",
      "Found 17621911 pages, best-seller: No, film: No, saga: The Borrowers, followed by: The Borrowers Afield, preceded by: The Borrowers Aloft\n",
      "2316\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 374 pages, best-seller: No, film: No, saga: Jack Reacher, followed by: Killing Floor, preceded by: Tripwire\n",
      "2318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2319\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2320\n",
      "Found 535 pages, best-seller: No, film: Yes, saga: No, followed by: The Remains of the Day, preceded by: When We Were Orphans\n",
      "2321\n",
      "Found 294 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Brothers K\n",
      "2322\n",
      "Found 740 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2323\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2324\n",
      "Found 291 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2325\n",
      "Found 165 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: 1979\n",
      "2326\n",
      "Found 304 pages, best-seller: No, film: Yes, saga: Discworld4th novel – 1st Death story, followed by: Equal Rites, preceded by: Sourcery\n",
      "2327\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2328\n",
      "Found 385 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2329\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2330\n",
      "Found 64 pages, best-seller: No, film: Yes, saga: 1, followed by: Mr. Brown Can Moo! Can You?, preceded by: Marvin K. Mooney Will You Please Go Now!\n",
      "2331\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2332\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2333\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: The Tale of Peter Rabbit, preceded by: The Tailor of Gloucester\n",
      "2334\n",
      "Found 64 pages, best-seller: Yes, film: Yes, saga: No, followed by: The Seven Lady Godivas, preceded by: McElligot's PoolHorton Hears a Who! (plotwise)\n",
      "2335\n",
      "Found 416 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2336\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 303 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2338\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Grantchester Grind\n",
      "2339\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: The Passage, preceded by: The City of Mirrors\n",
      "2341\n",
      "Found 2221 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2342\n",
      "Found 200 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2343\n",
      "Found 326 pages, best-seller: No, film: No, saga: The Cornish Trilogy, followed by: nan, preceded by: What's Bred in the Bone\n",
      "2344\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2345\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Discworld8th novel – 1st City Watch story, followed by: Pyramids, preceded by: Eric\n",
      "2346\n",
      "Found 241 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2347\n",
      "Found 2161 pages, best-seller: No, film: Yes, saga: No, followed by: The Vengeance Trail of Josey Wales, preceded by: Watch for Me on the Mountain\n",
      "2348\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2349\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2350\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2351\n",
      "Found 496 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2352\n",
      "Found 240 pages, best-seller: Yes, film: Yes, saga: Alex Rider series, followed by: nan, preceded by: Point Blanc\n",
      "2353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 432 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3691 pages, best-seller: Yes, film: Yes, saga: No, followed by: The Man in the Gray Flannel Suit, preceded by: nan\n",
      "2355\n",
      "Found 256 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2356\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2357\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2358\n",
      "Found 669 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2359\n",
      "Found 40 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 366 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Running Mate\n",
      "2361\n",
      "Found 209 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2362\n",
      "Found 496 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2363\n",
      "Found 557 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2364\n",
      "Found 400 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2366\n",
      "Found 309 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2367\n",
      "Found 264 pages, best-seller: No, film: Yes, saga: No, followed by: Trainspotting, preceded by: Filth\n",
      "2368\n",
      "Found 192 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2370\n",
      "Found 279 pages, best-seller: No, film: Yes, saga: No, followed by: Miss Wyoming, preceded by: Hey Nostradamus!\n",
      "2371\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2372\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 365 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2374\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2375\n",
      "Found 227 pages, best-seller: No, film: No, saga: Den of Shadows, followed by: Demon in My View(2000), preceded by: Midnight Predator(2002)\n",
      "2376\n",
      "Found 176 pages, best-seller: No, film: No, saga: Den of Shadows, followed by: In the Forests of the Night(1999), preceded by: Shattered Mirror(2001)\n",
      "2377\n",
      "Found 327 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2378\n",
      "Found 319 pages, best-seller: No, film: Yes, saga: No, followed by: The Comedians, preceded by: The Honorary Consul\n",
      "2379\n",
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2380\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Heinlein juveniles, followed by: Starman Jones, preceded by: Tunnel in the Sky\n",
      "2383\n",
      "Found 255 pages, best-seller: No, film: No, saga: Chronicles of Master Li and Number Ten Ox, followed by: The Story of the Stone;Also published in omnibus edition:The Chronicles of Master Li and Number Ten Ox., preceded by: nan\n",
      "2384\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2385\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2386\n",
      "Found 1902 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2387\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2388\n",
      "Found 271 pages, best-seller: Yes, film: No, saga: Cornelius Murphy Trilogy, followed by: nan, preceded by: Raiders of the Lost Car Park\n",
      "2389\n",
      "Found 287 pages, best-seller: No, film: Yes, saga: Cordelia GrayNo. 1, followed by: nan, preceded by: The Skull Beneath the Skin\n",
      "2390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 157 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2391\n",
      "Found 4281480 pages, best-seller: No, film: No, saga: Gabriel Allonseries, followed by: The Marching Season, preceded by: The English Assassin\n",
      "2392\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2393\n",
      "Found 96 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2394\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2395\n",
      "Found 432 pages, best-seller: No, film: No, saga: Jack Reacher, followed by: Echo Burning, preceded by: Persuader\n",
      "2396\n",
      "Found 343 pages, best-seller: No, film: No, saga: Jack Reacher, followed by: Die Trying, preceded by: Running Blind\n",
      "2397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16320825 pages, best-seller: Yes, film: Yes, saga: No, followed by: The Pilgrimage(1987), preceded by: Brida (1990)\n",
      "2398\n",
      "Found 280 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2399\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2401\n",
      "Found 312 pages, best-seller: No, film: No, saga: Lord Peter Wimsey, followed by: Busman's Honeymoon, preceded by: A Presumption of Death\n",
      "2402\n",
      "Found 204 pages, best-seller: No, film: No, saga: The Riddle Master Trilogy, followed by: The Riddle-Master of Hed, preceded by: Harpist in the Wind\n",
      "2403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 204 pages, best-seller: No, film: Yes, saga: No, followed by: Concrete Island(1974), preceded by: The Unlimited Dream Company (1979)\n",
      "2404\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 429 pages, best-seller: No, film: No, saga: Amelia Peabody seriesmysteries, followed by: Lord of the Silent, preceded by: Children of the Storm\n",
      "2406\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Assistant (1957)\n",
      "2407\n",
      "Found 135 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2408\n",
      "Found 288292 pages, best-seller: No, film: No, saga: Aurelio Zen series, #1, followed by: nan, preceded by: Vendetta\n",
      "2409\n",
      "Found 487 pages, best-seller: No, film: Yes, saga: No, followed by: Mr. Sammler's Planet, preceded by: The Dean's December\n",
      "2410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 368 pages, best-seller: Yes, film: No, saga: Pendergast, followed by: Fever Dream, preceded by: Two Graves\n",
      "2412\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2413\n",
      "Found 460 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 454 pages, best-seller: No, film: No, saga: Adam Dalgliesh#7, followed by: Death of an Expert Witness, preceded by: Devices and Desires\n",
      "2415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2416\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Uncle Fred in the Springtime, preceded by: \"Birth of a Salesman\" (short), Pigs Have Wings (novel)\n",
      "2417\n",
      "Found 418 pages, best-seller: No, film: Yes, saga: The Books of Abarat, followed by: nan, preceded by: Days of Magic, Nights of War\n",
      "2418\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2419\n",
      "Found 326 pages, best-seller: No, film: No, saga: No, followed by: Ecotopia, preceded by: nan\n",
      "2420\n",
      "Found 35213392 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2421\n",
      "Found 384 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2422\n",
      "Found 189 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2424\n",
      "Found 451 pages, best-seller: No, film: No, saga: The Culture, followed by: The State of the Art, preceded by: Inversions\n",
      "2425\n",
      "Found 98 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2426\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2427\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 345 pages, best-seller: No, film: No, saga: No, followed by: Excession, preceded by: Look to Windward\n",
      "2429\n",
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2430\n",
      "Found 298 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2431\n",
      "Found 208 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2432\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2433\n",
      "Found 517 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Strong Motion\n",
      "2434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Harry Bosch, followed by: nan, preceded by: The Black Ice\n",
      "2435\n",
      "Found 159 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2436\n",
      "Found 47 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2437\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 pages, best-seller: No, film: No, saga: No, followed by: Tell Me Your Dreams, preceded by: Are You Afraid Of The Dark?\n",
      "2439\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Things Fall Apart, preceded by: Arrow of God\n",
      "2440\n",
      "Found 337544368 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Midnight: A Gangster Love Story (2008)\n",
      "2441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2442\n",
      "Found 36 pages, best-seller: Yes, film: Yes, saga: The Chicka Chicka Boom Boom Series, followed by: N/A, preceded by: Chicka Chicka 1, 2, 3\n",
      "2443\n",
      "Found 64 pages, best-seller: No, film: Yes, saga: No, followed by: Patty's Pet, preceded by: Sammy the Seal\n",
      "2444\n",
      "Found 209 pages, best-seller: No, film: No, saga: No, followed by: The Heart of a Woman, preceded by: A Song Flung Up to Heaven\n",
      "2445\n",
      "Found 279 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2446\n",
      "Found 242 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 444 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2448\n",
      "Found 608 pages, best-seller: Yes, film: Yes, saga: Cole Family series, followed by: nan, preceded by: nan\n",
      "2449\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2450\n",
      "Found 282 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2451\n",
      "Found 373 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2452\n",
      "Found 400 pages, best-seller: No, film: No, saga: Young Wizards, followed by: None, preceded by: Deep Wizardry\n",
      "2453\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2454\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: Where Are the Children?, preceded by: The Cradle Will Fall\n",
      "2455\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: A Man of the People, preceded by: There was a Country: A Personal History of Biafra\n",
      "2456\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2457\n",
      "Found 167 pages, best-seller: No, film: No, saga: No, followed by: Arrow of God, preceded by: Anthills of the Savannah\n",
      "2458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2459\n",
      "Found 640 pages, best-seller: No, film: No, saga: Adam Dalgliesh, No. 11, followed by: A Certain Justice, preceded by: The Murder Room\n",
      "2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: HMS Ulysses, preceded by: South by Java Head\n",
      "2461\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2462\n",
      "Found 324 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2463\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 934 pages, best-seller: No, film: Yes, saga: No, followed by: The Last Frontier, preceded by: Fear Is the Key\n",
      "2465\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 pages, best-seller: Yes, film: Yes, saga: No, followed by: The Way to Dusty Death, preceded by: Circus\n",
      "2467\n",
      "Found 286 pages, best-seller: No, film: Yes, saga: No, followed by: Empire of the Sun, preceded by: nan\n",
      "2468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Rachel Papers, preceded by: Success\n",
      "2469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: A Handful of Dust, preceded by: Put Out More Flags\n",
      "2471\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2472\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2473\n",
      "Found nan pages, best-seller: No, film: No, saga: Albert Campion, followed by: Mystery Mile, preceded by: Police at the Funeral\n",
      "2474\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2475\n",
      "Found 576 pages, best-seller: No, film: Yes, saga: Danzig Trilogy, followed by: nan, preceded by: Cat and Mouse\n",
      "2476\n",
      "Found 312 pages, best-seller: No, film: Yes, saga: No, followed by: The Hotel(1927), preceded by: Friends and Relations (1931)\n",
      "2477\n",
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2478\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2479\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Marrying Buddha\n",
      "2480\n",
      "Found 269 pages, best-seller: No, film: No, saga: Inspector Wexford#13, followed by: The Speaker of Mandarin, preceded by: The Veiled One\n",
      "2481\n",
      "Found 336 pages, best-seller: No, film: No, saga: No, followed by: A Dark-Adapted Eye, preceded by: The House of Stairs\n",
      "2482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 509 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 236 pages, best-seller: No, film: No, saga: Adam Dalgliesh#3, followed by: A Mind to Murder, preceded by: Shroud for a Nightingale\n",
      "2484\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2485\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2486\n",
      "Found 402 pages, best-seller: No, film: Yes, saga: No, followed by: Put Out More Flags(1942), preceded by: Scott-King's Modern Europe (1947)\n",
      "2487\n",
      "Found 254 pages, best-seller: No, film: Yes, saga: No, followed by: Decline and Fall, preceded by: Black Mischief\n",
      "2488\n",
      "Found 576329439 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2489\n",
      "Found 160 pages, best-seller: No, film: No, saga: Rabbi Small, followed by: nan, preceded by: nan\n",
      "2490\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2491\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Trilogy[citation needed], followed by: nan, preceded by: The Deluge, Fire in the Steppe\n",
      "2492\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2493\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2494\n",
      "Found 384 pages, best-seller: No, film: No, saga: No, followed by: Fortune's Rocks, preceded by: The Pilot's Wife\n",
      "2495\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2497\n",
      "Found 512 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2498\n",
      "Found 204 pages, best-seller: No, film: No, saga: No, followed by: -, preceded by: Indecent Exposure\n",
      "2499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 993 pages, best-seller: No, film: No, saga: No, followed by: Shirley, preceded by: The Professor\n",
      "2500\n",
      "Found 221 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2501\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2502\n",
      "Found 445 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2503\n",
      "Found 442 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2505\n",
      "Found 284 pages, best-seller: No, film: No, saga: No, followed by: The Pursuit of Love, preceded by: Don't Tell Alfred\n",
      "2506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: East or West, followed by: The Silver Dove, preceded by: nan\n",
      "2507\n",
      "Found 245 pages, best-seller: No, film: No, saga: Doctor Whobook:New Series Adventures, followed by: The King's Dragon, preceded by: The Coming of the Terraphiles\n",
      "2508\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Siddhartha\n",
      "2509\n",
      "Found 302 pages, best-seller: No, film: No, saga: Horatio Hornblower, followed by: Lieutenant Hornblower(1952), preceded by: Hornblower and the Crisis (1967)\n",
      "2510\n",
      "Found 300 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2511\n",
      "Found 430 pages, best-seller: No, film: Yes, saga: No, followed by: Smiley's People, preceded by: A Perfect Spy\n",
      "2512\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2513\n",
      "Found 475688 pages, best-seller: No, film: No, saga: No, followed by: The Little Drummer Girl, preceded by: The Russia House\n",
      "2514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 318 pages, best-seller: No, film: Yes, saga: James Bond, followed by: Dr. No, preceded by: For Your Eyes Only\n",
      "2515\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Spy Line\n",
      "2516\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Big Sleep, preceded by: The High Window\n",
      "2517\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: How Sleep the Brave(1943), preceded by: The Cruise of the Breadwinner (1946)\n",
      "2518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2519\n",
      "Found 279 pages, best-seller: No, film: Yes, saga: No, followed by: Parker Pyne Investigates, preceded by: Death in the Clouds\n",
      "2520\n",
      "Found 246 pages, best-seller: No, film: Yes, saga: No, followed by: Running Blind, preceded by: The Tightrope Men\n",
      "2521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 318 pages, best-seller: No, film: No, saga: No, followed by: Bahama Crisis, preceded by: Night of Error\n",
      "2522\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2523\n",
      "Found 224 pages, best-seller: Yes, film: Yes, saga: No, followed by: Poirot's Early Cases, preceded by: Sleeping Murder\n",
      "2524\n",
      "Found 216 pages, best-seller: No, film: Yes, saga: No, followed by: Hickory Dickory Dock, preceded by: The Burden\n",
      "2525\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: Endless Night, preceded by: Hallowe'en Party\n",
      "2526\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2527\n",
      "Found 181 pages, best-seller: No, film: No, saga: Hardy Boys, followed by: The Sting of the Scorpion, preceded by: Mystery of the Samurai Sword\n",
      "2528\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2529\n",
      "Found 416 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2530\n",
      "Found 4011998 pages, best-seller: No, film: Yes, saga: Waverley Novels, followed by: A Legend of Montrose, preceded by: The Monastery\n",
      "2531\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Hunches in Bunches, preceded by: You're Only Old Once!\n",
      "2532\n",
      "Found 406 pages, best-seller: No, film: Yes, saga: L.A. Quartet, followed by: The Black Dahlia(1987), preceded by: L.A. Confidential (1990)\n",
      "2533\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 496 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2537\n",
      "Found 1074 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2538\n",
      "Found 192 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: My Brother, My Sister, and I\n",
      "2539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: O Pioneers!, preceded by: My Ántonia\n",
      "2540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 442 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352356 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2542\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2543\n",
      "Found 271 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2544\n",
      "Found 374 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2545\n",
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: Term Limits, preceded by: The Third Option\n",
      "2546\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2547\n",
      "Found 157 pages, best-seller: No, film: Yes, saga: George Smiley, followed by: nan, preceded by: A Murder of Quality\n",
      "2548\n",
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Presumed Innocent\n",
      "2549\n",
      "Found 224192 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2550\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2551\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2552\n",
      "Found 275 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2553\n",
      "Found 198 pages, best-seller: No, film: No, saga: No, followed by: Microserfs, preceded by: Girlfriend in a Coma\n",
      "2554\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2555\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2556\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2557\n",
      "Found 2404 pages, best-seller: No, film: Yes, saga: Collection Blanche, followed by: nan, preceded by: nan\n",
      "2558\n",
      "Found 283 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2559\n",
      "Found 272 pages, best-seller: No, film: No, saga: Hazelwood High Trilogy, followed by: Forged by Fire, preceded by: nan\n",
      "2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2561\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 642 pages, best-seller: Yes, film: Yes, saga: Robert Langdon#4, followed by: The Lost Symbol, preceded by: Origin\n",
      "2563\n",
      "Found nan pages, best-seller: No, film: No, saga: Jim Chee/Joe LeaphornNavajo Tribal Police Series, followed by: Dance Hall of the Dead(1973), preceded by: People of Darkness (1980)\n",
      "2564\n",
      "Found 468 pages, best-seller: Yes, film: Yes, saga: No, followed by: The 48 Laws of Power, preceded by: The 33 Strategies of War\n",
      "2565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2566\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Discworld10th novel – 2nd individual story, followed by: Eric, preceded by: Reaper Man\n",
      "2567\n",
      "Found 303 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2568\n",
      "Found 280 pages, best-seller: No, film: Yes, saga: No, followed by: Suicide Hill(1985), preceded by: The Black Dahlia (1987)\n",
      "2569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2570\n",
      "Found 226 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2571\n",
      "Found 560 pages, best-seller: No, film: No, saga: Revelation Space, followed by: nan, preceded by: Chasm City\n",
      "2572\n",
      "Found 249 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2573\n",
      "Found nan pages, best-seller: No, film: Yes, saga: 2525318047, followed by: nan, preceded by: nan\n",
      "2574\n",
      "Found 1152 pages, best-seller: No, film: No, saga: The Asian Saga, followed by: N/A, preceded by: 'Tai-Pan\n",
      "2575\n",
      "Found 371 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2576\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 447 pages, best-seller: No, film: No, saga: No, followed by: Something Happened, preceded by: God Knows\n",
      "2578\n",
      "Found 304 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2579\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: Widow's Walk, preceded by: Bad Business\n",
      "2581\n",
      "Found 14122377 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2582\n",
      "Found 190 pages, best-seller: No, film: No, saga: Jeeves, followed by: Jeeves in the Offing, preceded by: Much Obliged, Jeeves\n",
      "2583\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2584\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 303 pages, best-seller: No, film: Yes, saga: No, followed by: Thumbsucker(1999), preceded by: Mission to America (2005)\n",
      "2586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 326 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2587\n",
      "Found 496480 pages, best-seller: No, film: No, saga: Dirk PittNovels, followed by: Valhalla Rising, preceded by: Black Wind\n",
      "2588\n",
      "Found 2081 pages, best-seller: No, film: Yes, saga: No, followed by: The Kraken Wakes, preceded by: The Midwich Cuckoos\n",
      "2589\n",
      "Found 419 pages, best-seller: No, film: No, saga: Robotseries, followed by: The Naked Sun, \"Mirror Image\", preceded by: Robots and Empire\n",
      "2590\n",
      "Found 448 pages, best-seller: No, film: Yes, saga: No, followed by: Stark (1989), preceded by: This Other Eden (1993)\n",
      "2591\n",
      "Found 277 pages, best-seller: No, film: No, saga: No, followed by: Small World: An Academic Romance, preceded by: nan\n",
      "2592\n",
      "Found 494 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2593\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: Sally Lockhartseries, followed by: The Ruby in the Smoke, preceded by: The Tiger in the Well\n",
      "2594\n",
      "Found 178 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: James Miranda Barry\n",
      "2595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 199208 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2596\n",
      "Found 200 pages, best-seller: No, film: Yes, saga: Sally Lockhartseries, followed by: nan, preceded by: The Shadow in the North\n",
      "2597\n",
      "Found 288 pages, best-seller: No, film: No, saga: Inspector Morseseries, #10, followed by: The Jewel That Was Ours, preceded by: The Daughters of Cain\n",
      "2598\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: Aubrey-Maturin series, followed by: The Far Side of the World, preceded by: The Letter of Marque\n",
      "2599\n",
      "Found 284 pages, best-seller: No, film: Yes, saga: Aubrey-Maturin series, followed by: The Reverse of the Medal, preceded by: The Thirteen-Gun Salute\n",
      "2600\n",
      "Found 453464 pages, best-seller: No, film: No, saga: Heritage of Shannara, followed by: The Elf Queen of Shannara, preceded by: Ilse Witch\n",
      "2601\n",
      "Found 424 pages, best-seller: No, film: No, saga: Ringworld,Known Space, followed by: The Ringworld Engineers, preceded by: Ringworld's Children\n",
      "2602\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: Rune Trilogy, followed by: Manhattan Is My Beat, preceded by: Hard News\n",
      "2603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 396 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Sewer, Gas & Electric\n",
      "2604\n",
      "Found 320 pages, best-seller: No, film: Yes, saga: James Bond, followed by: nan, preceded by: nan\n",
      "2605\n",
      "Found 208 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Truncat\n",
      "2606\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2607\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2608\n",
      "Found 640 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Grail Prince\n",
      "2609\n",
      "Found 2451 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2610\n",
      "Found nan pages, best-seller: No, film: No, saga: Revelation Space, followed by: Revelation Space, preceded by: Redemption Ark\n",
      "2611\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2613\n",
      "Found 215 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2614\n",
      "Found 400 pages, best-seller: No, film: No, saga: No, followed by: The Masked Rider: Cycling in West Africa, preceded by: Traveling Music: Playing Back the Soundtrack to My Life and Times\n",
      "2615\n",
      "Found 324 pages, best-seller: No, film: Yes, saga: Austin family, followed by: The Young Unicorns, preceded by: Troubling a Star\n",
      "2616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2617\n",
      "Found 199 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Dermaphoria\n",
      "2618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3201 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2619\n",
      "Found 240 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2620\n",
      "Found 254 pages, best-seller: No, film: No, saga: No, followed by: The Gladiators, preceded by: Arrival and Departure\n",
      "2621\n",
      "Found nan pages, best-seller: No, film: No, saga: Riverworld, followed by: nan, preceded by: The Fabulous Riverboat\n",
      "2622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 216 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2623\n",
      "2624\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2626\n",
      "Found 400 pages, best-seller: No, film: No, saga: No, followed by: The Intuitionist, preceded by: The Colossus of New York\n",
      "2627\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2628\n",
      "Found 183 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32513342 pages, best-seller: No, film: Yes, saga: Little House, followed by: By the Shores of Silver Lake, preceded by: Little Town on the Prairie\n",
      "2630\n",
      "Found 520266253248 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3841 pages, best-seller: Yes, film: No, saga: The Parasol Protectorate, followed by: Changeless, preceded by: Heartless\n",
      "2632\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2634\n",
      "Found 404 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5411 pages, best-seller: No, film: Yes, saga: The Wildwood Chronicles, followed by: nan, preceded by: Under Wildwood: The Wildwood Chronicles, Book Two\n",
      "2637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2638\n",
      "Found 117 pages, best-seller: No, film: No, saga: Hainish Cycle, followed by: nan, preceded by: Planet of Exile (1966)\n",
      "2639\n",
      "Found 344 pages, best-seller: No, film: No, saga: Dirk Pittnovels, followed by: Vixen 03, preceded by: Pacific Vortex!\n",
      "2640\n",
      "Found 286 pages, best-seller: No, film: No, saga: Dirk PittNovels, followed by: Raise the Titanic!, preceded by: Night Probe!\n",
      "2641\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 233 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 196 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2644\n",
      "Found 320 pages, best-seller: No, film: No, saga: Vorkosigan SagaUniverse, followed by: A Civil Campaign, preceded by: Cryoburn\n",
      "2645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2646\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2647\n",
      "Found 273 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 pages, best-seller: No, film: No, saga: girls in love series-, followed by: nan, preceded by: Girls under Pressure\n",
      "2649\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2650\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 368 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2652\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2653\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Shamela(1741), preceded by: The Life and Death of Jonathan Wild, the Great (1743)\n",
      "2654\n",
      "Found 419 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: A Prayer for the City (1998)\n",
      "2655\n",
      "Found 219 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Curse of the Viking Grave\n",
      "2656\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2657\n",
      "Found 380 pages, best-seller: No, film: No, saga: Book of Elementals, followed by: nan, preceded by: The Crystal Palace\n",
      "2658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 496 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2659\n",
      "Found 438 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: A Quantum Murder\n",
      "2660\n",
      "Found 448 pages, best-seller: No, film: No, saga: The Zimiamvian Series, followed by: nan, preceded by: nan\n",
      "2661\n",
      "Found 343 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: One Knight Only\n",
      "2662\n",
      "Found 188 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2663\n",
      "Found 339 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2664\n",
      "Found 185 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Planet of the Robot Slaves\n",
      "2665\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Soul Clap Hands and Sing\n",
      "2666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 198 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2667\n",
      "Found 173 pages, best-seller: No, film: No, saga: 87th Precinct, followed by: Fuzz, preceded by: Jigsaw\n",
      "2668\n",
      "Found 138 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2669\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2670\n",
      "Found 304 pages, best-seller: No, film: No, saga: Sir John Fielding, #8, followed by: The Color of Death, preceded by: An Experiment In Treason\n",
      "2671\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2673\n",
      "Found nan pages, best-seller: Yes, film: No, saga: Westmoreland series, followed by: nan, preceded by: Whitney My Love\n",
      "2674\n",
      "Found 240 pages, best-seller: No, film: Yes, saga: No, followed by: Someday Angeline, preceded by: nan\n",
      "2675\n",
      "Found 576 pages, best-seller: No, film: Yes, saga: No, followed by: The Corrections, preceded by: Purity\n",
      "2676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 209 pages, best-seller: No, film: No, saga: No, followed by: her, preceded by: him\n",
      "2677\n",
      "Found 528 pages, best-seller: No, film: No, saga: Old Kingdom series, followed by: Lirael: Daughter of the Clayr, preceded by: nan\n",
      "2678\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 512 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Killer Angels\n",
      "2680\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 336 pages, best-seller: No, film: Yes, saga: No, followed by: Where Rainbows End, preceded by: A Place Called Here\n",
      "2682\n",
      "Found 191239 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2683\n",
      "Found nan pages, best-seller: No, film: No, saga: Moomins, followed by: The Exploits of Moominpappa, preceded by: Moominland Midwinter\n",
      "2684\n",
      "Found 501 pages, best-seller: No, film: No, saga: No, followed by: The Sarantine Mosaic, preceded by: The Lions of Al-Rassan\n",
      "2685\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2686\n",
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 312 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2688\n",
      "Found 279 pages, best-seller: No, film: No, saga: Down the Long Wind, followed by: nan, preceded by: Kingdom of Summer\n",
      "2689\n",
      "Found 272 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2690\n",
      "Found 400 pages, best-seller: No, film: No, saga: Amelia Peabody seriesmysteries, followed by: He Shall Thunder in the Sky, preceded by: The Golden One\n",
      "2691\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Quite Ugly One Morning,, preceded by: Not the End of the World\n",
      "2692\n",
      "Found 252 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2693\n",
      "Found 310 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 537 pages, best-seller: No, film: No, saga: Tunnels, followed by: Freefall, preceded by: Spiral\n",
      "2695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2697\n",
      "Found 200 pages, best-seller: No, film: No, saga: First authorship (Pseudonymous), followed by: Two Upbuilding Discourses, 1843, preceded by: Three Upbuilding Discourses\n",
      "2698\n",
      "Found nan pages, best-seller: No, film: No, saga: Tecumseh Fox, followed by: Double for Death, preceded by: The Broken Vase\n",
      "2699\n",
      "Found 240240 pages, best-seller: No, film: Yes, saga: George Smiley, followed by: A Murder of Quality, preceded by: The Looking-Glass War\n",
      "2700\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Gerald Durrell'sCorfuSaga, followed by: nan, preceded by: Birds, Beasts, and Relatives, The Garden of the Gods\n",
      "2701\n",
      "Found 204 pages, best-seller: No, film: Yes, saga: Gonzo Series, followed by: nan, preceded by: nan\n",
      "2702\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2703\n",
      "Found 431 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2704\n",
      "Found 309 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2705\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2706\n",
      "Found 352 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 417424 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2708\n",
      "Found 192 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 512 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2710\n",
      "Found 349 pages, best-seller: No, film: Yes, saga: L.A. Quartet, followed by: L.A. Confidential, preceded by: nan\n",
      "2711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 340 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2712\n",
      "Found 313 pages, best-seller: No, film: No, saga: Amelia Peabody seriesmysteries, followed by: The Curse of the Pharaohs, preceded by: Lion in the Valley\n",
      "2713\n",
      "Found 191 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2715\n",
      "Found nan pages, best-seller: No, film: No, saga: Inspector Alan Banks, #1, followed by: nan, preceded by: A Dedicated Man\n",
      "2716\n",
      "Found 339 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2717\n",
      "Found 448 pages, best-seller: No, film: No, saga: Sally Lockhartseries, followed by: The Shadow in the North, preceded by: The Tin Princess\n",
      "2718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2719\n",
      "Found nan pages, best-seller: No, film: No, saga: Inspector Alan Banks, #5, followed by: The Hanging Valley, preceded by: Wednesday's Child\n",
      "2720\n",
      "Found 330 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2721\n",
      "Found 299405 pages, best-seller: No, film: No, saga: No, followed by: Pinball, 1973, preceded by: Dance Dance Dance\n",
      "2722\n",
      "Found 316 pages, best-seller: No, film: Yes, saga: Aubrey-Maturin series, followed by: The Thirteen-Gun Salute, preceded by: Clarissa Oakes/The Truelove\n",
      "2723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 284 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 435 pages, best-seller: No, film: Yes, saga: Alex Cross, followed by: nan, preceded by: Kiss the Girls\n",
      "2726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Daughter of Silence, preceded by: The Ambassador\n",
      "2727\n",
      "Found 305 pages, best-seller: No, film: No, saga: Joe Leaphorn/Jim CheeNavajo Tribal PoliceSeries, followed by: Coyote Waits(1990), preceded by: The Fallen Man (1996)\n",
      "2728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2729\n",
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: The House of Stairs, preceded by: King Solomon's Carpet\n",
      "2730\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2732\n",
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2733\n",
      "Found nan pages, best-seller: No, film: No, saga: Inspector Alan Banks, #3, followed by: A Dedicated Man, preceded by: The Hanging Valley\n",
      "2734\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2735\n",
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2736\n",
      "Found 56 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2737\n",
      "Found 287 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 228 pages, best-seller: No, film: Yes, saga: The A-List, followed by: nan, preceded by: Girls on Film\n",
      "2739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 176 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2740\n",
      "Found 489 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: Nancy Drew stories, followed by: Mystery of the Winged Lion, preceded by: The Sinister Omen\n",
      "2743\n",
      "Found 89 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2744\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Tourist Season, preceded by: Skin Tight\n",
      "2746\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: The Demon, preceded by: The Willow Tree\n",
      "2747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 260 pages, best-seller: No, film: No, saga: Buffy the Vampire Slayer, followed by: Immortal, preceded by: Power of Persuasion\n",
      "2748\n",
      "Found 522 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2749\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2750\n",
      "Found 247240 pages, best-seller: No, film: Yes, saga: No, followed by: The Pastures of Heaven, preceded by: nan\n",
      "2751\n",
      "Found 256 pages, best-seller: No, film: No, saga: Inspector Morseseries, #4, followed by: The Silent World of Nicholas Quinn, preceded by: The Dead of Jericho\n",
      "2752\n",
      "Found 256 pages, best-seller: No, film: No, saga: Inspector Morseseries, #1, followed by: nan, preceded by: Last Seen Wearing\n",
      "2753\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: Bride Quartet, followed by: Vision in White, preceded by: Savor the Moment\n",
      "2754\n",
      "Found 144 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 340 pages, best-seller: No, film: Yes, saga: The Adversary Cycle, followed by: Reprisal, preceded by: nan\n",
      "2756\n",
      "Found 144 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2757\n",
      "Found 4481 pages, best-seller: No, film: No, saga: Lord Peter Wimsey, followed by: The Five Red Herrings, preceded by: Murder Must Advertise\n",
      "2758\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2759\n",
      "Found 261 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2760\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2761\n",
      "Found 240 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Fairest\n",
      "2762\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2763\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2764\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2766\n",
      "Found 64 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2767\n",
      "Found 128 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2768\n",
      "Found 432 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2769\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 367 pages, best-seller: Yes, film: No, saga: Darkseries, followed by: Dark Hunger, preceded by: Dark Demon\n",
      "2771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 207 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2772\n",
      "Found 471 pages, best-seller: No, film: No, saga: Michael Fallon trilogy, followed by: nan, preceded by: The Fallon Pride\n",
      "2773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 368347 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2775\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2776\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Anne of Green Gables, followed by: Anne of Green Gables, preceded by: Anne of the Island\n",
      "2777\n",
      "Found 351 pages, best-seller: No, film: Yes, saga: Time Quintet, followed by: A Swiftly Tilting Planet, preceded by: An Acceptable Time\n",
      "2778\n",
      "Found 257 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2779\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2780\n",
      "Found 196 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2781\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2783\n",
      "Found 336 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2784\n",
      "Found 415 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2785\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2786\n",
      "Found 393 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2787\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Tenant of Wildfell Hall\n",
      "2788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Discworld19th novel – 3rd City Watch novel (4th story), followed by: Maskerade, preceded by: Hogfather\n",
      "2789\n",
      "Found 300 pages, best-seller: No, film: No, saga: No, followed by: Down and Out in Paris and London, preceded by: A Clergyman's Daughter\n",
      "2790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 302 pages, best-seller: No, film: No, saga: No, followed by: —, preceded by: The Codex\n",
      "2791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2792\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2793\n",
      "Found 314 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2794\n",
      "Found 290 pages, best-seller: No, film: Yes, saga: Sally Lockhartseries, followed by: The Tiger in the Well, preceded by: nan\n",
      "2795\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2796\n",
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Jennifer Government\n",
      "2797\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2798\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2799\n",
      "Found 336 pages, best-seller: Yes, film: No, saga: The Southern Vampire Mysteries, followed by: Dead in the Family, preceded by: Deadlocked\n",
      "2800\n",
      "Found 216 pages, best-seller: No, film: No, saga: Wren series, followed by: A Posse of Princesses(2008), preceded by: Wren's Quest (1993)\n",
      "2801\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2802\n",
      "Found 376 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2803\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2804\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2805\n",
      "Found 302 pages, best-seller: No, film: Yes, saga: Remembrance of Earth's Past, followed by: nan, preceded by: The Dark Forest\n",
      "2806\n",
      "Found 232 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2807\n",
      "2808\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2809\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2810\n",
      "Found 176 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2811\n",
      "Found 279 pages, best-seller: No, film: No, saga: No, followed by: Complicity (novel), preceded by: Whit\n",
      "2812\n",
      "Found 416375 pages, best-seller: No, film: Yes, saga: Takeshi Kovacs, followed by: nan, preceded by: Broken Angels\n",
      "2813\n",
      "Found 114 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2815\n",
      "Found nan pages, best-seller: No, film: No, saga: Dirk PittNovels, followed by: nan, preceded by: Iceberg\n",
      "2816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2817\n",
      "Found 368 pages, best-seller: Yes, film: Yes, saga: Bigend cycle, followed by: nan, preceded by: Spook Country\n",
      "2818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 183 pages, best-seller: No, film: No, saga: Ware Tetralogy, followed by: Software, preceded by: Freeware\n",
      "2819\n",
      "Found 233 pages, best-seller: No, film: No, saga: No, followed by: Speak, preceded by: nan\n",
      "2820\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: Triggerfish Twist, preceded by: Cadillac Beach\n",
      "2821\n",
      "Found 181 pages, best-seller: No, film: No, saga: No, followed by: The Bridges of Madison County, preceded by: nan\n",
      "2822\n",
      "Found 352 pages, best-seller: No, film: No, saga: The Last Roundup, followed by: nan, preceded by: Oh, Play That Thing\n",
      "2823\n",
      "Found 214 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2824\n",
      "Found 232 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2825\n",
      "Found 355 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3432008 pages, best-seller: No, film: Yes, saga: Waverley Novels, followed by: The Black DwarfandOld Mortality, preceded by: The Heart of Midlothian\n",
      "2827\n",
      "Found 247 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 401 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2829\n",
      "Found 416 pages, best-seller: No, film: No, saga: Grand Tour, followed by: Mars, preceded by: Mars Life\n",
      "2830\n",
      "Found 448 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 pages, best-seller: No, film: No, saga: Leatherstocking, followed by: The Pathfinder, or The Inland Sea, preceded by: The Prairie\n",
      "2832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 194 pages, best-seller: No, film: Yes, saga: No, followed by: Rumble Fish, preceded by: Taming the Star Runner\n",
      "2833\n",
      "Found 263 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2834\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2835\n",
      "Found 1079 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2836\n",
      "Found 311 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2837\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2838\n",
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: Next: The Future Just Happened, preceded by: Coach: Lessons on the Game of Life\n",
      "2839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2840\n",
      "Found 224 pages, best-seller: No, film: No, saga: Casson Family, followed by: nan, preceded by: Indigo's Star\n",
      "2841\n",
      "Found 288 pages, best-seller: No, film: No, saga: Time[1], followed by: nan, preceded by: The Tides of Time\n",
      "2842\n",
      "Found 315 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 pages, best-seller: Yes, film: Yes, saga: Nero Wolfe, followed by: Over My Dead Body, preceded by: Black Orchids\n",
      "2844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2845\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2846\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2847\n",
      "Found 276 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2848\n",
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2850\n",
      "Found 212 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2851\n",
      "Found 539 pages, best-seller: No, film: No, saga: Dirk PittNovels, followed by: Sahara, preceded by: Shock Wave\n",
      "2852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2853\n",
      "Found 281 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Farewell Summer\n",
      "2854\n",
      "Found 283 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2855\n",
      "Found 305 pages, best-seller: No, film: No, saga: Marcus Didius Falco, followed by: One Virgin Too Many, preceded by: A Body in the Bath House\n",
      "2856\n",
      "Found 394 pages, best-seller: No, film: No, saga: No, followed by: Roll of Thunder, Hear My Cry, preceded by: The Gold Cadillac\n",
      "2857\n",
      "Found 213 pages, best-seller: No, film: No, saga: Fudge series, followed by: Fudge-A-Mania, preceded by: nan\n",
      "2858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 436 pages, best-seller: No, film: Yes, saga: Kurt Wallander#8, followed by: One Step Behind, preceded by: The Pyramid\n",
      "2860\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2861\n",
      "Found 283 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2862\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2262001 pages, best-seller: No, film: No, saga: No, followed by: On the Eve, preceded by: Smoke\n",
      "2864\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: “The Tactful Saboteur”, preceded by: The Dosadi Experiment\n",
      "2865\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 255 pages, best-seller: No, film: Yes, saga: James Bond, followed by: Live and Let Die, preceded by: Diamonds Are Forever\n",
      "2867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 408 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 194 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 274 pages, best-seller: No, film: Yes, saga: Tales of the City, followed by: Babycakes, preceded by: Sure of You\n",
      "2870\n",
      "Found 900 pages, best-seller: No, film: No, saga: No, followed by: The Power of One, preceded by: April Fool's Day\n",
      "2871\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2872\n",
      "Found 332 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2873\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Code Noir\n",
      "2874\n",
      "Found 384 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2875\n",
      "Found 244 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2877\n",
      "Found 310 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2878\n",
      "Found 213 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 570 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2880\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: They Burn the Thistles\n",
      "2881\n",
      "Found 247 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 531 pages, best-seller: Yes, film: No, saga: Languedoc Trilogy, followed by: nan, preceded by: Sepulchre\n",
      "2883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 704 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2884\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2885\n",
      "Found 160 pages, best-seller: No, film: No, saga: Adrian Moleseries, followed by: The Secret Diary of Adrian Mole, Aged 13¾, preceded by: The True Confessions of Adrian Albert Mole\n",
      "2886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: The Razor's Edge, preceded by: Creatures of Circumstance\n",
      "2887\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2888\n",
      "Found 480 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2889\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: My Name is Asher Lev, preceded by: nan\n",
      "2890\n",
      "Found 364 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2891\n",
      "Found nan pages, best-seller: No, film: No, saga: The Forsyte Saga, followed by: The Man of Property, preceded by: To Let\n",
      "2892\n",
      "Found 224 pages, best-seller: No, film: No, saga: Jeeves, followed by: Right Ho, Jeeves, preceded by: Joy in the Morning\n",
      "2893\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Bandini Quartet, followed by: Wait Until Spring, Bandini, preceded by: Dago Red\n",
      "2894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 pages, best-seller: No, film: No, saga: No, followed by: Island of the Blue Dolphins, preceded by: nan\n",
      "2895\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2896\n",
      "Found 223 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 130 pages, best-seller: No, film: Yes, saga: Brian's Saga, followed by: Hatchet, preceded by: Brian's Winter\n",
      "2898\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 287 pages, best-seller: No, film: No, saga: CHERUB, followed by: The Recruit, preceded by: Maximum Security\n",
      "2900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 402 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Magician King\n",
      "2901\n",
      "Found 160 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2903\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2904\n",
      "Found 171 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2905\n",
      "Found 241 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2907\n",
      "Found 1481 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2908\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 156 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 936 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: The Mountain Shadow (2015)\n",
      "2911\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Sword at Sunset, preceded by: Sword Song\n",
      "2912\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 349 pages, best-seller: No, film: Yes, saga: Ender's Game series, followed by: Xenocide, preceded by: A War of Gifts\n",
      "2914\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2915\n",
      "Found 480 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2916\n",
      "Found 382 pages, best-seller: No, film: No, saga: Avalon Series, followed by: Lady of Avalon, preceded by: Ancestors of Avalon\n",
      "2917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 406 pages, best-seller: No, film: No, saga: Shaw and Katie James, followed by: nan, preceded by: Deliver Us From Evil\n",
      "2918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 186 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2919\n",
      "Found 176 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Parvana's Journey\n",
      "2920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 253 pages, best-seller: No, film: Yes, saga: James Bond, followed by: For Your Eyes Only, preceded by: The Spy Who Loved Me\n",
      "2921\n",
      "Found 278 pages, best-seller: No, film: No, saga: No, followed by: The Halloween Tree, preceded by: A Graveyard for Lunatics\n",
      "2922\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2923\n",
      "Found 361 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2924\n",
      "Found 229 pages, best-seller: No, film: Yes, saga: No, followed by: Five Little Pigs, preceded by: Towards Zero\n",
      "2925\n",
      "Found 405 pages, best-seller: No, film: Yes, saga: No, followed by: Mexico Set, preceded by: Spy Hook\n",
      "2926\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2927\n",
      "Found 2 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2928\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2929\n",
      "Found 380 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2931\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2932\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: \"The Crime Wave at Blandings\" (short),Heavy Weather(novel), preceded by: Full Moon (Blandings), Uncle Dynamite (Uncle Fred)\n",
      "2933\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2934\n",
      "Found 383 pages, best-seller: No, film: No, saga: No, followed by: The Constant Gardener, preceded by: The Mission Song\n",
      "2935\n",
      "Found 182 pages, best-seller: No, film: No, saga: Hamish Macbeth, followed by: Death of a Cad, preceded by: Death of a Perfect Wife\n",
      "2936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2937\n",
      "Found 8231153 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 pages, best-seller: No, film: Yes, saga: Darkside, followed by: nan, preceded by: Lifeblood\n",
      "2939\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2940\n",
      "Found 314 pages, best-seller: No, film: No, saga: Dark Series, followed by: nan, preceded by: Dark Desire\n",
      "2941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Santangelonovels, followed by: nan, preceded by: Hollywood Wives\n",
      "2943\n",
      "Found 278 pages, best-seller: No, film: No, saga: Inspector Wexford#14, followed by: An Unkindness of Ravens, preceded by: Kissing the Gunner's Daughter\n",
      "2944\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Albert Campion, followed by: The Crime at Black Dudley, preceded by: Look to the Lady\n",
      "2945\n",
      "Found 172 pages, best-seller: No, film: No, saga: Shadow Children sequence, followed by: Among the Hidden, preceded by: Among the Betrayed\n",
      "2946\n",
      "Found 184 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2947\n",
      "Found 309 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2948\n",
      "Found 384 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Coalwood Way\n",
      "2949\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2950\n",
      "Found 290 pages, best-seller: No, film: Yes, saga: Philip Marlowe, followed by: Playback, preceded by: nan\n",
      "2951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2952\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2953\n",
      "Found 186 pages, best-seller: No, film: No, saga: Lucky Starrseries, followed by: Lucky Starr and the Pirates of the Asteroids, preceded by: Lucky Starr and the Big Sun of Mercury\n",
      "2954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 247 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2955\n",
      "Found 107 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2957\n",
      "Found 240 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2958\n",
      "Found 160 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2959\n",
      "Found 112 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2960\n",
      "Found 432 pages, best-seller: No, film: Yes, saga: No, followed by: The Handmaid's Tale, preceded by: nan\n",
      "2961\n",
      "Found 180 pages, best-seller: No, film: Yes, saga: Zuckerman Bound, followed by: nan, preceded by: Zuckerman Unbound\n",
      "2962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Necroscope series, followed by: Necroscope V: Deadspawn(1991), preceded by: The Last Aerie (1993)\n",
      "2963\n",
      "Found 135 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2964\n",
      "Found 464 pages, best-seller: No, film: No, saga: The Indian Lake Trilogy, followed by: My Heart is a Chainsaw, preceded by: nan\n",
      "2965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2966\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2968\n",
      "Found 160 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2969\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4492 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 420 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Tom Brown at Oxford\n",
      "2973\n",
      "Found 432 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2974\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2976\n",
      "Found 2711 pages, best-seller: No, film: Yes, saga: Philip Marlowe, followed by: The Big Sleep, preceded by: nan\n",
      "2977\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 324 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2979\n",
      "Found 165 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2980\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: A Confederacy of Dunces(1981), preceded by: nan\n",
      "2981\n",
      "Found 304 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: A Fatal Inversion\n",
      "2982\n",
      "Found 1841 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2983\n",
      "Found 272 pages, best-seller: No, film: No, saga: No, followed by: Damia, preceded by: Lyon's Pride\n",
      "2984\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2985\n",
      "Found 337 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2986\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Country of the Blind\n",
      "2987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 264 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2988\n",
      "Found nan pages, best-seller: No, film: No, saga: Doctor Whobook:The New Adventures, followed by: The Dying Days, preceded by: Dragons' Wrath\n",
      "2989\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2990\n",
      "Found nan pages, best-seller: No, film: No, saga: Blandings Castle, followed by: nan, preceded by: nan\n",
      "2991\n",
      "Found 419 pages, best-seller: No, film: No, saga: No, followed by: 12 Million Black Voices: A Folk History of the Negro in the United States, preceded by: The Outsider\n",
      "2992\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Barnaby Rudge, preceded by: Dombey and Son\n",
      "2993\n",
      "Found 190 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: A War of Shadows\n",
      "2994\n",
      "Found 352 pages, best-seller: No, film: No, saga: Amelia Peabody seriesmysteries, followed by: Deeds of the Disturber, preceded by: The Snake, the Crocodile, and the Dog\n",
      "2995\n",
      "Found 253 pages, best-seller: No, film: No, saga: The France Trilogy, followed by: nan, preceded by: 'Birdsong\n",
      "2996\n",
      "Found 117 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "2997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 199 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "2998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222 pages, best-seller: No, film: Yes, saga: Erast Fandorin, followed by: nan, preceded by: The Turkish Gambit\n",
      "2999\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Help! I'm Trapped in the First Day of School!\n",
      "3000\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3001\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 307 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3003\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Emma, preceded by: Persuasion\n",
      "3004\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3005\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3006\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3007\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3008\n",
      "Found 391 pages, best-seller: Yes, film: Yes, saga: The Hunger Games, followed by: The Hunger Games, preceded by: Mockingjay\n",
      "3009\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3010\n",
      "Found 432 pages, best-seller: No, film: No, saga: A Touch of Frost, followed by: A Touch of Frost, preceded by: Hard Frost\n",
      "3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3013\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 199 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3015\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3016\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 136 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Catriona (1893)\n",
      "3018\n",
      "Found 245 pages, best-seller: No, film: No, saga: Down the Long Wind, followed by: Hawk of May, preceded by: In Winter's Shadow\n",
      "3019\n",
      "Found 276 pages, best-seller: No, film: No, saga: Dragon, followed by: Dragon of the Lost Sea(1982), preceded by: Dragon Cauldron (1991)\n",
      "3020\n",
      "Found 377 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 448 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3022\n",
      "Found 743 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3023\n",
      "Found 190240 pages, best-seller: No, film: No, saga: The Cadfael Chronicles, followed by: The Raven in the Foregate, preceded by: The Hermit of Eyton Forest\n",
      "3024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3026\n",
      "3027\n",
      "Found 237 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3028\n",
      "Found 181 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3029\n",
      "Found 512 pages, best-seller: No, film: No, saga: No, followed by: Island, preceded by: Blood Games\n",
      "3030\n",
      "Found 368 pages, best-seller: No, film: Yes, saga: New Tales of the Vampires, followed by: nan, preceded by: Vittorio the Vampire\n",
      "3031\n",
      "Found 279 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3032\n",
      "Found 282 pages, best-seller: No, film: No, saga: Henry Merrivale, followed by: The Curse of the Bronze Lamp, preceded by: The Skeleton in the Clock\n",
      "3033\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3034\n",
      "Found 176 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3035\n",
      "Found 287 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 297 pages, best-seller: No, film: Yes, saga: No, followed by: The Ministry of Fear(1943), preceded by: The Third Man (1949)\n",
      "3037\n",
      "Found 304 pages, best-seller: No, film: Yes, saga: Red Dwarf, followed by: nan, preceded by: Better Than Life\n",
      "3038\n",
      "Found 128 pages, best-seller: No, film: No, saga: Henry Huggins, followed by: Henry and the Clubhouse, preceded by: nan\n",
      "3039\n",
      "Found 181 pages, best-seller: No, film: No, saga: Spenser, followed by: Promised Land, preceded by: Looking for Rachel Wallace\n",
      "3040\n",
      "Found 254 pages, best-seller: No, film: No, saga: No, followed by: Changeling, preceded by: nan\n",
      "3041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3043\n",
      "Found 147 pages, best-seller: No, film: No, saga: Den of Shadows, followed by: nan, preceded by: Demon in My View(2000)\n",
      "3044\n",
      "Found 496 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3045\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3046\n",
      "Found 416 pages, best-seller: Yes, film: Yes, saga: No, followed by: South Moon Under, preceded by: Cross Creek\n",
      "3047\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3048\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Small World: An Academic Romance\n",
      "3049\n",
      "Found 313 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 717 pages, best-seller: No, film: Yes, saga: Bas-Lagnovels, followed by: Perdido Street Station, preceded by: Iron Council\n",
      "3051\n",
      "Found 3901962 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3052\n",
      "Found 181 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3053\n",
      "Found 1441302000 pages, best-seller: No, film: No, saga: No, followed by: A Long Way from Chicago, preceded by: A Season of Gifts\n",
      "3054\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: The Tale of Squirrel Nutkin, preceded by: The Tale of Benjamin Bunny\n",
      "3055\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3056\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 175 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3058\n",
      "Found 352 pages, best-seller: No, film: No, saga: Nuala Anne McGrail series, followed by: Irish Crystal, preceded by: Irish Tiger\n",
      "3059\n",
      "Found 304 pages, best-seller: No, film: Yes, saga: Indiana Jones, followed by: Indiana Jones and the Dance of the Giants, preceded by: Indiana Jones and the Genesis Deluge\n",
      "3060\n",
      "Found 438 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3061\n",
      "Found 320 pages, best-seller: No, film: No, saga: Magic Kingdom of Landover, followed by: Magic Kingdom for Sale—Sold!, preceded by: Wizard at Large\n",
      "3062\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3063\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 302 pages, best-seller: No, film: Yes, saga: Remembrance of Earth's Past, followed by: nan, preceded by: The Dark Forest\n",
      "3065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3067\n",
      "Found 279 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3068\n",
      "Found 149 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Breaks, preceded by: Freedomland\n",
      "3070\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3071\n",
      "Found 328 pages, best-seller: Yes, film: Yes, saga: No, followed by: Animal Farm, preceded by: nan\n",
      "3072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 643 pages, best-seller: No, film: No, saga: Tunnels, followed by: Tunnels(2007), preceded by: Freefall (2009)\n",
      "3073\n",
      "Found 2871 pages, best-seller: No, film: No, saga: Lord Peter Wimsey, followed by: Unnatural Death, preceded by: Strong Poison\n",
      "3074\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3075\n",
      "Found 3011 pages, best-seller: No, film: No, saga: No, followed by: The Night Manager, preceded by: The Tailor of Panama\n",
      "3076\n",
      "Found 311 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 131 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Oliver's Story (novel)\n",
      "3078\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3079\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3080\n",
      "Found nan pages, best-seller: No, film: No, saga: Discworld19th novel – 3rd City Watch novel (4th story), followed by: Maskerade, preceded by: Hogfather\n",
      "3081\n",
      "Found 228 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 425 pages, best-seller: No, film: Yes, saga: No, followed by: Death of a River Guide(1994), preceded by: Gould's Book of Fish (2001)\n",
      "3083\n",
      "Found 275 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: She Got Up Off the Couch: And Other Heroic Acts from Mooreland Indiana (2006)\n",
      "3084\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3086\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3087\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3089\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3090\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Vurt series, followed by: Pollen, preceded by: Nymphomation\n",
      "3091\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Success, preceded by: Money\n",
      "3093\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3094\n",
      "Found 152 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3095\n",
      "Found 224 pages, best-seller: No, film: No, saga: Inspector Morseseries, #6, followed by: The Dead of Jericho, preceded by: The Secret of Annexe 3\n",
      "3096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3098\n",
      "Found nan pages, best-seller: No, film: No, saga: Discworld12th novel – 3rd witches story, followed by: Reaper Man, preceded by: Small Gods\n",
      "3099\n",
      "Found 64 pages, best-seller: No, film: Yes, saga: I Can Read!, followed by: nan, preceded by: nan\n",
      "3100\n",
      "Found 242 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3101\n",
      "Found 224 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3102\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: What Becomes of the Broken Hearted?\n",
      "3103\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3104\n",
      "Found 222 pages, best-seller: No, film: No, saga: No, followed by: Farmer in the Sky, preceded by: The Rolling Stones\n",
      "3105\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3106\n",
      "Found 408 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3107\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Fuzzy Sapiens\n",
      "3108\n",
      "Found 286 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3109\n",
      "Found 608 pages, best-seller: No, film: No, saga: Nantucket series, followed by: nan, preceded by: Against the Tide of Years\n",
      "3110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3111\n",
      "Found 368 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Beowulf's Children\n",
      "3112\n",
      "Found 180 pages, best-seller: No, film: No, saga: Betsy-Tacy, followed by: Betsy and Tacy Go Over the Big Hill(1942), preceded by: Heaven to Betsy (1945)\n",
      "3113\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3114\n",
      "Found 258 pages, best-seller: No, film: Yes, saga: No, followed by: An Artist of the Floating World, preceded by: The Unconsoled\n",
      "3115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3116\n",
      "Found 222 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3120\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3121\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3122\n",
      "Found 336 pages, best-seller: No, film: No, saga: Camilla Dickinson, followed by: Camilla Dickinson, preceded by: nan\n",
      "3123\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Dear Enemy\n",
      "3124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3125\n",
      "Found 274 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Witch of Blackbird Pond\n",
      "3126\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3127\n",
      "Found 22 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3128\n",
      "Found 161 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: The Oz books, followed by: nan, preceded by: The Marvelous Land of Oz\n",
      "3130\n",
      "Found 333 pages, best-seller: No, film: No, saga: Guardians of Time Trilogy, followed by: nan, preceded by: The Dark\n",
      "3131\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3132\n",
      "Found 2161 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3133\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2301 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3135\n",
      "Found nan pages, best-seller: No, film: No, saga: Chronicles of Barsetshire, followed by: The Warden, preceded by: Doctor Thorne\n",
      "3136\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3137\n",
      "Found 239 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3138\n",
      "Found 193 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3139\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3141\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: Children of the Famine, followed by: nan, preceded by: Wildflower Girl\n",
      "3143\n",
      "Found 3171983 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3144\n",
      "Found 608 pages, best-seller: No, film: No, saga: Sevenwaters trilogy, followed by: Son of the Shadows, preceded by: Heir to Sevenwaters\n",
      "3145\n",
      "Found 214 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3146\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 243 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3148\n",
      "Found 636 pages, best-seller: No, film: Yes, saga: Harry Potter, followed by: Harry Potter and the Prisoner of Azkaban, preceded by: Harry Potter and the Order of the Phoenix\n",
      "3149\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3152\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3153\n",
      "Found 183 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3154\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3155\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Service With a Smile, preceded by: \"Sticky Wicket at Blandings\" (short story), A Pelican at Blandings (novel)\n",
      "3156\n",
      "Found 158 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 336 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3158\n",
      "Found 352 pages, best-seller: Yes, film: No, saga: Warriors: The New Prophecy, followed by: Dawn, preceded by: Twilight\n",
      "3159\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3160\n",
      "Found 753 pages, best-seller: No, film: No, saga: Starfire series, followed by: In Death Ground, preceded by: Insurrection\n",
      "3161\n",
      "Found 512 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3162\n",
      "Found nan pages, best-seller: No, film: Yes, saga: James Bond, followed by: nan, preceded by: nan\n",
      "3163\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3164\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3165\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3166\n",
      "Found 329 pages, best-seller: No, film: No, saga: Inspector Lynley, followed by: Payment in Blood, preceded by: A Suitable Vengeance\n",
      "3167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 277 pages, best-seller: No, film: No, saga: The Forever War series, followed by: Forever Peace(1997), preceded by: nan\n",
      "3168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: Fluke, or, I Know Why the Winged Whale Sings, preceded by: A Dirty Job\n",
      "3169\n",
      "Found 400 pages, best-seller: No, film: No, saga: Amelia Peabody seriesmysteries, followed by: The Falcon at the Portal, preceded by: Lord of the Silent\n",
      "3170\n",
      "Found 333 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3171\n",
      "Found nan pages, best-seller: No, film: No, saga: Romance of the Three Kingdoms, followed by: nan, preceded by: nan\n",
      "3172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 429 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3173\n",
      "Found 240 pages, best-seller: No, film: No, saga: The State, followed by: A World Out of Time, preceded by: The Smoke Ring\n",
      "3174\n",
      "Found 255 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3175\n",
      "Found 1321 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: The Cornish Trilogy, followed by: What's Bred in the Bone, preceded by: nan\n",
      "3177\n",
      "Found 290267 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: To be Announced\n",
      "3178\n",
      "Found 213 pages, best-seller: No, film: No, saga: Dragon, followed by: N/A, preceded by: Dragon Steel (1985)\n",
      "3179\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3180\n",
      "Found 247 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 pages, best-seller: No, film: Yes, saga: Mickey Bolitar series, followed by: nan, preceded by: Seconds Away(2012)\n",
      "3182\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Invisible Cities, preceded by: Mr. Palomar\n",
      "3184\n",
      "Found 2851 pages, best-seller: No, film: No, saga: Lord Peter Wimsey, followed by: Clouds of Witness, preceded by: The Unpleasantness at the Bellona Club\n",
      "3185\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3187\n",
      "Found 576 pages, best-seller: No, film: No, saga: No, followed by: Queen of Camelot, preceded by: nan\n",
      "3188\n",
      "Found nan pages, best-seller: No, film: No, saga: Blackford Oakes, followed by: nan, preceded by: nan\n",
      "3189\n",
      "Found 384 pages, best-seller: No, film: No, saga: Jack Reacher, followed by: Running Blind, preceded by: Without Fail\n",
      "3190\n",
      "Found 337 pages, best-seller: No, film: Yes, saga: Meg, followed by: nan, preceded by: The Trench\n",
      "3191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Peasants\n",
      "3192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 503 pages, best-seller: No, film: No, saga: The Way, followed by: nan, preceded by: Eternity\n",
      "3193\n",
      "Found 240 pages, best-seller: No, film: No, saga: No, followed by: The Tar-Aiym Krang, preceded by: The End of the Matter\n",
      "3194\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Spy Sinker, preceded by: Hope\n",
      "3195\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: The Sound and the Fury, preceded by: Sanctuary\n",
      "3196\n",
      "Found 175 pages, best-seller: No, film: Yes, saga: The Mouse and the Motorcycle, followed by: The Mouse and the Motorcycle, preceded by: Ralph S. Mouse\n",
      "3197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3198\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Extraordinary Voyages#12Captain Nemo#2, followed by: Around the World in Eighty Days, preceded by: The Survivors of the Chancellor\n",
      "3199\n",
      "Found 472 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3200\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3201\n",
      "Found 246 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Pawns of Null-A\n",
      "3202\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3203\n",
      "Found 402 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3204\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3205\n",
      "Found 336 pages, best-seller: No, film: No, saga: Kenzie and Gennaro, followed by: A Drink Before the War, preceded by: Sacred\n",
      "3206\n",
      "Found nan pages, best-seller: No, film: No, saga: Blackford Oakes, followed by: nan, preceded by: nan\n",
      "3207\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3209\n",
      "Found 160 pages, best-seller: No, film: No, saga: Darkover, followed by: nan, preceded by: nan\n",
      "3210\n",
      "Found 255 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 859 pages, best-seller: No, film: Yes, saga: Lanny Budd, followed by: Worlds End, preceded by: Dragon's Teeth\n",
      "3212\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3213\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3214\n",
      "Found 401 pages, best-seller: No, film: No, saga: CoDominium, followed by: The Mote in God's Eye, preceded by: Outies\n",
      "3215\n",
      "Found 2231 pages, best-seller: No, film: No, saga: Chrestomanci, followed by: Charmed Life, preceded by: Witch Week\n",
      "3216\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 237 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3218\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3220\n",
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: The A.B.C. Murders, preceded by: Cards on the Table\n",
      "3221\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3222\n",
      "Found 310 pages, best-seller: No, film: No, saga: No, followed by: The Road of Dreams, preceded by: The Murder of Roger Ackroyd\n",
      "3223\n",
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: Elephants Can Remember, preceded by: Poems\n",
      "3224\n",
      "Found 224 pages, best-seller: No, film: No, saga: James Bond, followed by: nan, preceded by: nan\n",
      "3225\n",
      "Found 308 pages, best-seller: No, film: Yes, saga: Nero Wolfe, followed by: Fer-de-Lance, preceded by: The Rubber Band\n",
      "3226\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: The Golden Ball and Other Stories, preceded by: Postern of Fate\n",
      "3227\n",
      "Found 481 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3228\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Spy Hook, preceded by: Spy Sinker\n",
      "3229\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3230\n",
      "Found 396 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 432 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3232\n",
      "3233\n",
      "Found 494 pages, best-seller: No, film: No, saga: Dragonriders of Pern, followed by: The Renegades of Pern, preceded by: The Chronicles of Pern: First Fall\n",
      "3234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3235\n",
      "Found 310 pages, best-seller: No, film: No, saga: Kate Martinelli series, followed by: nan, preceded by: To Play the Fool\n",
      "3236\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3237\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 336 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Serpent of Venice\n",
      "3239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 384 pages, best-seller: No, film: No, saga: Kay Scarpetta, followed by: All That Remains, preceded by: The Body Farm\n",
      "3241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3242\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 464 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3244\n",
      "Found 229 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3245\n",
      "Found 434 pages, best-seller: No, film: No, saga: Chief Inspector Barnaby, followed by: Death of a Hollow Man, preceded by: Written in Blood\n",
      "3246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 497 pages, best-seller: No, film: No, saga: Dragonriders of Pern, followed by: Dragonsinger, preceded by: Dragondrums\n",
      "3247\n",
      "Found 2052 pages, best-seller: No, film: Yes, saga: Earthsea, followed by: \"The Rule of Names\", preceded by: The Tombs of Atuan\n",
      "3248\n",
      "Found 1631 pages, best-seller: No, film: Yes, saga: Earthsea, followed by: A Wizard of Earthsea, preceded by: The Farthest Shore\n",
      "3249\n",
      "Found 9 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3250\n",
      "Found 252 pages, best-seller: No, film: Yes, saga: Mythago Wood series, followed by: nan, preceded by: Lavondyss (1988)\n",
      "3251\n",
      "Found 410 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3252\n",
      "Found 274 pages, best-seller: No, film: No, saga: Alphabet Mysteries, followed by: nan, preceded by: \"B\" Is for Burglar\n",
      "3253\n",
      "Found 266 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 351 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Well of Stars\n",
      "3255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 421 pages, best-seller: No, film: No, saga: The Last Dragon Chronicles, followed by: The Fire Within, preceded by: Fire Star\n",
      "3256\n",
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: The Looking-Glass War, preceded by: The Naïve and Sentimental Lover\n",
      "3257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 456 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3258\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3259\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: My Friend Leonard\n",
      "3260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3262\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3263\n",
      "Found 245 pages, best-seller: No, film: Yes, saga: No, followed by: N or M?, preceded by: Five Little Pigs\n",
      "3264\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Merivel: A Man of His Time\n",
      "3266\n",
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3267\n",
      "Found 502 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3268\n",
      "Found 287 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 326 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3270\n",
      "Found 190 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Leave it to Psmith\n",
      "3271\n",
      "Found 272 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3272\n",
      "Found 202 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Drink Down the Moon\n",
      "3273\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: Appointment with Death, preceded by: Murder is Easy\n",
      "3274\n",
      "Found 383 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3275\n",
      "Found 528 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Wayward Son\n",
      "3276\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: Ellery Queenmysteries, followed by: Calamity Town, preceded by: The Murderer is a Fox\n",
      "3278\n",
      "Found 656 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3279\n",
      "Found 210 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3280\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3281\n",
      "Found 355 pages, best-seller: No, film: Yes, saga: No, followed by: Basket Case, preceded by: Nature Girl\n",
      "3282\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3283\n",
      "Found 416 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3284\n",
      "Found 313 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 251 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3286\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3287\n",
      "Found nan pages, best-seller: No, film: No, saga: Sector General, followed by: Hospital Station, preceded by: Major Operation\n",
      "3288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 244 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 516 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: Banco\n",
      "3290\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3291\n",
      "Found nan pages, best-seller: No, film: No, saga: Heinlein juveniles, followed by: Tunnel in the Sky, preceded by: Citizen of the Galaxy\n",
      "3292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 303 pages, best-seller: No, film: Yes, saga: Ballet, followed by: nan, preceded by: Tennis Shoes\n",
      "3293\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3294\n",
      "Found 245 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3295\n",
      "Found 114 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3296\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3297\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Terra-Farma\n",
      "3298\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Love & Lies\n",
      "3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2491 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 297 pages, best-seller: No, film: Yes, saga: No, followed by: Survivor, preceded by: Choke\n",
      "3302\n",
      "Found 531 pages, best-seller: Yes, film: No, saga: Languedoc Trilogy, followed by: nan, preceded by: Sepulchre\n",
      "3303\n",
      "Found 434 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3304\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3305\n",
      "Found nan pages, best-seller: No, film: No, saga: Discworld32ndnovel– 2nd Tiffany Aching story, followed by: Monstrous Regiment, preceded by: Going Postal\n",
      "3306\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3307\n",
      "Found 251 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3308\n",
      "Found 236 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 354 pages, best-seller: Yes, film: No, saga: House of Night, followed by: Marked, preceded by: Chosen\n",
      "3310\n",
      "Found 211 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 pages, best-seller: No, film: No, saga: League of Peoples, followed by: Trapped, preceded by: nan\n",
      "3312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3313\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3315\n",
      "Found 316 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3316\n",
      "Found 180 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Blanche among the Talented Tenth\n",
      "3317\n",
      "Found 154 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3318\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3319\n",
      "Found 180 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3320\n",
      "Found 255 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3321\n",
      "Found 222 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3323\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Cannery Row, preceded by: nan\n",
      "3324\n",
      "Found nan pages, best-seller: No, film: No, saga: Heinlein juveniles, followed by: The Star Beast, preceded by: Time for the Stars\n",
      "3325\n",
      "Found 232 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Jason and Marceline\n",
      "3326\n",
      "Found 222 pages, best-seller: No, film: Yes, saga: The Chronicles of Prydain, followed by: The Castle of Llyr, preceded by: The High King\n",
      "3327\n",
      "Found 256256 pages, best-seller: No, film: No, saga: Aurelio Zenseries, #6, followed by: Cosi Fan Tutti, preceded by: Blood Rain\n",
      "3328\n",
      "Found 216 pages, best-seller: No, film: No, saga: Green Sky Trilogy, followed by: Below the Root, preceded by: Until the Celebration\n",
      "3329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3330\n",
      "Found 324 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Pasadena\n",
      "3331\n",
      "Found 400 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Stars We Steal\n",
      "3332\n",
      "Found 159 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3333\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Kisscut, preceded by: nan\n",
      "3334\n",
      "Found 317 pages, best-seller: Yes, film: Yes, saga: Harry Potter, followed by: Harry Potter and the Chamber of Secrets, preceded by: Harry Potter and the Goblet of Fire\n",
      "3335\n",
      "Found 308 pages, best-seller: No, film: No, saga: Polly O'Keefe, followed by: Dragons in the Waters, preceded by: An Acceptable Time\n",
      "3336\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3337\n",
      "Found 282 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3338\n",
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3339\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3340\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3341\n",
      "Found 2981982 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3342\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3343\n",
      "Found 560 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3344\n",
      "Found 308 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3345\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9441 pages, best-seller: Yes, film: No, saga: The Baroque Cycle, followed by: nan, preceded by: The Confusion\n",
      "3347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 640 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3348\n",
      "Found 148 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3349\n",
      "Found 118 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3350\n",
      "Found 248 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 337 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3352\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 589 pages, best-seller: No, film: No, saga: Lonesome Dove series, followed by: Lonesome Dove, preceded by: Dead Man's Walk\n",
      "3354\n",
      "Found 605 pages, best-seller: No, film: No, saga: No, followed by: I Will Fear No Evil, preceded by: The Number of the Beast\n",
      "3355\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3356\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3357\n",
      "Found 275 pages, best-seller: No, film: No, saga: Blackford Oakes, followed by: Stained Glass, preceded by: Marco Polo, if You Can\n",
      "3358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 177 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 pages, best-seller: No, film: Yes, saga: NASA Trilogy, followed by: Titan, preceded by: nan\n",
      "3360\n",
      "Found 202 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3362\n",
      "Found 320256 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3363\n",
      "Found 367 pages, best-seller: No, film: No, saga: Mythago Woodseries, followed by: Mythago Wood(1984), preceded by: The Bone Forest (1991)\n",
      "3364\n",
      "Found 279 pages, best-seller: No, film: Yes, saga: Oz books, followed by: The Magic of Oz, preceded by: The Royal Book of Oz\n",
      "3365\n",
      "Found 237 pages, best-seller: No, film: No, saga: The Benny Books, followed by: nan, preceded by: Benny and Babe\n",
      "3366\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3367\n",
      "Found 480 pages, best-seller: No, film: No, saga: Aloysius Pendergast, followed by: The Cabinet of Curiosities, preceded by: Brimstone\n",
      "3368\n",
      "Found 480 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3369\n",
      "Found 253 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3370\n",
      "Found 176 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3371\n",
      "Found 246 pages, best-seller: No, film: No, saga: Earthsea, followed by: Tales from Earthsea, preceded by: nan\n",
      "3372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3373\n",
      "Found 276 pages, best-seller: No, film: No, saga: Galactic Center Saga, followed by: nan, preceded by: Across the Sea of Suns\n",
      "3374\n",
      "Found 190 pages, best-seller: No, film: Yes, saga: The Howling, followed by: nan, preceded by: The Howling II\n",
      "3375\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3376\n",
      "Found 9403 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: La Esmeralda (libretto only)\n",
      "3377\n",
      "Found 137 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3378\n",
      "Found 2881 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3381\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3382\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Pollyanna Grows Up\n",
      "3383\n",
      "Found 236 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3384\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3385\n",
      "Found 202 pages, best-seller: No, film: Yes, saga: No, followed by: Charlie and the Chocolate Factory, preceded by: nan\n",
      "3386\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 229 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3388\n",
      "Found 373 pages, best-seller: No, film: No, saga: Magics, followed by: nan, preceded by: Secret of the Sixth Magic\n",
      "3389\n",
      "Found 19322151 pages, best-seller: No, film: No, saga: The Borrowers, followed by: The Borrowers, preceded by: The Borrowers Afloat\n",
      "3390\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3391\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3393\n",
      "Found 312 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3394\n",
      "Found 225 pages, best-seller: No, film: No, saga: A's literature, followed by: nan, preceded by: Al Capone Shines My ShoesAl Capone Does My HomeworkAl Capone Throws Me A Curve\n",
      "3395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3396\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3399\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3400\n",
      "Found 403 pages, best-seller: No, film: Yes, saga: Gemma Doyle Trilogy, followed by: nan, preceded by: Rebel Angels\n",
      "3401\n",
      "Found 374 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: For Love of Audrey Rose\n",
      "3402\n",
      "Found 270 pages, best-seller: No, film: Yes, saga: No, followed by: The Sittaford Mystery, preceded by: The Thirteen Problems\n",
      "3403\n",
      "Found 199 pages, best-seller: No, film: Yes, saga: Inspector Cockrill, followed by: Heads You Lose, preceded by: Suddenly at His Residence\n",
      "3404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Discworld14th novel – 4th witches story, followed by: Small Gods, preceded by: Men at Arms\n",
      "3405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3406\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Pickwick Papers, preceded by: Nicholas Nickleby\n",
      "3407\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 224 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3409\n",
      "Found 3831 pages, best-seller: No, film: No, saga: Magids, followed by: nan, preceded by: The Merlin Conspiracy\n",
      "3410\n",
      "Found 181 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3412\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Tale of Two Bad Mice, preceded by: The Tale of the Pie and the Patty-Pan\n",
      "3413\n",
      "Found 309 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3414\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 265 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Riding the Rap\n",
      "3416\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Two Old Women(1993), preceded by: Raising Ourselves: A Gwich'in Coming of Age Story from the Yukon River (2002)\n",
      "3417\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 292 pages, best-seller: No, film: No, saga: No, followed by: The Iron Woman, preceded by: nan\n",
      "3419\n",
      "Found 286 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 464 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3421\n",
      "Found 398 pages, best-seller: No, film: No, saga: Dragonlord, followed by: The Last Dragonlord, preceded by: Bard's Oath\n",
      "3422\n",
      "Found 512 pages, best-seller: No, film: No, saga: American Empire, followed by: American Empire: The Center Cannot Hold, preceded by: Settling Accounts: Return Engagement\n",
      "3423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: The Pale Horse, preceded by: The Clocks\n",
      "3425\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3426\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3427\n",
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3428\n",
      "Found 2201 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3429\n",
      "Found 192 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: Ring, followed by: nan, preceded by: Spiral\n",
      "3431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 313 pages, best-seller: No, film: No, saga: Heechee Saga, followed by: nan, preceded by: Beyond the Blue Event Horizon\n",
      "3432\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3433\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Deliver Us from Evil: Defeating Terrorism, Despotism, and Liberalism\n",
      "3434\n",
      "Found 4641 pages, best-seller: No, film: No, saga: The Broken Earth trilogy, followed by: The Obelisk Gate, preceded by: nan\n",
      "3435\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3436\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3437\n",
      "Found 992003 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3438\n",
      "Found 314 pages, best-seller: No, film: Yes, saga: Dirk PittNovels, followed by: Iceberg, preceded by: Vixen 03\n",
      "3439\n",
      "Found 192 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3440\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Leave it to Psmith(novel),Blandings Castle and Elsewhere(shorts), preceded by: Heavy Weather\n",
      "3441\n",
      "Found 402 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3442\n",
      "Found 536 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3443\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Cricket in Times Square\n",
      "3444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3446\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3447\n",
      "Found 638 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3448\n",
      "Found 185 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3449\n",
      "Found 160 pages, best-seller: No, film: No, saga: No, followed by: Towards Zero, preceded by: Death Comes as the End\n",
      "3450\n",
      "Found 216 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3451\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3452\n",
      "Found 364 pages, best-seller: No, film: Yes, saga: Doctor Dolittle, followed by: The Story of Doctor Dolittle, preceded by: Doctor Dolittle's Post Office\n",
      "3453\n",
      "Found 768 pages, best-seller: Yes, film: Yes, saga: Robert Langdon#1, followed by: nan, preceded by: The Da Vinci Code\n",
      "3454\n",
      "Found 352 pages, best-seller: No, film: No, saga: No, followed by: The Panda's Thumb, preceded by: Hen's Teeth and Horse's Toes\n",
      "3455\n",
      "Found 190 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3456\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 228 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3458\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3459\n",
      "Found 260 pages, best-seller: No, film: No, saga: The Immortals series, followed by: nan, preceded by: Wolf-Speaker\n",
      "3460\n",
      "Found 205208 pages, best-seller: No, film: No, saga: The Cadfael Chronicles, followed by: The Hermit of Eyton Forest, preceded by: The Heretic's Apprentice\n",
      "3461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Cat Who Walks Through Walls\n",
      "3462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3463\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 128 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 420 pages, best-seller: No, film: Yes, saga: Kurt Wallander#5, followed by: The Man Who Smiled, preceded by: The Fifth Woman\n",
      "3466\n",
      "Found 213 pages, best-seller: No, film: Yes, saga: No, followed by: Hell's Angels: A Strange and Terrible Saga, preceded by: nan\n",
      "3467\n",
      "Found 271 pages, best-seller: No, film: Yes, saga: Sprawl trilogy, followed by: \"Burning Chrome\", preceded by: Count Zero\n",
      "3468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 393 pages, best-seller: No, film: No, saga: The Giver Quartet, followed by: Messenger, preceded by: nan\n",
      "3469\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Discworld18th novel – 5th witches story, followed by: Interesting Times, preceded by: Feet of Clay\n",
      "3470\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Ring, followed by: Ring, preceded by: Loop\n",
      "3471\n",
      "Found 505 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3472\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3473\n",
      "Found 348 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3474\n",
      "Found nan pages, best-seller: No, film: No, saga: Inspector Wexford#10, followed by: Shake Hands Forever, preceded by: Put on By Cunning\n",
      "3475\n",
      "Found 347 pages, best-seller: Yes, film: No, saga: No, followed by: An Urchin in the Storm, preceded by: Bully for Brontosaurus\n",
      "3476\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3477\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 286 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3480\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3481\n",
      "Found 362 pages, best-seller: No, film: No, saga: Vurt series, followed by: Automated Alice, preceded by: Pixel Juice\n",
      "3482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3483\n",
      "Found 368 pages, best-seller: No, film: No, saga: Yes, followed by: nan, preceded by: nan\n",
      "3484\n",
      "Found 462 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3485\n",
      "Found 149 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3486\n",
      "Found 275 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: So Many Ways To Begin\n",
      "3487\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Old Curiosity Shop, preceded by: Martin Chuzzlewit\n",
      "3488\n",
      "Found 287 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3489\n",
      "Found 1951 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Inspector Alan Banks, #9, followed by: Innocent Graves, preceded by: In a Dry Season\n",
      "3491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: The Story Girl, preceded by: nan\n",
      "3492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 431 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3494\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3495\n",
      "Found 130 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3496\n",
      "Found 233 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3497\n",
      "Found 576 pages, best-seller: No, film: Yes, saga: No, followed by: End of Watch, preceded by: If It Bleeds (novella)\n",
      "3498\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Spy Line, preceded by: Faith\n",
      "3499\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3500\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3501\n",
      "Found 308 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3502\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3503\n",
      "Found 165 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3504\n",
      "Found 4201 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3505\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: Voyages extraordinairesCaptain Nemo#1, followed by: In Search of the Castaways, preceded by: Around the Moon\n",
      "3506\n",
      "Found 311 pages, best-seller: No, film: No, saga: Heechee[2]The Heechee SagaGateway trilogy, followed by: Beyond the Blue Event Horizon, preceded by: The Annals of the Heechee\n",
      "3507\n",
      "Found nan pages, best-seller: No, film: No, saga: Curious George, followed by: Curious George Learns the Alphabet, preceded by: nan\n",
      "3508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 pages, best-seller: No, film: Yes, saga: Doctor Whobook:Eighth Doctor Adventures, followed by: Reckless Engineering, preceded by: Timeless\n",
      "3509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 246 pages, best-seller: No, film: Yes, saga: No, followed by: The Natural(1952), preceded by: The Magic Barrel (1958)\n",
      "3510\n",
      "Found 288 pages, best-seller: No, film: No, saga: Ringworld, followed by: The Ringworld Throne, preceded by: Fate of Worlds\n",
      "3511\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3513\n",
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3514\n",
      "Found 454 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 222 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3516\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3517\n",
      "Found nan pages, best-seller: No, film: No, saga: Ramona, followed by: Ramona and Her Mother, preceded by: Ramona Forever\n",
      "3518\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Heinlein juveniles, followed by: Space Cadet, preceded by: Farmer in the Sky\n",
      "3520\n",
      "Found 191 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3521\n",
      "Found 379 pages, best-seller: No, film: No, saga: The Salterton Trilogy, followed by: Leaven of Malice, preceded by: nan\n",
      "3522\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3523\n",
      "Found 369 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 326 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 549 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3527\n",
      "Found 460 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 850 pages, best-seller: No, film: No, saga: Outlanderseries, followed by: nan, preceded by: Dragonfly in Amber\n",
      "3529\n",
      "Found 352 pages, best-seller: No, film: No, saga: Word & Void series, followed by: Running with the Demon, preceded by: Angel Fire East\n",
      "3530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3531\n",
      "Found 310 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3532\n",
      "Found 9 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3533\n",
      "Found 384 pages, best-seller: No, film: No, saga: No, followed by: Pylon, preceded by: The Unvanquished\n",
      "3534\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: The Lazarus Effect, preceded by: nan\n",
      "3535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Lord Ramage novels, followed by: nan, preceded by: Ramage and the Drumbeat\n",
      "3536\n",
      "Found 254 pages, best-seller: No, film: No, saga: \"The Moon Pool\"June 22, 1918\"Conquest of the Moon Pool\"Weekly: February 15 – March 22, 1919, followed by: nan, preceded by: The Metal Monster\n",
      "3537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3538\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3539\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3540\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3541\n",
      "Found 160 pages, best-seller: No, film: No, saga: No, followed by: Anagrams (1986), preceded by: A Gate at the Stairs (2009)\n",
      "3542\n",
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3544\n",
      "Found 344427 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3545\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3548\n",
      "Found 272 pages, best-seller: No, film: No, saga: Chief Inspector Barnabyseries, followed by: The Killings at Badger's Drift, preceded by: Death in Disguise\n",
      "3549\n",
      "Found 286 pages, best-seller: No, film: No, saga: Albert Campion, followed by: Police at the Funeral, preceded by: Death of a Ghost\n",
      "3550\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Last Empress\n",
      "3551\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3552\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3553\n",
      "Found 605 pages, best-seller: No, film: No, saga: No, followed by: The Bear's Tears, preceded by: All the Grey Cats\n",
      "3554\n",
      "Found 239 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3555\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3556\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3557\n",
      "Found 252 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3558\n",
      "Found 405 pages, best-seller: No, film: No, saga: Vorkosigan Saga, followed by: Komarr, preceded by: Diplomatic Immunity\n",
      "3559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 208 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3560\n",
      "Found 199 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Starlight Barking (1967)\n",
      "3561\n",
      "Found 414 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3563\n",
      "Found 262 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 269 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 254 pages, best-seller: No, film: No, saga: Sir John Fielding, #1, followed by: none, preceded by: Murder in Grub Street\n",
      "3566\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Nigger of the 'Narcissus'(1897), preceded by: Lord Jim (1900)\n",
      "3567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 pages, best-seller: No, film: Yes, saga: Doctor Whobook:Eighth Doctor Adventures, followed by: Father Time, preceded by: EarthWorld\n",
      "3568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Doctor Whobook:Virgin New Adventures, followed by: Toy Soldiers, preceded by: The Also People\n",
      "3570\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 576 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3572\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Buru Quartet, followed by: nan, preceded by: Child of All Nations\n",
      "3573\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3574\n",
      "Found 384 pages, best-seller: No, film: No, saga: Inspector Morseseries, #13, followed by: Death Is Now My Neighbour, preceded by: nan\n",
      "3575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3576\n",
      "Found 32 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3578\n",
      "Found 299 pages, best-seller: No, film: No, saga: 13, followed by: nan, preceded by: nan\n",
      "3579\n",
      "Found 736 pages, best-seller: No, film: No, saga: No, followed by: Heroes Die, preceded by: Caine Black Knife\n",
      "3580\n",
      "Found 384 pages, best-seller: No, film: No, saga: Thursday Next, followed by: The Eyre Affair, preceded by: The Well of Lost Plots\n",
      "3581\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3582\n",
      "Found 307 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3584\n",
      "Found 257 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3586\n",
      "Found 196 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3587\n",
      "Found 255 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3588\n",
      "Found 503 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3589\n",
      "Found 2861 pages, best-seller: No, film: Yes, saga: No, followed by: Murder in Mesopotamia, preceded by: Murder in the Mews\n",
      "3590\n",
      "Found 298 pages, best-seller: No, film: No, saga: No, followed by: The Secret Adversary, preceded by: Poirot Investigates\n",
      "3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 336 pages, best-seller: No, film: No, saga: Warriors, followed by: A Dangerous Path, preceded by: Ravenpaw's PathFirestar's QuestMidnight\n",
      "3592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 375 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3594\n",
      "Found 224 pages, best-seller: No, film: No, saga: The Cadfael Chronicles, followed by: The Devil's Novice, preceded by: The Pilgrim of Hate\n",
      "3595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 295 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Edenborn\n",
      "3596\n",
      "Found 480 pages, best-seller: No, film: No, saga: Deverry cycle, followed by: First in series, preceded by: Darkspell\n",
      "3597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 384 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3599\n",
      "Found 214 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3600\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Tale of Tom Kitten, preceded by: The Tale of Samuel Whiskers or, The Roly-Poly Pudding\n",
      "3601\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3602\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3603\n",
      "Found 444 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3604\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3605\n",
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: In the Courts of the Crimson Kings\n",
      "3606\n",
      "Found 207 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3607\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3609\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3610\n",
      "Found 162 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3611\n",
      "Found 2102 pages, best-seller: No, film: No, saga: Chrestomanci, followed by: The Magicians of Caprona, preceded by: The Lives of Christopher Chant\n",
      "3612\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3614\n",
      "Found 160 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3615\n",
      "Found nan pages, best-seller: No, film: No, saga: War God series, followed by: nan, preceded by: The War God's Own\n",
      "3616\n",
      "Found 270 pages, best-seller: No, film: No, saga: Garrett P.I., followed by: Dread Brass Shadows, preceded by: Deadly Quicksilver Lies\n",
      "3617\n",
      "Found 261 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Outcasts of 19 Schuyler Place\n",
      "3618\n",
      "Found 158 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: George's Mother\n",
      "3619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3620\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3621\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Asterix, followed by: Asterix and Obelix All at Sea, preceded by: Asterix and the Class Act\n",
      "3622\n",
      "Found 560 pages, best-seller: No, film: No, saga: Saga of the Light Isles, followed by: -, preceded by: Foxmask\n",
      "3623\n",
      "Found 352 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Hayduke Lives!\n",
      "3624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 368 pages, best-seller: No, film: No, saga: Inspector Wexford# 23, followed by: The Monster in the Box, preceded by: No Man's Nightingale\n",
      "3625\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3626\n",
      "Found 1912161997 pages, best-seller: No, film: No, saga: Austin family, followed by: A Full House: An Austin Family Christmas, preceded by: The Moon by Night\n",
      "3627\n",
      "Found 432 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3628\n",
      "Found 470 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Equality (1897)\n",
      "3629\n",
      "Found 208 pages, best-seller: No, film: No, saga: Alliance-Union universe,the Merchanter novels, followed by: Downbelow Station, preceded by: Rimrunners\n",
      "3630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 458 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3631\n",
      "Found nan pages, best-seller: No, film: No, saga: Discworld33rd novel  – 1st Moist von Lipwig story, followed by: A Hat Full of Sky, preceded by: Thud!\n",
      "3632\n",
      "Found 352 pages, best-seller: No, film: No, saga: No, followed by: none, preceded by: Flash\n",
      "3633\n",
      "Found 222 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3634\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3635\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3636\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3637\n",
      "Found 331 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3638\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3639\n",
      "Found 2062 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3640\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3641\n",
      "Found nan pages, best-seller: No, film: No, saga: Curious George, followed by: Curious George Rides a Bike, preceded by: Curious George Flies a Kite\n",
      "3642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 466 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3644\n",
      "Found 879 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3645\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Safe House\n",
      "3646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3647\n",
      "Found 168 pages, best-seller: No, film: Yes, saga: Moomins, followed by: Moominsummer Madness, preceded by: Tales from Moominvalley\n",
      "3648\n",
      "Found 224 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3649\n",
      "Found 384 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3650\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3651\n",
      "Found 216 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3652\n",
      "Found 198 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3653\n",
      "Found 474 pages, best-seller: No, film: Yes, saga: The Forge of God series, followed by: nan, preceded by: Anvil of Stars\n",
      "3654\n",
      "Found 264 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3655\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3656\n",
      "Found 248 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 128 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3658\n",
      "Found 128 pages, best-seller: No, film: No, saga: The Sword of Truth, followed by: The First Confessor: The Legend of Magda Searus, preceded by: Wizard's First Rule\n",
      "3659\n",
      "Found 437 pages, best-seller: No, film: No, saga: No, followed by: –, preceded by: Cloud's Rider (1996)\n",
      "3660\n",
      "Found 556 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: The Big Fisherman\n",
      "3661\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Vile Bodies\n",
      "3662\n",
      "Found 365 pages, best-seller: No, film: No, saga: The Legends of Camber of Culdi, followed by: Camber of Culdi, preceded by: Camber the Heretic\n",
      "3663\n",
      "Found 238 pages, best-seller: No, film: Yes, saga: No, followed by: A Cool Million, preceded by: nan\n",
      "3664\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Albert Campion, followed by: More Work for the Undertaker, preceded by: The Beckoning Lady\n",
      "3665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 215 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3666\n",
      "Found 192 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 591 pages, best-seller: No, film: Yes, saga: Les Rougon-Macquart, followed by: La Bête humaine, preceded by: Nana\n",
      "3668\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3669\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Tess of the d'Urbervilles, preceded by: The Well-Beloved\n",
      "3670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 pages, best-seller: No, film: No, saga: The Riftwar Saga, followed by: Magician, preceded by: A Darkness at Sethanon\n",
      "3671\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3672\n",
      "Found 382 pages, best-seller: No, film: No, saga: No, followed by: Our Gang, preceded by: My Life as a Man\n",
      "3673\n",
      "Found 223 pages, best-seller: No, film: Yes, saga: Robotseries, followed by: Robot Visions, preceded by: \"Mother Earth\"\n",
      "3674\n",
      "Found nan pages, best-seller: No, film: No, saga: ConSentient, followed by: Whipping Star, preceded by: Eye\n",
      "3675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 536 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 464 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Bleeding Hearts\n",
      "3677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3678\n",
      "Found 352 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3680\n",
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3681\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3682\n",
      "Found 271 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3683\n",
      "Found 640 pages, best-seller: No, film: Yes, saga: Santangelonovels, followed by: Lucky, preceded by: Vendetta: Lucky's Revenge\n",
      "3684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 454 pages, best-seller: No, film: No, saga: Noughts & Crosses saga, followed by: nan, preceded by: Knife Edge\n",
      "3685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 592 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3686\n",
      "Found 208 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3687\n",
      "Found 166 pages, best-seller: No, film: No, saga: Jim Chee/Joe LeaphornNavajo Tribal Police Series, followed by: The Blessing Way(1970), preceded by: Listening Woman (1978)\n",
      "3688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3689\n",
      "Found 4341512 pages, best-seller: No, film: No, saga: The Warlord Chronicles, followed by: nan, preceded by: Enemy of God\n",
      "3690\n",
      "Found nan pages, best-seller: No, film: No, saga: Discworld5th novel – 3rd Rincewind story, followed by: Mort, preceded by: Wyrd Sisters\n",
      "3691\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3693\n",
      "Found 184 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3694\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3695\n",
      "Found 3001 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3696\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Lucia Triumphant, preceded by: Who's Afraid of Beowulf?\n",
      "3697\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Languedoc Trilogy, followed by: Labyrinth, preceded by: Citadel\n",
      "3698\n",
      "Found 207 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3699\n",
      "Found 403 pages, best-seller: No, film: No, saga: Multiple, followed by: nan, preceded by: nan\n",
      "3700\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3701\n",
      "Found 259 pages, best-seller: No, film: Yes, saga: James Bond, followed by: nan, preceded by: nan\n",
      "3702\n",
      "Found 304470 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 399 pages, best-seller: No, film: Yes, saga: His Dark Materials[1], followed by: La Belle Sauvage, preceded by: The Subtle Knife\n",
      "3704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3705\n",
      "Found 113 pages, best-seller: No, film: No, saga: Sam Krupnik, followed by: Attaboy, Sam!, preceded by: Zooman Sam\n",
      "3706\n",
      "Found 302 pages, best-seller: No, film: Yes, saga: Remembrance of Earth's Past, followed by: nan, preceded by: The Dark Forest\n",
      "3707\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Lord Peter Wimsey, followed by: Gaudy Night, preceded by: nan\n",
      "3708\n",
      "Found 245 pages, best-seller: No, film: No, saga: Nero Wolfe, followed by: Trouble in Triplicate, preceded by: Three Doors to Death\n",
      "3709\n",
      "Found 260 pages, best-seller: No, film: No, saga: No, followed by: The Power of Silence, preceded by: Magical Passes\n",
      "3710\n",
      "Found 272 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3711\n",
      "Found 768 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3712\n",
      "Found 314 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3713\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Dead Secret, preceded by: No Name\n",
      "3715\n",
      "Found 226 pages, best-seller: No, film: No, saga: No, followed by: The Revenge of the Lawn(1970), preceded by: The Hawkline Monster: A Gothic Western (1974)\n",
      "3716\n",
      "Found 399 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3717\n",
      "Found nan pages, best-seller: No, film: No, saga: Gideon Fell, followed by: The Problem of the Wire Cage, preceded by: The Case of the Constant Suicides\n",
      "3718\n",
      "Found 464 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3719\n",
      "Found 408 pages, best-seller: No, film: No, saga: Inspector Chen Cao, followed by: nan, preceded by: nan\n",
      "3720\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3721\n",
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 436 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3724\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: Rainbowtrilogy, followed by: nan, preceded by: Rainbow High\n",
      "3725\n",
      "Found 448 pages, best-seller: No, film: Yes, saga: The Vampire Chronicles, followed by: The Queen of the Damned, preceded by: Memnoch the Devil\n",
      "3726\n",
      "Found 426 pages, best-seller: No, film: No, saga: No, followed by: In the Winter Dark, preceded by: The Riders\n",
      "3727\n",
      "Found 450 pages, best-seller: No, film: No, saga: No, followed by: The Doubleman, preceded by: Out of Ireland\n",
      "3728\n",
      "Found 295 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 512 pages, best-seller: No, film: No, saga: Insurrectiontrilogy, followed by: nan, preceded by: Renegade (2012)[1]\n",
      "3730\n",
      "Found 217 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3731\n",
      "Found 263 pages, best-seller: No, film: No, saga: Johnny Maxwell Trilogy, followed by: Johnny and the Dead, preceded by: nan\n",
      "3732\n",
      "Found 200 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3734\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: To the North(1932), preceded by: The Death of the Heart(1938)\n",
      "3735\n",
      "Found 264 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3737\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Beautiful and Damned (1922)\n",
      "3738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3739\n",
      "Found 527 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3740\n",
      "Found 193 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3741\n",
      "Found 230 pages, best-seller: No, film: Yes, saga: Indiana Jones, followed by: Indiana Jones and the Peril at Delphi, preceded by: Indiana Jones and the Seven Veils\n",
      "3742\n",
      "Found 127 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3743\n",
      "Found 3711 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3744\n",
      "Found 255 pages, best-seller: No, film: No, saga: Doctor Whobook:Virgin New Adventures, followed by: Sanctuary, preceded by: Original Sin\n",
      "3745\n",
      "Found 90 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3746\n",
      "Found 188 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3747\n",
      "Found 191 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3749\n",
      "Found 209225 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3750\n",
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3751\n",
      "Found 597 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3752\n",
      "Found 197 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3753\n",
      "Found 144 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3754\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Icerigger, preceded by: The Deluge Drivers\n",
      "3755\n",
      "Found 312 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3756\n",
      "Found 414 pages, best-seller: No, film: No, saga: The Morgaine Stories, followed by: Fires of Azeroth(1979), preceded by: nan\n",
      "3757\n",
      "Found 255 pages, best-seller: No, film: No, saga: Dalemark Quartet, followed by: Cart and Cwidder, preceded by: The Spellcoats\n",
      "3758\n",
      "Found 192 pages, best-seller: No, film: No, saga: The Bagthorpe Saga, followed by: nan, preceded by: Absolute Zero\n",
      "3759\n",
      "Found 704 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3762\n",
      "Found 312 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3763\n",
      "Found 232 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 293 pages, best-seller: No, film: Yes, saga: Nero Wolfe, followed by: Some Buried Caesar, preceded by: Where There's a Will\n",
      "3765\n",
      "Found 277 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3766\n",
      "Found nan pages, best-seller: No, film: Yes, saga: World of Warcraft, followed by: nan, preceded by: nan\n",
      "3767\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Cider with Rosie, preceded by: A Moment of War\n",
      "3768\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3769\n",
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3770\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3771\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3772\n",
      "Found 501 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 pages, best-seller: No, film: No, saga: No, followed by: The Lime Twig, preceded by: The Innocent Party\n",
      "3774\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3775\n",
      "Found 240 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3776\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Great Expectations, preceded by: The Mystery of Edwin Drood\n",
      "3777\n",
      "Found 240 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3778\n",
      "Found 2811 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3780\n",
      "Found 176 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3781\n",
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: Coyote Blue, preceded by: Island of the Sequined Love Nun\n",
      "3782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3783\n",
      "Found 368 pages, best-seller: No, film: No, saga: No, followed by: Angela's Ashes, preceded by: Teacher Man\n",
      "3784\n",
      "Found 560 pages, best-seller: No, film: Yes, saga: The Vampire Chronicles, followed by: Interview with the Vampire, preceded by: The Queen of the Damned\n",
      "3785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3786\n",
      "Found 32 pages, best-seller: No, film: No, saga: No, followed by: The Z Was Zapped, preceded by: Just a Dream\n",
      "3787\n",
      "Found 304 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3788\n",
      "Found 390 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Romanov Prophecy\n",
      "3789\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: Double Sin and Other Stories, preceded by: The Mirror Crack'd from Side to Side\n",
      "3790\n",
      "Found 186 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Scarlet Gospels\n",
      "3791\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 179 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3793\n",
      "Found 431878 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3794\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3795\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3796\n",
      "Found 294268 pages, best-seller: No, film: Yes, saga: Aubrey-Maturin series, followed by: HMS Surprise, preceded by: Desolation Island\n",
      "3797\n",
      "Found 256 pages, best-seller: No, film: No, saga: Garrett P.I., followed by: nan, preceded by: Bitter Gold Hearts\n",
      "3798\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3799\n",
      "Found 167 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3800\n",
      "Found 240 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3801\n",
      "Found 191 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3802\n",
      "Found 252 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3803\n",
      "Found 335 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3804\n",
      "Found 208 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3805\n",
      "Found 400 pages, best-seller: No, film: Yes, saga: Dollanganger series, followed by: nan, preceded by: Petals on the Wind (1980)\n",
      "3806\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: David Copperfield, preceded by: A Child's History of England\n",
      "3807\n",
      "Found 416 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3808\n",
      "Found 127 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 268 pages, best-seller: No, film: No, saga: Cheela, followed by: Dragon's Egg, preceded by: nan\n",
      "3810\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3811\n",
      "Found 128 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3812\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3813\n",
      "Found nan pages, best-seller: No, film: No, saga: Discworld13th novel – 3rd individual story, followed by: Witches Abroad, preceded by: Lords and Ladies\n",
      "3814\n",
      "Found nan pages, best-seller: No, film: No, saga: Discworld17th novel – 5th Rincewind story, followed by: Soul Music, preceded by: Maskerade\n",
      "3815\n",
      "Found 213 pages, best-seller: No, film: No, saga: No, followed by: The Tiger's Daughter(1971), preceded by: Darkness (1985)\n",
      "3816\n",
      "Found 342 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3817\n",
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3818\n",
      "Found 4734681 pages, best-seller: No, film: No, saga: Magids, followed by: Deep Secret, preceded by: nan\n",
      "3819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3820\n",
      "Found 128 pages, best-seller: No, film: No, saga: No, followed by: \"Rommel?\" \"Gunner Who?\", preceded by: Mussolini: His Part in My Downfall\n",
      "3821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 pages, best-seller: No, film: Yes, saga: No, followed by: Popcorn (1996),, preceded by: Inconceivable (1999)\n",
      "3822\n",
      "Found 160 pages, best-seller: No, film: No, saga: Hainish Cycle, followed by: Planet of Exile, preceded by: The Left Hand of Darkness\n",
      "3823\n",
      "Found 151 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3824\n",
      "Found 537 pages, best-seller: No, film: No, saga: Dirk PittNovels, followed by: Inca Gold, preceded by: Flood Tide\n",
      "3825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 461 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3826\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3827\n",
      "Found 145 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3828\n",
      "Found 320 pages, best-seller: No, film: No, saga: Chief Inspector Armand Gamache, followed by: A Fatal Grace, preceded by: A Rule Against Murder\n",
      "3829\n",
      "Found 307 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3830\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3831\n",
      "Found 577 pages, best-seller: No, film: No, saga: The Expanse, followed by: nan, preceded by: Caliban's War\n",
      "3832\n",
      "Found 368 pages, best-seller: No, film: No, saga: Orion, followed by: Vengeance of Orion, preceded by: Orion and the Conqueror\n",
      "3833\n",
      "Found 233 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3834\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3835\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3836\n",
      "Found nan pages, best-seller: No, film: No, saga: Asterix, followed by: The Mansions of the Gods, preceded by: Asterix and the Soothsayer\n",
      "3837\n",
      "Found 144 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3838\n",
      "Found 298 pages, best-seller: No, film: No, saga: Nero Wolfe, followed by: The Rubber Band, preceded by: Too Many Cooks\n",
      "3839\n",
      "Found 186 pages, best-seller: No, film: Yes, saga: Nero Wolfe, followed by: Triple Jeopardy, preceded by: The Golden Spiders\n",
      "3840\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3841\n",
      "Found 159 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Ben, in the World\n",
      "3842\n",
      "Found 185 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3843\n",
      "Found 380 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Lord of Opium\n",
      "3844\n",
      "Found 287 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3845\n",
      "Found 151 pages, best-seller: No, film: No, saga: Star Trek, followed by: The Price of the Phoenix, preceded by: Vulcan!\n",
      "3846\n",
      "Found 405 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 pages, best-seller: No, film: No, saga: Clifton Chronicles(Book 2), followed by: Only Time Will Tell, preceded by: Best Kept Secret\n",
      "3848\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3849\n",
      "Found 2771925 pages, best-seller: No, film: Yes, saga: The Katy Books, followed by: nan, preceded by: What Katy Did at School\n",
      "3850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 321 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3851\n",
      "Found 255 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3853\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3855\n",
      "Found 310 pages, best-seller: No, film: No, saga: No, followed by: Au bonheur des ogres, preceded by: La Petite Marchand de prose\n",
      "3856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Jesse Stone, followed by: Night and Day, preceded by: nan\n",
      "3857\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3858\n",
      "Found 346 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3859\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3860\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3861\n",
      "Found nan pages, best-seller: No, film: No, saga: Moomins, followed by: Moominpappa at Sea, preceded by: nan\n",
      "3862\n",
      "Found 272 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 295 pages, best-seller: Yes, film: Yes, saga: James Bond, followed by: nan, preceded by: nan\n",
      "3864\n",
      "Found 236 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3865\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3866\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3867\n",
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 128 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3869\n",
      "Found nan pages, best-seller: No, film: No, saga: Tawny Man Trilogy, followed by: nan, preceded by: The Golden Fool\n",
      "3870\n",
      "Found 272 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3871\n",
      "Found 318 pages, best-seller: No, film: Yes, saga: Tarzan series, followed by: Tarzan and the Leopard Men, preceded by: Tarzan and the Forbidden City\n",
      "3872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 344 pages, best-seller: No, film: Yes, saga: No, followed by: The Honorary Consul, preceded by: Doctor Fischer of Geneva or The Bomb Party\n",
      "3874\n",
      "Found 407 pages, best-seller: No, film: Yes, saga: Cutler series, followed by: nan, preceded by: Secrets of the Morning (1991)\n",
      "3875\n",
      "Found 445 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3876\n",
      "Found 467 pages, best-seller: No, film: No, saga: No, followed by: The Void Captain's Tale, preceded by: nan\n",
      "3877\n",
      "Found 544 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3878\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3880\n",
      "Found 220 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3881\n",
      "Found 262 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3882\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3883\n",
      "Found 272 pages, best-seller: No, film: No, saga: Horatio Hornblower, followed by: Flying Colours(1938), preceded by: Lord Hornblower (1946)\n",
      "3884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 397 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3886\n",
      "Found 186 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3887\n",
      "Found 191 pages, best-seller: No, film: No, saga: The Tanith Series, followed by: nan, preceded by: Prince of Tanith\n",
      "3888\n",
      "Found 6241 pages, best-seller: No, film: Yes, saga: No, followed by: Dombey and Son, preceded by: Bleak House\n",
      "3889\n",
      "Found 352 pages, best-seller: No, film: Yes, saga: Ender's Game series, followed by: nan, preceded by: Earth Afire\n",
      "3890\n",
      "Found 134 pages, best-seller: No, film: No, saga: No, followed by: An Imaginary Life, preceded by: Harland's Half Acre\n",
      "3891\n",
      "Found 216 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3892\n",
      "Found 316 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: The Jesus Incident, preceded by: The Ascension Factor\n",
      "3894\n",
      "Found nan pages, best-seller: No, film: No, saga: Heinlein juveniles, followed by: The Rolling Stones, preceded by: The Star Beast\n",
      "3895\n",
      "Found 248 pages, best-seller: No, film: Yes, saga: Nero Wolfe, followed by: Curtains for Three, preceded by: Triple Jeopardy\n",
      "3896\n",
      "Found 377 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3897\n",
      "Found 326 pages, best-seller: No, film: Yes, saga: Merlin Saga, followed by: First in series, preceded by: Merlin Book 2: The Seven Songs\n",
      "3898\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3899\n",
      "Found 3511 pages, best-seller: No, film: No, saga: Lord Peter Wimsey, followed by: Strong Poison, preceded by: Have His Carcase\n",
      "3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 660 pages, best-seller: Yes, film: No, saga: Freehold Series, followed by: nan, preceded by: The Weapon\n",
      "3901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Disappearance at Devil's Rock, preceded by: Survivor Song\n",
      "3902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Cause for Alarm, preceded by: Judgment on Deltchev\n",
      "3903\n",
      "Found 160 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3904\n",
      "Found 42 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3905\n",
      "Found 368 pages, best-seller: No, film: No, saga: High Druid of Shannara, followed by: Jarka Ruus, preceded by: Straken\n",
      "3906\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3907\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3908\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3909\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3910\n",
      "Found 336 pages, best-seller: No, film: No, saga: No, followed by: Idlewild, preceded by: Everfree\n",
      "3911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 349 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4181 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 141 pages, best-seller: No, film: No, saga: Veritas Maritime, followed by: nan, preceded by: nan\n",
      "3914\n",
      "Found 432 pages, best-seller: Yes, film: No, saga: Amos Decker, followed by: nan, preceded by: nan\n",
      "3915\n",
      "Found 554 pages, best-seller: No, film: No, saga: Saga of the Light Isles, followed by: Wolfskin, preceded by: -\n",
      "3916\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Tri Ogalala, preceded by: nan\n",
      "3917\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3918\n",
      "Found 496 pages, best-seller: No, film: No, saga: The Emberverse series, followed by: nan, preceded by: The Protector's War\n",
      "3919\n",
      "Found 296 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3921\n",
      "Found 355 pages, best-seller: No, film: No, saga: No, followed by: Singularity Sky, preceded by: nan\n",
      "3922\n",
      "Found 363 pages, best-seller: No, film: No, saga: Avalon Series, followed by: The Fall of Atlantis(Web of Light/Web of Darkness), preceded by: Ravens of Avalon\n",
      "3923\n",
      "Found 480 pages, best-seller: No, film: No, saga: Spatterjay sequence, followed by: nan, preceded by: The Voyage of the Sable Keech\n",
      "3924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3925\n",
      "Found 576 pages, best-seller: No, film: Yes, saga: Bas-Lagnovels, followed by: The Scar, preceded by: nan\n",
      "3926\n",
      "Found 372 pages, best-seller: No, film: No, saga: Troll Trilogy, followed by: nan, preceded by: Troll Mill\n",
      "3927\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 230 pages, best-seller: No, film: No, saga: The Ice Trilogy, followed by: nan, preceded by: Ice (Sorokin novel)\n",
      "3929\n",
      "Found 565 pages, best-seller: No, film: No, saga: Revelation Space, followed by: Redemption Ark, preceded by: The Prefect\n",
      "3930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 368 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3931\n",
      "Found 341 pages, best-seller: No, film: No, saga: No, followed by: Zeitgeist, preceded by: Visionary in Residence\n",
      "3932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3933\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3934\n",
      "Found 4481 pages, best-seller: No, film: No, saga: Tetragrammaton Series, followed by: nan, preceded by: nan\n",
      "3935\n",
      "Found 309 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3936\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6721 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 337 pages, best-seller: No, film: Yes, saga: Meetings Sextet, followed by: nan, preceded by: Wanderlust\n",
      "3939\n",
      "Found 462 pages, best-seller: No, film: Yes, saga: Shane Schofield, followed by: Area 7, preceded by: Scarecrow and the Army of Thieves\n",
      "3940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400366 pages, best-seller: No, film: No, saga: Takeshi Kovacs, followed by: Altered Carbon, preceded by: Woken Furies\n",
      "3941\n",
      "Found 436 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3942\n",
      "Found 400 pages, best-seller: No, film: No, saga: Wess'Har Series, followed by: nan, preceded by: Crossing the Line\n",
      "3943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47621 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3944\n",
      "Found 394 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624656 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3946\n",
      "Found 480 pages, best-seller: No, film: No, saga: Destiny's ChildrenXeelee Sequence, followed by: nan, preceded by: Exultant\n",
      "3947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3948\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3949\n",
      "Found 400 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3950\n",
      "Found 384 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3951\n",
      "Found 359 pages, best-seller: No, film: No, saga: The Childe Morgan Trilogy, followed by: King Kelson's Bride(publication date),The Bastard Prince(literary chronology), preceded by: Childe Morgan\n",
      "3952\n",
      "Found 352 pages, best-seller: No, film: No, saga: Marcus Didius Falco, followed by: A Body in the Bath House, preceded by: The Accusers\n",
      "3953\n",
      "Found 464 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3954\n",
      "Found 432 pages, best-seller: No, film: No, saga: No, followed by: Warchild, preceded by: Cagebird\n",
      "3955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3956\n",
      "Found 400 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Iron Sunrise\n",
      "3957\n",
      "Found 496 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 336 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3959\n",
      "Found 576 pages, best-seller: No, film: No, saga: Revelation Space, followed by: Chasm City, preceded by: Absolution Gap\n",
      "3960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 pages, best-seller: No, film: No, saga: Matthew Shardlake Series, followed by: nan, preceded by: Dark Fire\n",
      "3961\n",
      "Found 352 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3962\n",
      "Found 352 pages, best-seller: No, film: No, saga: The Dragonkeeper trilogy, followed by: Garden of the Purple Dragon, preceded by: Blood Brothers\n",
      "3963\n",
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Third Policeman\n",
      "3964\n",
      "Found 608 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3965\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3966\n",
      "Found 384 pages, best-seller: No, film: No, saga: Hellenic Traders, followed by: Over the Wine Dark Sea, preceded by: The Sacred Land\n",
      "3967\n",
      "Found 589 pages, best-seller: No, film: No, saga: Empire of Man\\Roger MacClintock series, followed by: March to the Sea, preceded by: We Few\n",
      "3968\n",
      "Found 412 pages, best-seller: Yes, film: No, saga: No, followed by: The Bottoms(2000), preceded by: Sunset and Sawdust (2004)\n",
      "3969\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3970\n",
      "Found 240 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3971\n",
      "Found 349 pages, best-seller: No, film: Yes, saga: Ender's Game series, followed by: Xenocide, preceded by: A War of Gifts\n",
      "3972\n",
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3973\n",
      "Found 512 pages, best-seller: No, film: No, saga: American Empire, followed by: American Empire: Blood and Iron, preceded by: American Empire: The Victorious Opposition\n",
      "3974\n",
      "Found 400 pages, best-seller: No, film: No, saga: No, followed by: Grasshopper, preceded by: The Minotaur\n",
      "3975\n",
      "Found 243 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3977\n",
      "Found 249 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 322 pages, best-seller: No, film: Yes, saga: Jesse Stone, followed by: nan, preceded by: Trouble in Paradise\n",
      "3979\n",
      "3980\n",
      "Found 368359 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Seven Hills\n",
      "3981\n",
      "Found 768 pages, best-seller: Yes, film: Yes, saga: Robert Langdon#1, followed by: nan, preceded by: The Da Vinci Code\n",
      "3982\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3983\n",
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3984\n",
      "Found 272 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3985\n",
      "Found 208 pages, best-seller: No, film: No, saga: Conan the Barbarian, followed by: nan, preceded by: nan\n",
      "3986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 336 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3987\n",
      "Found 375 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3988\n",
      "Found 96 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3989\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Reflections on a Marine Venus (1953), preceded by: Blue Thirst (1975)\n",
      "3990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 319 pages, best-seller: No, film: No, saga: The Black Company, followed by: nan, preceded by: Shadows Linger\n",
      "3991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Doctor Whobook:Virgin New Adventures, followed by: Lucifer Rising, preceded by: Shadowmind\n",
      "3992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 432 pages, best-seller: No, film: No, saga: The Wizard Knight, followed by: nan, preceded by: The Wizard\n",
      "3993\n",
      "Found 220 pages, best-seller: No, film: No, saga: No, followed by: Ironman, preceded by: The Sledding Hill\n",
      "3994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "3995\n",
      "Found 319 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3996\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "3997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 212 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Perfect English\n",
      "3998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: The Husband's Secret, preceded by: Truly Madly Guilty\n",
      "3999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Pickwick Papers, preceded by: Nicholas Nickleby\n",
      "4000\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4001\n",
      "Found 366 pages, best-seller: No, film: No, saga: Merlin's Godson, followed by: The Ship From Atlantis, preceded by: none\n",
      "4002\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4003\n",
      "Found 279 pages, best-seller: No, film: No, saga: Sir John Fielding, #5, followed by: Person or Persons Unknown, preceded by: Death of a Colonial\n",
      "4004\n",
      "Found 182 pages, best-seller: No, film: No, saga: Nero Wolfe, followed by: Trio for Blunt Instruments, preceded by: The Doorbell Rang\n",
      "4005\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4006\n",
      "Found 342 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4007\n",
      "Found 144 pages, best-seller: No, film: Yes, saga: No, followed by: #$@ &!: The Official Lloyd Llewellyn Collection, preceded by: The Manly World of Lloyd Llewellyn: a Golden Treasury of his Complete Works\n",
      "4008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4009\n",
      "Found 179 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Mid-Flinx\n",
      "4010\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4011\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4012\n",
      "Found 169 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4013\n",
      "Found 180 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4015\n",
      "Found 296 pages, best-seller: No, film: Yes, saga: No, followed by: The Big Four, preceded by: The Seven Dials Mystery\n",
      "4016\n",
      "Found 223 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4017\n",
      "Found 440 pages, best-seller: No, film: No, saga: Inspector Rebus, followed by: The Falls, preceded by: A Question of Blood\n",
      "4018\n",
      "Found 215 pages, best-seller: No, film: No, saga: Kukulkan, followed by: nan, preceded by: The Venom Trees of Sunga\n",
      "4019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 399 pages, best-seller: No, film: Yes, saga: The Domination, followed by: The Stone Dogs, preceded by: Drakas!\n",
      "4020\n",
      "Found 384 pages, best-seller: No, film: No, saga: Space Trilogy, followed by: Perelandra, preceded by: nan\n",
      "4021\n",
      "Found 262 pages, best-seller: No, film: No, saga: No, followed by: Homunculus, preceded by: nan\n",
      "4022\n",
      "Found 648 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4024\n",
      "4025\n",
      "Found 32 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4026\n",
      "Found 471 pages, best-seller: No, film: No, saga: The Forge of God Series, followed by: The Forge of God, preceded by: nan\n",
      "4027\n",
      "Found nan pages, best-seller: No, film: No, saga: Malory Towers, followed by: none, preceded by: The Second Form at Malory Towers\n",
      "4028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 296 pages, best-seller: No, film: No, saga: Adam Dalgliesh#4, followed by: Unnatural Causes, preceded by: The Black Tower\n",
      "4029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: The House of the Dead, followed by: nan, preceded by: nan\n",
      "4030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 pages, best-seller: No, film: Yes, saga: Red Dwarf, followed by: Last Human, preceded by: nan\n",
      "4031\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: The Story of Miss Moppet, preceded by: The Tale of Jemima Puddle-Duck\n",
      "4032\n",
      "Found 253 pages, best-seller: No, film: No, saga: Xeelee Sequence, followed by: Raft, preceded by: Flux\n",
      "4033\n",
      "Found nan pages, best-seller: No, film: No, saga: Asterix, followed by: Asterix and the Roman Agent, preceded by: The Mansions of the Gods\n",
      "4034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4035\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4036\n",
      "Found 137 pages, best-seller: No, film: No, saga: No, followed by: The Once and Future King, preceded by: nan\n",
      "4037\n",
      "Found 192 pages, best-seller: No, film: No, saga: The Zone Unknown, followed by: Rats, preceded by: Night of the Bat\n",
      "4038\n",
      "Found 586 pages, best-seller: No, film: No, saga: Empire of Man\\Roger MacClintock series, followed by: nan, preceded by: March to the Sea\n",
      "4039\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Georgics, preceded by: nan\n",
      "4040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4041\n",
      "Found 403 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4042\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4043\n",
      "Found 192 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 415 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4045\n",
      "Found 262 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 288 pages, best-seller: No, film: Yes, saga: No, followed by: When We Were Orphans, preceded by: Nocturnes\n",
      "4047\n",
      "Found 317 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4048\n",
      "Found 306 pages, best-seller: No, film: Yes, saga: Dragonlance, followed by: nan, preceded by: nan\n",
      "4049\n",
      "Found 247 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4050\n",
      "Found 4531 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Closing Time (1994)\n",
      "4051\n",
      "Found 215 pages, best-seller: No, film: No, saga: The Chronicles of Amber, followed by: Trumps of Doom, preceded by: Sign of Chaos\n",
      "4052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Doctor Whobook:Virgin New Adventures, followed by: All-Consuming Fire, preceded by: Strange England\n",
      "4053\n",
      "Found 160 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4054\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Ramona, followed by: Ramona Quimby, Age 8-1981, preceded by: Ramona's World -1999\n",
      "4055\n",
      "Found 698 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4056\n",
      "Found 480 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: The Art of Seduction\n",
      "4057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 388 pages, best-seller: No, film: No, saga: Harry Bosch#18, followed by: The Burning Room, preceded by: The Wrong Side of Goodbye\n",
      "4058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4060\n",
      "Found 237 pages, best-seller: No, film: Yes, saga: The Oz Books, followed by: nan, preceded by: nan\n",
      "4061\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1882014 pages, best-seller: No, film: No, saga: Apple Paperbacks, followed by: nan, preceded by: nan\n",
      "4063\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4064\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4065\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Tailor of Gloucester, preceded by: The Tale of Two Bad Mice\n",
      "4066\n",
      "Found 336 pages, best-seller: No, film: No, saga: No, followed by: Brown Girl in the Ring, preceded by: nan\n",
      "4067\n",
      "Found 283 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4068\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4069\n",
      "Found 417 pages, best-seller: Yes, film: No, saga: TheFoundationSeries, followed by: Prelude to Foundation, preceded by: Foundation\n",
      "4070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: together withPearl,CleannessandPatience, followed by: nan, preceded by: nan\n",
      "4071\n",
      "Found 196 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4072\n",
      "Found 324 pages, best-seller: No, film: No, saga: Alex Rider series, followed by: Point Blanc, preceded by: Eagle Strike\n",
      "4073\n",
      "Found 288 pages, best-seller: No, film: No, saga: Alex Rider series, followed by: Stormbreaker, preceded by: Skeleton Key\n",
      "4074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 128 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4075\n",
      "Found 184 pages, best-seller: No, film: No, saga: Judge Dee, followed by: The Haunted Monastery, preceded by: The Monkey and the Tiger\n",
      "4076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 324 pages, best-seller: No, film: No, saga: Jesse Stone, followed by: Night Passage, preceded by: Death in Paradise\n",
      "4077\n",
      "Found 394 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 432 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4079\n",
      "Found 243 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4080\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Famous Fiveseries, followed by: Five Have a Mystery to Solve, preceded by: nan\n",
      "4081\n",
      "Found 186 pages, best-seller: No, film: No, saga: Nero Wolfe, followed by: Three for the Chair, preceded by: And Four to Go\n",
      "4082\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 191 pages, best-seller: No, film: Yes, saga: No, followed by: Crime and Punishment, preceded by: The Idiot\n",
      "4084\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Tale of Benjamin Bunny, preceded by: The Tale of Mrs. Tiggy-Winkle\n",
      "4085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 336 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 157 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4087\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4088\n",
      "Found 112 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4089\n",
      "Found 238 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Pull Out All the Stops!\n",
      "4090\n",
      "Found 256 pages, best-seller: No, film: No, saga: James Bond, followed by: nan, preceded by: nan\n",
      "4091\n",
      "Found 284 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4092\n",
      "Found 251 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4094\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 212 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4097\n",
      "Found 18636391964 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4098\n",
      "Found 167 pages, best-seller: No, film: No, saga: Ware Tetralogy, followed by: nan, preceded by: Wetware\n",
      "4099\n",
      "Found 208 pages, best-seller: No, film: No, saga: 'Dead' trilogy, followed by: nan, preceded by: Dead Boys\n",
      "4100\n",
      "Found 527 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4101\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4102\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4103\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 pages, best-seller: No, film: No, saga: The 39 Clues, followed by: The Sword Thief, preceded by: The Black Circle\n",
      "4105\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Schoolmaster, preceded by: The Wine of Astonishment\n",
      "4106\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: A Treatise of Human Nature, preceded by: An Enquiry Concerning the Principles of Morals\n",
      "4107\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4108\n",
      "Found 452 pages, best-seller: No, film: No, saga: Marcus Didius Falco, followed by: The Silver Pigs, preceded by: Venus in Copper\n",
      "4109\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: The Road Goes Ever On, preceded by: Bilbo's Last Song (posthumous)\n",
      "4110\n",
      "Found 226 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Who P-P-P-Plugged Roger Rabbit?\n",
      "4111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 253 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 183 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4113\n",
      "Found 399 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4114\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: One, Two, Buckle My Shoe, preceded by: N or M?\n",
      "4115\n",
      "Found 188 pages, best-seller: No, film: No, saga: Known Space Universe, followed by: nan, preceded by: nan\n",
      "4116\n",
      "Found 212 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4117\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4118\n",
      "Found 246 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4120\n",
      "Found 240 pages, best-seller: No, film: Yes, saga: Philip Marlowe, followed by: Farewell, My Lovely, preceded by: The Lady in the Lake\n",
      "4121\n",
      "Found 399 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4122\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4123\n",
      "Found 320 pages, best-seller: No, film: Yes, saga: Allan Quatermain Series, followed by: The Witch's Head, preceded by: She: A History of Adventure\n",
      "4124\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4125\n",
      "Found 416432 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4126\n",
      "Found 192 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4127\n",
      "Found 243 pages, best-seller: No, film: No, saga: Fafhrd and the Gray Mouserseries, followed by: The Swords of Lankhmar, preceded by: The Knight and Knave of Swords\n",
      "4128\n",
      "Found 1911 pages, best-seller: No, film: No, saga: No, followed by: Gone-Away Lake, preceded by: nan\n",
      "4129\n",
      "Found nan pages, best-seller: No, film: No, saga: Confessions of a Teenage Drama Queen, followed by: Confessions of a Teenage Drama Queen, preceded by: Confessions of a Hollywood Star\n",
      "4130\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4131\n",
      "Found 483 pages, best-seller: No, film: Yes, saga: No, followed by: Sir Nigel, preceded by: nan\n",
      "4132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4133\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4134\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4135\n",
      "Found 183 pages, best-seller: Yes, film: No, saga: Realistic Fiction, followed by: nan, preceded by: nan\n",
      "4136\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4137\n",
      "Found 198 pages, best-seller: No, film: Yes, saga: No, followed by: The Storyteller, preceded by: Death in the Andes\n",
      "4138\n",
      "Found 282 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 pages, best-seller: No, film: Yes, saga: No, followed by: Thy Neighbour's Wife, preceded by: Return of the Brute\n",
      "4140\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4142\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4143\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4144\n",
      "Found 250 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: The Extraordinary Voyages#5, followed by: From the Earth to the Moon, preceded by: Twenty Thousand Leagues Under the Sea\n",
      "4146\n",
      "Found 246 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4147\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4148\n",
      "Found 119 pages, best-seller: No, film: No, saga: The Anastasia Series, followed by: Anastasia at Your Service, preceded by: Anastasia on Her Own\n",
      "4149\n",
      "Found 229 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4150\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4151\n",
      "Found 323 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4152\n",
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 265 pages, best-seller: No, film: Yes, saga: No, followed by: The Temptation of Eileen Hughes(1981), preceded by: Black Robe (1985)\n",
      "4155\n",
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4156\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4157\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4158\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Ulysses(1922), preceded by: nan\n",
      "4159\n",
      "Found 124 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4160\n",
      "Found 222 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4161\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4162\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: A Canticle for Leibowitz, preceded by: nan\n",
      "4163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 384 pages, best-seller: No, film: No, saga: League of Peoples, followed by: Commitment Hour, preceded by: Hunted\n",
      "4164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 169 pages, best-seller: No, film: No, saga: The Giver Quartet, followed by: Gathering Blue, preceded by: Son\n",
      "4165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 619 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4166\n",
      "Found 384 pages, best-seller: No, film: No, saga: Outlaw Chronicles, followed by: nan, preceded by: Holy Warrior(2010)\n",
      "4167\n",
      "Found 262 pages, best-seller: No, film: Yes, saga: The Demonataseries, followed by: Bec, preceded by: Demon Apocalypse\n",
      "4168\n",
      "Found 197 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4169\n",
      "Found 314 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4170\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4171\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: Giant's Bread, preceded by: The Sittaford Mystery\n",
      "4172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4173\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Famous Fiveseries, followed by: Five on a Secret Trail, preceded by: Five Get Into A Fix\n",
      "4174\n",
      "Found 184 pages, best-seller: No, film: Yes, saga: Inspector Wexford#3, followed by: A New Lease of Death, preceded by: The Best Man to Die\n",
      "4175\n",
      "Found 240 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4177\n",
      "Found 80 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4178\n",
      "Found 297 pages, best-seller: No, film: Yes, saga: No, followed by: The Ministry of Fear(1943), preceded by: The Third Man (1949)\n",
      "4179\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4181\n",
      "Found 164 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4182\n",
      "Found 272 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4184\n",
      "Found 243 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4185\n",
      "Found 253 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4186\n",
      "Found nan pages, best-seller: No, film: No, saga: Riverworld, followed by: The Fabulous Riverboat, preceded by: The Magic Labyrinth\n",
      "4187\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4188\n",
      "Found 273 pages, best-seller: No, film: No, saga: The Deptford Trilogy, followed by: nan, preceded by: The Manticore\n",
      "4189\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Oz books, followed by: The Patchwork Girl of Oz, preceded by: The Scarecrow of Oz\n",
      "4190\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: The Oz books, followed by: The Lost Princess of Oz, preceded by: The Magic of Oz\n",
      "4191\n",
      "Found 240 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Sky Island\n",
      "4192\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Oz books, followed by: Tik-Tok of OzSky Island, preceded by: Rinkitink in Oz\n",
      "4193\n",
      "Found 242 pages, best-seller: No, film: Yes, saga: The Oz Books, followed by: nan, preceded by: nan\n",
      "4194\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Oz books, followed by: Glinda of Oz, preceded by: Kabumpo in Oz\n",
      "4195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 138 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4196\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Oz books, followed by: The Wonderful Wizard of Oz, preceded by: Ozma of Oz\n",
      "4197\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Oz books, followed by: The Tin Woodman of Oz, preceded by: Glinda of Oz\n",
      "4198\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Oz Books, followed by: Rinkitink in Oz, preceded by: The Tin Woodman of Oz\n",
      "4199\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4200\n",
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: The Sea Fairies, preceded by: The Scarecrow of Oz\n",
      "4201\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Oz books, followed by: The Scarecrow of Oz, preceded by: The Lost Princess of Oz\n",
      "4202\n",
      "Found nan pages, best-seller: No, film: No, saga: The Twinkle Tales, followed by: nan, preceded by: nan\n",
      "4203\n",
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4204\n",
      "Found 100 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4205\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4206\n",
      "4207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 187 pages, best-seller: No, film: Yes, saga: Dave Brandstetter mysteries, followed by: nan, preceded by: nan\n",
      "4208\n",
      "Found 212 pages, best-seller: No, film: Yes, saga: Heinlein juveniles, followed by: nan, preceded by: Space Cadet\n",
      "4209\n",
      "Found 336 pages, best-seller: No, film: No, saga: Buffy the Vampire Slayer, followed by: Here Be Monsters, preceded by: Lost Slayer\n",
      "4210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 294 pages, best-seller: No, film: No, saga: 1, followed by: nan, preceded by: nan\n",
      "4211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4212\n",
      "Found 521 pages, best-seller: No, film: No, saga: Obernewtyn Chronicles, followed by: The Farseekers, preceded by: The Keeping Place\n",
      "4213\n",
      "Found 291 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4214\n",
      "Found 562 pages, best-seller: No, film: No, saga: Great War, followed by: How Few Remain, preceded by: The Great War: Walk in Hell\n",
      "4215\n",
      "Found 250 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Sands of Time\n",
      "4216\n",
      "Found nan pages, best-seller: No, film: Yes, saga: La Comédie humaine, followed by: nan, preceded by: nan\n",
      "4217\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4218\n",
      "Found 326 pages, best-seller: No, film: No, saga: Galactic Center Saga, followed by: Across the Sea of Suns, preceded by: Tides of Light\n",
      "4219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 132 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4220\n",
      "Found 313 pages, best-seller: No, film: Yes, saga: D.C. Quartet, followed by: nan, preceded by: nan\n",
      "4221\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4222\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4224\n",
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4225\n",
      "Found 230 pages, best-seller: No, film: No, saga: none, followed by: none, preceded by: none\n",
      "4226\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1801 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4228\n",
      "Found 280 pages, best-seller: No, film: Yes, saga: No, followed by: As She Climbed Across the Table, preceded by: Motherless Brooklyn\n",
      "4229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152 pages, best-seller: No, film: No, saga: Nero Wolfe, followed by: Please Pass the Guilt, preceded by: Death Times Three\n",
      "4230\n",
      "Found nan pages, best-seller: No, film: No, saga: Four Lords of the Diamond, followed by: nan, preceded by: Cerberus: A Wolf in the Fold\n",
      "4231\n",
      "Found 194 pages, best-seller: No, film: Yes, saga: Martin Beckseries, followed by: Murder at the Savoy, preceded by: The Locked Room\n",
      "4232\n",
      "Found 576 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4233\n",
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4234\n",
      "Found 258 pages, best-seller: No, film: Yes, saga: No, followed by: A Division of the Spoils(1974), preceded by: nan\n",
      "4235\n",
      "Found nan pages, best-seller: No, film: No, saga: Albert Campion, followed by: Flowers for the Judge, preceded by: The Case of the Late Pig\n",
      "4236\n",
      "Found nan pages, best-seller: No, film: No, saga: Albert Campion, followed by: nan, preceded by: Mystery Mile\n",
      "4237\n",
      "Found 223 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4238\n",
      "Found 350 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4239\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 208 pages, best-seller: No, film: Yes, saga: Philip Marlowe, followed by: The Long Goodbye, preceded by: Poodle Springs\n",
      "4241\n",
      "Found 458 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4242\n",
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4243\n",
      "Found 680 pages, best-seller: No, film: No, saga: No, followed by: –, preceded by: Regenesis\n",
      "4244\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Destination Mecca, preceded by: The Way of the Sufi\n",
      "4245\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Way West\n",
      "4247\n",
      "Found 200 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4248\n",
      "Found 640 pages, best-seller: No, film: No, saga: Diogenes Trilogy,Aloysius Pendergast, followed by: Dance of Death, preceded by: The Wheel of Darkness\n",
      "4249\n",
      "Found 448 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4250\n",
      "Found 304 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4251\n",
      "Found 128 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4252\n",
      "Found 189 pages, best-seller: No, film: No, saga: Ramona (novel series), followed by: Ramona the Pest, preceded by: Ramona and Her Father\n",
      "4253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: A Cherry, preceded by: Goodbye\n",
      "4254\n",
      "Found 387 pages, best-seller: No, film: No, saga: The Deryni Cycle, followed by: The Bastard Prince(publication date),The Quest for Saint Camber(literary chronology), preceded by: In the King's Service (next published)\n",
      "4255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 471 pages, best-seller: No, film: No, saga: Legends Westtrilogy, followed by: nan, preceded by: The Bad Lands\n",
      "4256\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4257\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4258\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Cause for Alarm, preceded by: Judgment on Deltchev\n",
      "4260\n",
      "Found 154 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 440 pages, best-seller: No, film: No, saga: The Enemy, followed by: nan, preceded by: The Dead\n",
      "4262\n",
      "Found 296 pages, best-seller: No, film: No, saga: No, followed by: The Golden Keel, preceded by: Wyatt's Hurricane\n",
      "4263\n",
      "Found nan pages, best-seller: No, film: No, saga: Albert Campion, followed by: Death of a Ghost, preceded by: The Case of the Late Pig\n",
      "4264\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4265\n",
      "Found 282291 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: Doctor Whobook:New Series Adventures, followed by: The Deviant Strain, preceded by: The Stealers of Dreams\n",
      "4267\n",
      "Found 228 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4268\n",
      "Found 32 pages, best-seller: Yes, film: Yes, saga: No, followed by: The Mysteries of Harris Burdick, preceded by: The Stranger\n",
      "4269\n",
      "Found 237 pages, best-seller: No, film: Yes, saga: No, followed by: The Last of the Golden Girls, preceded by: What Casanova Told Me\n",
      "4270\n",
      "Found 176 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 455 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: Jeeves, followed by: The Code of the Woosters, preceded by: The Mating Season\n",
      "4273\n",
      "Found nan pages, best-seller: No, film: No, saga: Dangerous Angels, followed by: Witch Baby, preceded by: Missing Angel Juan\n",
      "4274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4275\n",
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: Zombie Lover, preceded by: The Dastard\n",
      "4276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 740 pages, best-seller: Yes, film: Yes, saga: John Clark, followed by: Executive Orders, preceded by: The Bear and the Dragon\n",
      "4277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4279\n",
      "Found 192 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 277 pages, best-seller: No, film: No, saga: Fiction, followed by: nan, preceded by: Bad, Badder, Baddest (1997)[2]\n",
      "4281\n",
      "Found 314 pages, best-seller: No, film: No, saga: The Legends of Camber of Culdi, followed by: High Deryni(by publication date), preceded by: Saint Camber\n",
      "4282\n",
      "Found 251 pages, best-seller: No, film: No, saga: none, followed by: nan, preceded by: nan\n",
      "4283\n",
      "Found 394 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 318 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4285\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Nova Trilogy, followed by: nan, preceded by: nan\n",
      "4286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: -, preceded by: Royal Flash\n",
      "4288\n",
      "Found 272 pages, best-seller: No, film: No, saga: Nero Wolfe, followed by: Where There's a Will, preceded by: Not Quite Dead Enough\n",
      "4289\n",
      "Found 255272281205 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4290\n",
      "Found 280 pages, best-seller: No, film: Yes, saga: Aubrey-Maturin series, followed by: Desolation Island, preceded by: The Surgeon's Mate\n",
      "4291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: No, saga: Ghostwalker series, followed by: Mind Game, preceded by: Conspiracy Game\n",
      "4292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 303 pages, best-seller: No, film: No, saga: Nero Wolfe, followed by: The Red Box, preceded by: Some Buried Caesar\n",
      "4293\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4294\n",
      "Found 92 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4295\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4296\n",
      "Found 27511 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4297\n",
      "Found 256 pages, best-seller: No, film: No, saga: The Riddle Master Trilogy, followed by: Heir of Sea and Fire, (1977), preceded by: nan\n",
      "4298\n",
      "Found 550 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4299\n",
      "Found 446 pages, best-seller: Yes, film: No, saga: JADE, followed by: nan, preceded by: nan\n",
      "4300\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Second Genesis\n",
      "4301\n",
      "Found 282 pages, best-seller: No, film: Yes, saga: No, followed by: The Mystery of the Blue Train, preceded by: Partners in Crime\n",
      "4302\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4303\n",
      "Found 348 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4304\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Claudine, followed by: nan, preceded by: nan\n",
      "4305\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Hygiene and the Assassin, preceded by: Human Rites\n",
      "4306\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Burmese Days, preceded by: Keep the Aspidistra Flying\n",
      "4307\n",
      "Found 336 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4308\n",
      "Found 202 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4309\n",
      "Found nan pages, best-seller: No, film: No, saga: Dray Prescot series, followed by: none, preceded by: The Suns of Scorpio\n",
      "4310\n",
      "Found 438 pages, best-seller: No, film: No, saga: Gormenghast, followed by: nan, preceded by: Gormenghast\n",
      "4311\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4312\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Nigger of the 'Narcissus'(1897), preceded by: Lord Jim (1900)\n",
      "4313\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4314\n",
      "Found 324 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4315\n",
      "Found 165 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4316\n",
      "Found 352 pages, best-seller: No, film: No, saga: Marcus Didius Falco, followed by: Ode to a Banker, preceded by: The Jupiter Myth\n",
      "4317\n",
      "Found 608 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4318\n",
      "Found 127 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4319\n",
      "Found 245 pages, best-seller: No, film: No, saga: No, followed by: The Dharma Bums(1958), preceded by: Maggie Cassidy  (1959)\n",
      "4320\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4321\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4322\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4323\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4324\n",
      "Found 277 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Good Earth\n",
      "4325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 353 pages, best-seller: No, film: No, saga: House of Earth, followed by: Sons, preceded by: nan\n",
      "4326\n",
      "Found 85 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4327\n",
      "Found 182 pages, best-seller: No, film: No, saga: Anthony Monday, followed by: The Treasure of Alpheus Winterborn, preceded by: The Lamp from the Warlock's Tomb\n",
      "4328\n",
      "Found 1771 pages, best-seller: No, film: No, saga: No, followed by: The Saturdays, preceded by: Then There Were Five\n",
      "4329\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: Song of Solomon, preceded by: Beloved\n",
      "4330\n",
      "Found 511 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 388 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4332\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Les Rougon-Macquart, followed by: Nana, preceded by: La Débâcle\n",
      "4333\n",
      "Found 233 pages, best-seller: No, film: Yes, saga: Rats of NIMH[1], followed by: nan, preceded by: Racso and the Rats of NIMH\n",
      "4334\n",
      "Found 250 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4336\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Lew Archer, followed by: The Moving Target, preceded by: The Way Some People Die\n",
      "4337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4338\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4340\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 247 pages, best-seller: No, film: Yes, saga: No, followed by: Tell All, preceded by: Invisible Monsters Remix\n",
      "4342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 62 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4343\n",
      "Found 400 pages, best-seller: No, film: Yes, saga: Op-Center, followed by: nan, preceded by: Mirror Image\n",
      "4344\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Junkie, preceded by: Minutes to Go (1960) with Sinclair Beiles, Gregory Corso, Brion Gysin\n",
      "4345\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 251 pages, best-seller: No, film: No, saga: Nero Wolfe, followed by: The Silent Speaker, preceded by: And Be a Villain\n",
      "4347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 333 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4348\n",
      "Found 608 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4349\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Asterix, followed by: Asterix and the Big Fight, preceded by: Asterix and the Normans\n",
      "4350\n",
      "Found nan pages, best-seller: No, film: No, saga: Asterix, followed by: Asterix in Britain, preceded by: Asterix the Legionary\n",
      "4351\n",
      "Found 214 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4352\n",
      "Found 240 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Penny Dreadful\n",
      "4353\n",
      "Found 356352 pages, best-seller: No, film: No, saga: Richard Sharpe, followed by: Sharpe's Prey, preceded by: Sharpe's Havoc\n",
      "4354\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Gay Science, preceded by: Beyond Good and Evil\n",
      "4355\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Jaguar\n",
      "4356\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Leatherstocking Tales, followed by: The Pioneers(1823), preceded by: The Prairie (1827)\n",
      "4357\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: The Heroic Slave\n",
      "4358\n",
      "Found 248 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4359\n",
      "Found 48 pages, best-seller: No, film: No, saga: The Jolly Postman, followed by: nan, preceded by: The Jolly Christmas Postman, The Jolly Pocket Postman\n",
      "4360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4361\n",
      "Found 247 pages, best-seller: No, film: No, saga: No, followed by: The Good Master, preceded by: nan\n",
      "4362\n",
      "Found 256 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4363\n",
      "Found 558 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4364\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The White Company\n",
      "4365\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4366\n",
      "Found 243 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 314 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4368\n",
      "Found 271269 pages, best-seller: No, film: No, saga: The Chronicles of the Deryni, followed by: The Childe Morgan Trilogy(literary chronology), preceded by: Deryni Checkmate\n",
      "4369\n",
      "Found 179193 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4370\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4371\n",
      "Found nan pages, best-seller: No, film: No, saga: Curious George, followed by: Curious George Gets a Medal, preceded by: Curious George Learns the Alphabet\n",
      "4372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 384 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4373\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4374\n",
      "Found 344 pages, best-seller: No, film: No, saga: No, followed by: Son of Spellsinger, preceded by: nan\n",
      "4375\n",
      "Found 320 pages, best-seller: No, film: No, saga: Dayworld, followed by: nan, preceded by: Dayworld Rebel\n",
      "4376\n",
      "Found 512 pages, best-seller: No, film: Yes, saga: No, followed by: The Age of Kali, preceded by: Begums Thugs And White Mughals\n",
      "4377\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4378\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4379\n",
      "Found 672 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4380\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4381\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 248 pages, best-seller: No, film: Yes, saga: No, followed by: The Exorcist, preceded by: nan\n",
      "4383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 318 pages, best-seller: No, film: No, saga: No, followed by: The Enemy, preceded by: Bahama Crisis\n",
      "4385\n",
      "Found 254 pages, best-seller: No, film: No, saga: No, followed by: High Citadel, preceded by: Landslide\n",
      "4386\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Beneath the Wheel\n",
      "4387\n",
      "Found 492 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4388\n",
      "Found 32 pages, best-seller: No, film: No, saga: None, followed by: N/A, preceded by: The Funny Thing\n",
      "4389\n",
      "Found 175 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4390\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4391\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4392\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4393\n",
      "Found 227 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4394\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4395\n",
      "Found 454 pages, best-seller: No, film: No, saga: Nantucket series, followed by: Island in the Sea of Time, preceded by: On the Oceans of Eternity\n",
      "4396\n",
      "Found 464 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4397\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4398\n",
      "Found 352 pages, best-seller: No, film: No, saga: No, followed by: The King Must Die, preceded by: nan\n",
      "4399\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4400\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Nova Trilogy, followed by: nan, preceded by: nan\n",
      "4401\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Nova Trilogy, followed by: nan, preceded by: nan\n",
      "4402\n",
      "Found 252 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4403\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4404\n",
      "Found 827 pages, best-seller: No, film: Yes, saga: No, followed by: Mao II, preceded by: The Body Artist\n",
      "4405\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Finding Cassie Crazy\n",
      "4406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 298 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4408\n",
      "Found 329 pages, best-seller: No, film: No, saga: Silverwingseries, followed by: Sunwing, preceded by: Darkwing\n",
      "4409\n",
      "Found 302336 pages, best-seller: No, film: No, saga: The Chronicles of the Deryni, followed by: Deryni Rising, preceded by: High Deryni\n",
      "4410\n",
      "Found 224 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Star Light\n",
      "4411\n",
      "Found 299 pages, best-seller: No, film: No, saga: Queens of England, followed by: nan, preceded by: nan\n",
      "4412\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4413\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4414\n",
      "Found 276 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4415\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4416\n",
      "Found 254 pages, best-seller: No, film: No, saga: Fafhrd and the Gray Mouserseries, followed by: nan, preceded by: Swords Against Death\n",
      "4417\n",
      "Found 229 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 302 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4420\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: Adventures of Huckleberry Finn, preceded by: Tom Sawyer, Detective\n",
      "4421\n",
      "Found 432 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4422\n",
      "Found 245 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4423\n",
      "Found 480 pages, best-seller: No, film: No, saga: Saga of the Skolian Empire, followed by: Spherical Harmonic, preceded by: Diamond Star\n",
      "4424\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Glass Bead Game\n",
      "4425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 pages, best-seller: Yes, film: No, saga: Warriors, followed by: nan, preceded by: Fire and Ice\n",
      "4426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4427\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4428\n",
      "4429\n",
      "Found 400 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4430\n",
      "Found 274 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4431\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4432\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4433\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4434\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 336 pages, best-seller: No, film: No, saga: This Is Not a Test, followed by: nan, preceded by: Please Remain Calm (This Is Not a Test #2)\n",
      "4436\n",
      "Found 319 pages, best-seller: No, film: Yes, saga: Aubrey–Maturin series, followed by: The Letter of Marque, preceded by: The Nutmeg of Consolation\n",
      "4437\n",
      "Found 310 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4438\n",
      "Found 637 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4439\n",
      "Found 480 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4441\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Anne's House of Dreams, preceded by: Rainbow Valley\n",
      "4442\n",
      "Found 272 pages, best-seller: No, film: No, saga: No, followed by: Nightbirds on Nantucket, preceded by: The Cuckoo Tree\n",
      "4443\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4444\n",
      "Found 373 pages, best-seller: No, film: No, saga: No, followed by: Rider at the Gate(1995), preceded by: –\n",
      "4445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 128 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4446\n",
      "Found 294 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4447\n",
      "Found 341 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4448\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: My Life in Art, preceded by: Building a Character\n",
      "4449\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4450\n",
      "Found 192 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4451\n",
      "Found 490 pages, best-seller: No, film: Yes, saga: The Emigrants, followed by: The Emigrants, preceded by: The Settlers\n",
      "4452\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4453\n",
      "Found 331 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 497 pages, best-seller: No, film: No, saga: Diogenes Trilogy,Aloysius Pendergast, followed by: Still Life with Crows, preceded by: Dance of Death\n",
      "4455\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4456\n",
      "Found nan pages, best-seller: No, film: No, saga: Dahakseries, followed by: Mutineers' Moon, preceded by: Heirs of Empire\n",
      "4457\n",
      "Found 323 pages, best-seller: No, film: No, saga: RCN Series, followed by: None (first in the series), preceded by: Lt. Leary Commanding\n",
      "4458\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4459\n",
      "Found 232 pages, best-seller: No, film: No, saga: No, followed by: Pubis Angelical, preceded by: Blood of Requited Love\n",
      "4460\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4461\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4462\n",
      "Found 268 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4463\n",
      "Found 343 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4464\n",
      "Found 314 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4465\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4466\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4467\n",
      "Found 311 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4468\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4469\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4470\n",
      "Found 263 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 329 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4472\n",
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4473\n",
      "Found 272 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Meanest Doll in the World\n",
      "4474\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4475\n",
      "Found 834 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4476\n",
      "Found 292 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Affair\n",
      "4477\n",
      "Found 368 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4478\n",
      "Found nan pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: Seeds of Contemplation (1949) [1]\n",
      "4479\n",
      "Found 404 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4480\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4481\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4482\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4483\n",
      "4484\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4485\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4486\n",
      "Found 260 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4487\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4488\n",
      "Found 32 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4489\n",
      "Found 320 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4490\n",
      "Found 64 pages, best-seller: No, film: Yes, saga: Frog and Toad, followed by: Frog and Toad Are Friends, preceded by: Frog and Toad All Year\n",
      "4491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 pages, best-seller: No, film: No, saga: David Wellington's Monster trilogy, followed by: nan, preceded by: Monster Nation\n",
      "4492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 396 pages, best-seller: No, film: No, saga: The Dresden Files, followed by: Blood Rites, preceded by: Proven Guilty\n",
      "4493\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4494\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4495\n",
      "Found 304 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4496\n",
      "Found 343 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4498\n",
      "Found nan pages, best-seller: No, film: No, saga: Albert Campion, followed by: Dancers in Mourning, preceded by: Traitor's Purse\n",
      "4499\n",
      "Found 672 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4500\n",
      "Found 114 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4502\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Enduring Love, preceded by: Atonement\n",
      "4503\n",
      "Found 424 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4504\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Asterix, followed by: Asterix and the Banquet, preceded by: Asterix and the Big Fight\n",
      "4505\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Asterix, followed by: Asterix and the Goths, preceded by: Asterix and the Banquet\n",
      "4506\n",
      "Found nan pages, best-seller: No, film: No, saga: Asterix, followed by: Asterix in Spain, preceded by: Asterix in Switzerland\n",
      "4507\n",
      "Found 223 pages, best-seller: Yes, film: Yes, saga: Harry Potter, followed by: nan, preceded by: Harry Potter and the Chamber of Secrets\n",
      "4508\n",
      "Found nan pages, best-seller: No, film: No, saga: Heinlein juveniles, followed by: Red Planet, preceded by: Between Planets\n",
      "4509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 220 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4510\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4511\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4512\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4514\n",
      "Found 144 pages, best-seller: No, film: No, saga: Dangerous Angels, followed by: Cherokee Bat and the Goat Guys, preceded by: Baby Be-Bop\n",
      "4515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4516\n",
      "Found nan pages, best-seller: No, film: No, saga: Marîd Audran series, followed by: A Fire in the Sun, preceded by: nan\n",
      "4517\n",
      "Found 189 pages, best-seller: No, film: No, saga: Marîd Audran series, followed by: When Gravity Fails, preceded by: The Exile Kiss\n",
      "4518\n",
      "Found 214256 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4519\n",
      "Found nan pages, best-seller: No, film: No, saga: The Morgaine Stories, followed by: Well of Shiuan(1978), preceded by: Exile's Gate (1988)\n",
      "4520\n",
      "Found 139 pages, best-seller: No, film: No, saga: Darkover, followed by: nan, preceded by: nan\n",
      "4521\n",
      "Found 190 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4522\n",
      "Found 2461991 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4523\n",
      "Found 310 pages, best-seller: No, film: No, saga: Modern Tale of Faerie[1], followed by: nan, preceded by: Valiant\n",
      "4524\n",
      "Found 333 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 190 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4527\n",
      "Found 382 pages, best-seller: No, film: Yes, saga: Aubrey–Maturin series, followed by: The Fortune of War, preceded by: The Ionian Mission\n",
      "4528\n",
      "Found 315 pages, best-seller: No, film: No, saga: Barsoom, followed by: A Fighting Man of Mars, preceded by: Synthetic Men of Mars\n",
      "4529\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4530\n",
      "Found 320 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4531\n",
      "Found 220 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4532\n",
      "Found 372 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Poe Shadow\n",
      "4533\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4534\n",
      "Found 479 pages, best-seller: No, film: No, saga: Lord of the Isles, followed by: Queen of Demons, preceded by: Mistress of the Catacombs\n",
      "4535\n",
      "Found 192 pages, best-seller: No, film: No, saga: Beast Master;Hosteen Storm, followed by: nan, preceded by: Lord of Thunder\n",
      "4536\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4537\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4538\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4540\n",
      "Found 272 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4541\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2561 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4543\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4544\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: The Vampire Chronicles, preceded by: nan\n",
      "4546\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4547\n",
      "Found 152 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4548\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4549\n",
      "Found 192 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4550\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4551\n",
      "Found 432 pages, best-seller: No, film: No, saga: No, followed by: Honeymoon, preceded by: nan\n",
      "4552\n",
      "Found 224 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4553\n",
      "Found 1961 pages, best-seller: Yes, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4554\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4555\n",
      "Found 384 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Show Business (1992)\n",
      "4556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: Shadowmarchtrilogy: Book 2, followed by: Shadowmarch, preceded by: Shadowrise\n",
      "4557\n",
      "Found 173 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4558\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Showboat World\n",
      "4559\n",
      "Found 176 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4560\n",
      "Found 190 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4561\n",
      "Found 176 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4562\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4563\n",
      "Found 142 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4564\n",
      "Found 141 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4565\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4566\n",
      "Found nan pages, best-seller: No, film: Yes, saga: The Oz books, followed by: The Emerald City of Oz, preceded by: Tik-Tok of Oz\n",
      "4567\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4568\n",
      "Found 32 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4569\n",
      "Found 1349 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: A Suitable Girl\n",
      "4570\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4571\n",
      "Found 208 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 384 pages, best-seller: No, film: No, saga: Eagles of the Empire, followed by: The Gladiator, preceded by: Praetorian\n",
      "4573\n",
      "Found 319 pages, best-seller: No, film: Yes, saga: No, followed by: The First Sir Percy, preceded by: Sir Percy Leads the Band\n",
      "4574\n",
      "Found 320 pages, best-seller: No, film: Yes, saga: Aubrey-Maturin series, followed by: The Hundred Days, preceded by: The Final Unfinished Voyage of Jack Aubrey\n",
      "4575\n",
      "Found 261 pages, best-seller: No, film: Yes, saga: Aubrey-Maturin series, followed by: Clarissa Oakes, preceded by: The Commodore\n",
      "4576\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4577\n",
      "Found 360 pages, best-seller: No, film: No, saga: Inspector Chen Cao, followed by: Death of a Red Heroine, preceded by: When Red Is Black\n",
      "4578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 432 pages, best-seller: No, film: No, saga: Skyward, followed by: Starsight, preceded by: Defiant\n",
      "4579\n",
      "Found 336 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4580\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4581\n",
      "Found 410 pages, best-seller: No, film: Yes, saga: Cutler series, followed by: Secrets of the Morning 1991, preceded by: Midnight Whispers 1992\n",
      "4582\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4583\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4584\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4585\n",
      "Found 480 pages, best-seller: No, film: No, saga: Duneseries, followed by: God Emperor of Dune, preceded by: Chapterhouse: Dune\n",
      "4586\n",
      "Found 148 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 158 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4588\n",
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: Crumbs, preceded by: King of the Rattling Spirits\n",
      "4589\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4590\n",
      "Found 467 pages, best-seller: No, film: No, saga: Radix Tetrad, followed by: nan, preceded by: In Other Worlds\n",
      "4591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Doctor Whobook:Virgin New Adventures, followed by: The Death of Art, preceded by: Bad Therapy (publication)\n",
      "4592\n",
      "Found 736 pages, best-seller: No, film: No, saga: Sword of Shadows, followed by: nan, preceded by: A Fortress of Grey Ice\n",
      "4593\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4594\n",
      "Found 222 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4595\n",
      "Found 190 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4596\n",
      "Found 276 pages, best-seller: No, film: No, saga: Sir John Fielding, #2, followed by: Blind Justice, preceded by: Watery Grave\n",
      "4597\n",
      "Found 224 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4598\n",
      "Found 368 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: An Infamous Army\n",
      "4599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4600\n",
      "Found 533 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4601\n",
      "Found 216 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 461 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4605\n",
      "Found 256 pages, best-seller: No, film: No, saga: No, followed by: Against the Fall of Night, preceded by: nan\n",
      "4606\n",
      "Found 320452 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4607\n",
      "Found 191 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4608\n",
      "Found nan pages, best-seller: No, film: No, saga: Inspector Alan Banks, #8, followed by: Dry Bones That Dream, preceded by: Dead Right\n",
      "4609\n",
      "Found 432466 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 736 pages, best-seller: No, film: No, saga: The 'Egyptian' novels, followed by: Warlock, preceded by: Desert God\n",
      "4611\n",
      "Found 512 pages, best-seller: No, film: Yes, saga: No, followed by: Flashman's Lady, preceded by: Flashman and the Dragon\n",
      "4612\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Ghost Rider: Travels on the Healing Road\n",
      "4613\n",
      "Found 241 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4614\n",
      "Found 154 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4615\n",
      "Found 442 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 pages, best-seller: Yes, film: No, saga: The A-List, followed by: American Beauty, preceded by: Beautiful Stranger\n",
      "4617\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4618\n",
      "Found 148 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: A Year Down Yonder\n",
      "4619\n",
      "Found 462 pages, best-seller: No, film: Yes, saga: Women's Murder Club, followed by: nan, preceded by: 2nd Chance\n",
      "4620\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4621\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3591 pages, best-seller: No, film: No, saga: A Time Odyssey, followed by: Sunstorm, preceded by: nan\n",
      "4623\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4624\n",
      "Found nan pages, best-seller: No, film: No, saga: Children of Violence, followed by: Landlocked (novel), preceded by: nan\n",
      "4625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 384 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4627\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Vurt series, followed by: nan, preceded by: Pollen\n",
      "4628\n",
      "Found 558 pages, best-seller: No, film: No, saga: No, followed by: The Siege of Krishnapur, preceded by: nan\n",
      "4629\n",
      "Found 192 pages, best-seller: No, film: No, saga: Gerald Durrell'sCorfutrilogy, followed by: My Family and Other Animals,Birds, Beasts and Relatives, preceded by: nan\n",
      "4630\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4631\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4632\n",
      "Found 352 pages, best-seller: No, film: Yes, saga: No, followed by: Filth, preceded by: nan\n",
      "4633\n",
      "Found nan pages, best-seller: No, film: No, saga: The Beebo Brinker Chronicles, followed by: Women in the Shadows, preceded by: Beebo Brinker\n",
      "4634\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: Mike, preceded by: Psmith, Journalist\n",
      "4635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 287 pages, best-seller: No, film: Yes, saga: No, followed by: Under Venus, preceded by: If You Could See Me Now\n",
      "4636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4637\n",
      "Found 512 pages, best-seller: No, film: No, saga: The Second Chronicles of Thomas Covenant, followed by: The One Tree, preceded by: The Runes of the Earth\n",
      "4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: Kay ScarpettaMysteries, followed by: The Last Precinct, preceded by: Trace\n",
      "4639\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4640\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4641\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4642\n",
      "Found 176 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4643\n",
      "Found 520 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4644\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 592 pages, best-seller: No, film: No, saga: No, followed by: Cyteen, preceded by: nan\n",
      "4646\n",
      "Found 39311995 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4647\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4648\n",
      "Found 2391751947 pages, best-seller: No, film: Yes, saga: Henry Merrivale, followed by: The Reader is Warned, preceded by: Murder in the Submarine Zone\n",
      "4649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 255 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4650\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4651\n",
      "Found 288 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4652\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4653\n",
      "Found nan pages, best-seller: No, film: No, saga: Heinlein juveniles, followed by: Starman Jones, preceded by: Tunnel in the Sky\n",
      "4654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 319 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4655\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: The Haunted Bookshop\n",
      "4656\n",
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4657\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Malory Towers, followed by: The Second Form at Malory Towers, preceded by: Upper Fourth at Malory Towers\n",
      "4658\n",
      "Found 198 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4659\n",
      "Found 741 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4660\n",
      "Found 278 pages, best-seller: No, film: No, saga: No, followed by: Now That April's Here and Other Stories, preceded by: Luke Baldwin's Vow\n",
      "4661\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Tecumseh Fox, followed by: Bad for Business, preceded by: nan\n",
      "4662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4663\n",
      "Found 432 pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4664\n",
      "Found 371 pages, best-seller: No, film: Yes, saga: Molly Moon, followed by: nan, preceded by: Molly Moon Stops the World\n",
      "4665\n",
      "Found 158 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4666\n",
      "Found 303 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4667\n",
      "Found 760 pages, best-seller: No, film: No, saga: Earth's Children, followed by: The Mammoth Hunters, preceded by: The Shelters of Stone\n",
      "4668\n",
      "Found 139 pages, best-seller: No, film: Yes, saga: No, followed by: The Wilderness, preceded by: Tourist Guide to Ireland\n",
      "4669\n",
      "Found 224 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4670\n",
      "Found 181 pages, best-seller: No, film: Yes, saga: Nancy Drew Mystery Stories, followed by: The Secret in the Old Attic, preceded by: The Mystery of the Tolling Bell\n",
      "4671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6241848 pages, best-seller: No, film: Yes, saga: No, followed by: Mrs. Perkins's Ball, preceded by: The Book of Snobs\n",
      "4673\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4674\n",
      "Found 40 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: Yes, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4676\n",
      "Found 287 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 304430 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4678\n",
      "Found 190 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4680\n",
      "Found 154 pages, best-seller: No, film: No, saga: No, followed by: The Blizzard Disaster (Frightmares Series)(1998), preceded by: Shelter Dogs (1999)\n",
      "4681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4682\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4684\n",
      "Found 330 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4685\n",
      "Found 336 pages, best-seller: Yes, film: No, saga: Alphabet Mysteries, followed by: \"N\" Is for Noose, preceded by: \"P\" Is for Peril\n",
      "4686\n",
      "Found nan pages, best-seller: No, film: No, saga: Conan the Barbarian, followed by: nan, preceded by: nan\n",
      "4687\n",
      "Found 167 pages, best-seller: No, film: No, saga: Switchers Trilogy, followed by: Switchers, preceded by: Wild Blood\n",
      "4688\n",
      "Found 186 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4689\n",
      "Found 544 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4690\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4691\n",
      "Found 275 pages, best-seller: No, film: No, saga: Dan Starkeynovels, followed by: Of Wee Sweetie Mice and Men(1996)', preceded by: Shooting Sean(2001)'\n",
      "4692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 315 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4693\n",
      "Found 233 pages, best-seller: No, film: No, saga: No, followed by: Space Station Seventh Grade, preceded by: nan\n",
      "4694\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4695\n",
      "Found 238 pages, best-seller: No, film: No, saga: No, followed by: Shooting Script, preceded by: Blame the Dead\n",
      "4696\n",
      "Found 355 pages, best-seller: No, film: No, saga: Ringworldstoryline fromKnown Space, followed by: Ringworld, preceded by: The Ringworld Throne\n",
      "4697\n",
      "Found 240 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4698\n",
      "Found 306 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4699\n",
      "Found 184 pages, best-seller: No, film: No, saga: Nero Wolfe, followed by: Death of a Doxy, preceded by: Death of a Dude\n",
      "4700\n",
      "Found 186 pages, best-seller: No, film: No, saga: Nero Wolfe, followed by: Three Witnesses, preceded by: Three for the Chair\n",
      "4701\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4702\n",
      "Found 216 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4703\n",
      "Found nan pages, best-seller: No, film: No, saga: Greenwich Village Trilogy, followed by: The Butterfly Kid, preceded by: The Probability Pad\n",
      "4704\n",
      "Found 183 pages, best-seller: No, film: Yes, saga: Nero Wolfe, followed by: Three at Wolfe's Door, preceded by: The Final Deduction\n",
      "4705\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4706\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4707\n",
      "Found 3362 pages, best-seller: No, film: No, saga: The Underland Chronicles, followed by: nan, preceded by: Gregor and the Prophecy of Bane\n",
      "4708\n",
      "Found nan pages, best-seller: No, film: Yes, saga: Martin Beckseries, followed by: Cop Killer, preceded by: nan\n",
      "4709\n",
      "Found 158 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4710\n",
      "Found 216 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4711\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4712\n",
      "Found 280 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4713\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4714\n",
      "Found 285 pages, best-seller: No, film: No, saga: Novaya volna russkoy fantastiki, followed by: nan, preceded by: nan\n",
      "4715\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4716\n",
      "Found 3841 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: Grant Comes East\n",
      "4717\n",
      "Found 448 pages, best-seller: No, film: Yes, saga: Dragonlance Chronicles, followed by: nan, preceded by: Dragons of Winter Night\n",
      "4718\n",
      "Found nan pages, best-seller: No, film: No, saga: Moomins, followed by: nan, preceded by: nan\n",
      "4719\n",
      "Found 504 pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4720\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: Three Men on the Bummel\n",
      "4721\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4722\n",
      "Found 682 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4723\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: The Tale of Ginger and Pickles, preceded by: The Tale of Timmy Tiptoes\n",
      "4724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 255 pages, best-seller: Yes, film: No, saga: Silverwingseries, followed by: nan, preceded by: Sunwing\n",
      "4725\n",
      "Found 326 pages, best-seller: No, film: Yes, saga: Barsoom, followed by: nan, preceded by: The Gods of Mars\n",
      "4726\n",
      "Found 195 pages, best-seller: No, film: No, saga: The Matador Series, followed by: nan, preceded by: Matadora\n",
      "4727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 528 pages, best-seller: Yes, film: No, saga: No, followed by: State of Fear, preceded by: Pirate Latitudes\n",
      "4728\n",
      "Found nan pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4730\n",
      "Found 267 pages, best-seller: No, film: No, saga: Kenzie and Gennaro, followed by: nan, preceded by: Darkness, Take My Hand\n",
      "4731\n",
      "Found 189 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4732\n",
      "Found 191 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4733\n",
      "Found 144 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4734\n",
      "Found 188 pages, best-seller: No, film: No, saga: No, followed by: nan, preceded by: nan\n",
      "4735\n",
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n",
      "4736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\Noel Nathan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nan pages, best-seller: No, film: Yes, saga: No, followed by: nan, preceded by: nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming you have a pandas DataFrame named books_df\n",
    "\n",
    "\n",
    "\n",
    "def find_book_values(book_webpage):\n",
    "    soup = BeautifulSoup(book_webpage.html(), 'html.parser')\n",
    "\n",
    "            \n",
    "    values = extract_book_features(soup)\n",
    "\n",
    "    if not values:\n",
    "        return False\n",
    "\n",
    "    [pages, best_seller, film,  saga, follow_by, preceded_by] = values\n",
    "\n",
    "\n",
    "    if not pages: \n",
    "        pages =  float('NaN')\n",
    "\n",
    "    if not saga: \n",
    "        saga = 'No'\n",
    "    \n",
    "    if best_seller:\n",
    "        best_seller = 'Yes'\n",
    "    else:\n",
    "        best_seller = 'No'\n",
    "\n",
    "    if film:\n",
    "        film = 'Yes'\n",
    "    else:\n",
    "        film = 'No'\n",
    "    \n",
    "    if not follow_by:\n",
    "        follow_by = float('NaN')\n",
    "    \n",
    "    if not preceded_by:\n",
    "        preceded_by = float('NaN')\n",
    "    \n",
    "    print(f\"Found {pages} pages, best-seller: {best_seller}, film: {film}, saga: {saga}, followed by: {follow_by}, preceded by: {preceded_by}\")\n",
    "    return [pages, best_seller, film, saga, follow_by, preceded_by]\n",
    "    \n",
    "\n",
    "def search_books_with_saga(keyword, books_df):\n",
    "    def extract_from_webpage(book_webpage):\n",
    "\n",
    "        if not book_webpage: return False\n",
    "\n",
    "        values = find_book_values(book_webpage)\n",
    "\n",
    "        if not values: return False\n",
    "\n",
    "        books_df.loc[books_df['Book Title'] == keyword, ['Number of Pages', 'Best Seller', 'Film', 'Saga', 'Followed by', 'Preceded by']] = values\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    book_webpage = False\n",
    "\n",
    "    try:\n",
    "        book_webpage = wikipedia.page(keyword, auto_suggest=False)\n",
    "    except wikipedia.exceptions.DisambiguationError:\n",
    "        pass\n",
    "    except wikipedia.exceptions.PageError as e:\n",
    "        pass\n",
    "\n",
    "    if extract_from_webpage(book_webpage): return\n",
    "    \n",
    "    try :\n",
    "        book_webpage = wikipedia.page(keyword + ' (novel)', )\n",
    "    except wikipedia.exceptions.DisambiguationError:\n",
    "        pass\n",
    "    except wikipedia.exceptions.PageError as e:\n",
    "        pass\n",
    "    \n",
    "    if extract_from_webpage(book_webpage): return\n",
    "\n",
    "    \n",
    "    search_results = wikipedia.search(keyword + ' (novel)', results=4)\n",
    "\n",
    "    for book in search_results:\n",
    "        try:\n",
    "            book_webpage = wikipedia.page(book)\n",
    "        except wikipedia.exceptions.DisambiguationError:\n",
    "            pass\n",
    "        except wikipedia.exceptions.PageError as e:\n",
    "            pass\n",
    "        if extract_from_webpage(book_webpage): return\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in books_df.iterrows():\n",
    "    print(index)\n",
    "    search_books_with_saga(row['Book Title'], books_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.to_csv('../clean_data/books2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1669"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df['Number of Pages'].isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
